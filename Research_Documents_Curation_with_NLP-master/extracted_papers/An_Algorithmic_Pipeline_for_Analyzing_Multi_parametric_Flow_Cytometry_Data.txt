5
1
0
2

 

n
a
J
 

4
1

 
 
]

.

M
Q
o
i
b
-
q
[
 
 

1
v
1
6
4
3
0

.

1
0
5
1
:
v
i
X
r
a

AN ALGORITHMIC PIPELINE FOR ANALYZING

MULTI-PARAMETRIC FLOW CYTOMETRY DATA

A Dissertation

Submitted to the Faculty

of

Purdue University

by

Md Ariful Azad

In Partial Fulﬁllment of the

Requirements for the Degree

of

Doctor of Philosophy

May 2014

Purdue University

West Lafayette, Indiana

ii

To my mother Ayesha Begum,

eldest brother Md. Aslam hossain,

& wife Rubaya Pervin,

thank you for enlightening my spirit.

iii

ACKNOWLEDGMENTS

All praises go to the Almighty Allah for giving me the opportunity and strength

to achieve a doctoral degree. I remember my father who passed away at my young

age. May Allah keep him in the eternal peace.

Foremost, I convey my sincere gratitude to my advisor Prof. Alex Pothen for

his guidance and support in my Ph.D study. He patiently nurtured me throughout

the doctoral study and enthusiastically helped me in the research and writing the

thesis. The hospitality of Alex and his family made my stay at Purdue enjoyable. He

also advised me in many non-academic matters whenever needed. I could not have

imagined a better advisor and mentor.

I am grateful to Dr. Bartek Rajwa and Dr. Saumyadipta Pyne for helping me

with their immense knowledge. Without their help, it would be diﬃcult for me to

understand the biological systems for which I developed algorithms in my dissertation.

I would like to thank Prof. Olga Vitek and Prof. Ananth Grama for serving in my

Ph.D advising committee and guiding me in various aspects of my research.

My sincere appreciation also goes to Dr. Mahantesh Halapannavar and Dr. John

Feo for mentoring me in the summer internship at Paciﬁc Northwest National Lab

where I gained valuable experience from exciting projects.

I thank my fellow col-

leagues and friends: Dr. Assefaw Gebremedhin, Arif Khan, Mu Wang, Yu-hong

Yeung, and Baharak Saberidokht for stimulating discussions and creating a friendly

work atmosphere. I am thankful to Johannes Langguth and Md. Mostofa Ali Patwary

who visited from university of Bergen and discussed interesting problems. I would

like to give my deepest thanks to Bangladeshi students at Purdue for making my stay

as comfortable as home. Especially, I am grateful to my friends Imrul Hossain and

Alim al Islam for their aﬀection and generous help.

iv

I am blessed to be born in a lovingly family. As the youngest child, each member

of my family raised me with aﬀection and instilled values in me. Especially my mother

Ayesha Begum and the eldest brother Md. Aslam Hossain made me passionate about

research and inspired me to pursue higher education abroad. Finally, I was not able to

ﬁnish this journey without the love and encouragement from my wife Rubaya Pervin.

Her cooperation and support in every aspect of life drive me forward.

It has been a great privilege to pursue my doctoral study in the Department of

Computer Science at Purdue University. I would like to thank the university and the

department for providing me an excellent environment for learning and research. I

will always cherish my memory at Purdue.

TABLE OF CONTENTS

v

Page

LIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

viii

LIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ABBREVIATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ABSTRACT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ix

xi

xii

1
1
3
4
5
6
8
9
10
11
12
13
15
18
18
19
20
22

23
23
25
27
27
27
28
30
30
33
34

Flow cytometry (FC)

Spectral unmixing (compensation)

Identifying cell populations (gating or clustering)

1 INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1 Diversity of the cellular systems . . . . . . . . . . . . . . . . . . . .
1.2
. . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Flow cytometry data analysis
. . . . . . . . . . . . . . . . . . . . .
1.3.1 Removing unintended cells . . . . . . . . . . . . . . . . . . .
1.3.2
. . . . . . . . . . . . . .
1.3.3 Data transformation and variance stabilization . . . . . . . .
1.3.4
. . . . . .
1.3.5 Registering cell populations across samples . . . . . . . . . .
1.3.6 Meta-clustering and templates . . . . . . . . . . . . . . . . .
1.3.7 Classifying FC samples . . . . . . . . . . . . . . . . . . . . .
1.4 The need for automation in FC data analysis . . . . . . . . . . . . .
1.5 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.6 Datasets used in this thesis . . . . . . . . . . . . . . . . . . . . . . .
1.6.1 Healthy donor (HD) dataset . . . . . . . . . . . . . . . . . .
1.6.2 T cell phosphorylation (TCP) dataset . . . . . . . . . . . . .
1.7 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.8 Outline of the thesis
. . . . . . . . . . . . . . . . . . . . . . . . . .

2 VARIANCE STABILIZATION IN FLOW CYTOMETRY . . . . . . . .
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Variance stabilization for ﬂow cytometry data . . . . . . . . . . . .
2.3.1 The goal of variance stabilization . . . . . . . . . . . . . . .
2.3.2 Channel-speciﬁc variance stabilization . . . . . . . . . . . .
2.3.3 ﬂowVS : an algorithm for per-channel variance stabilization .
2.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.1
Selecting the optimum cofactors for the asinh transformation
2.4.2 Normality of the variance-stabilized clusters
. . . . . . . . .
2.4.3 Application to microarray data . . . . . . . . . . . . . . . .

2.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 POPULATION IDENTIFICATION BY CLUSTERING ALGORITHMS
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1
3.2 Clustering algorithms . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Cluster validation methods . . . . . . . . . . . . . . . . . . . . . . .
Internal cluster validation methods . . . . . . . . . . . . . .
3.3.1
3.3.2 External cluster validation methods . . . . . . . . . . . . . .
Selecting the number of clusters (cell populations) . . . . . .
3.3.3
3.3.4
Selecting the “best” algorithm . . . . . . . . . . . . . . . . .
3.4 Consensus clustering . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Identifying cell populations in a healthy sample . . . . . . .
Identifying cell sub-populations in T cells . . . . . . . . . . .
3.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.5.1
3.5.2

4 REGISTERING CELL POPULATIONS ACROSS FC SAMPLES . . . .
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1
4.2 Dissimilarity between a pair of cell clusters . . . . . . . . . . . . . .
4.3 The mixed edge cover (MEC) algorithm . . . . . . . . . . . . . . .
4.3.1 Overview of the algorithm . . . . . . . . . . . . . . . . . . .
4.3.2 Bipartite graph model
. . . . . . . . . . . . . . . . . . . . .
4.3.3 MEC algorithm on the bipartite graph . . . . . . . . . . . .
4.3.4 Proof of correctness . . . . . . . . . . . . . . . . . . . . . . .
4.3.5 Complexity of the MEC algorithm . . . . . . . . . . . . . .
4.4 Properties of mixed edge cover . . . . . . . . . . . . . . . . . . . . .
4.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.5.1 Registering populations across samples from two healthy sub-

jects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.5.2 Registering populations before and after stimulating T cells
4.5.3 Registering population in diagnosing Acute Myeloid Leukemia

(AML) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.6 Conclusions and future work . . . . . . . . . . . . . . . . . . . . . .

5.1
5.2 An algorithm for constructing templates

5 META-CLUSTERS AND CLASS TEMPLATES . . . . . . . . . . . . . .
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . .
5.2.1 Dissimilarity between samples or templates . . . . . . . . . .
5.2.2 The hierarchical matching-and-merging (HM&M) algorithm
5.2.3 Creating templates from a template-tree . . . . . . . . . . .
5.2.4 Computational complexity . . . . . . . . . . . . . . . . . . .
5.3 The homogeneity of meta-clusters and templates . . . . . . . . . . .
5.3.1 Analyzing homogeneity of a one-dimensional meta-cluster . .
5.3.2 Comparison with null hypothesis based signiﬁcance testing .

vi

Page
37

39
39
41
43
44
47
49
49
50
51
51
54
59

61
61
63
65
65
66
67
69
69
70
70

70
73

75
76

78
78
81
81
82
83
84
84
85
87

5.3.3 Analyzing homogeneity of high-dimensional meta-clusters . .
5.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . .
. . . . . . . . . .
5.5 Conclusions and future work . . . . . . . . . . . . . . . . . . . . . .

5.4.1 Creating templates from healthy samples
5.4.2 Creating templates from the TCP dataset

6 CLASSIFYING FC SAMPLES BASED ON TEMPLATES . . . . . . . .
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.2 Classifying Samples with Static Templates . . . . . . . . . . . . . .
6.2.1 Creating static templates from a collection of FC samples . .
6.2.2 Classifying new samples with static templates . . . . . . . .
6.3 Building dynamic templates . . . . . . . . . . . . . . . . . . . . . .
6.3.1 The algorithm . . . . . . . . . . . . . . . . . . . . . . . . . .
6.3.2 Computational complexity . . . . . . . . . . . . . . . . . . .
6.3.3 Classifying a sample
. . . . . . . . . . . . . . . . . . . . . .
6.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.4.1 Classifying stimulation status of T cells . . . . . . . . . . . .
6.4.2 Classifying immune patterns in healthy individuals
. . . . .
6.5 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7 CLASSIFICATION OF ACUTE MYELOID LEUKEMIA . . . . . . . . .
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2.1 The AML Dataset
. . . . . . . . . . . . . . . . . . . . . . .
Identifying cell populations in each sample . . . . . . . . . .
7.2.2
7.2.3 Creating templates from a collection of samples . . . . . . .
7.2.4 Classiﬁcation score of a sample in AML dataset . . . . . . .
7.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.3.1 Cell populations in healthy and AML samples . . . . . . . .
7.3.2 Healthy and AML templates . . . . . . . . . . . . . . . . . .
Identifying meta-clusters symptomatic of AML . . . . . . . .
7.3.3
7.3.4
Impact of each tube in the classiﬁcation . . . . . . . . . . .
7.3.5 Classifying test samples
. . . . . . . . . . . . . . . . . . . .
7.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8 CONCLUSIONS AND FUTURE WORK . . . . . . . . . . . . . . . . . .
8.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.2 Future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

LIST OF REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . .

VITA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

vii

Page
89
90
90
94
97

100
100
102
102
103
104
104
106
107
108
108
113
114

116
116
118
118
120
120
120
123
123
124
127
132
134
136

137
137
139

142

155

LIST OF TABLES

Table

1.1 Diﬀerent analysis steps of FC data (right column) are originated from FC

data attributes (left column).

. . . . . . . . . . . . . . . . . . . . . . .

3.1 List of clustering algorithms used in the FC data analysis . . . . . . . .

3.2 List of internal cluster validation indices . . . . . . . . . . . . . . . . .

5.1 Summary of terminology used in Chapter 5 . . . . . . . . . . . . . . .

5.2 The homogeneity of meta-clusters contained in the templates created from

the TCP dataset

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

viii

Page

6

42

47

79

97

7.1 The ﬂuorophore-conjugated antibodies contained in each of the 8 tubes in

which the samples were incubated.

. . . . . . . . . . . . . . . . . . . .

119

7.2 Meta-clusters characteristic of AML for the 23 AML samples in the train-

ing set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

128

7.3 Four statistical measures evaluating the performance of the template-based

classiﬁcation in the AML data . . . . . . . . . . . . . . . . . . . . . . .

132

LIST OF FIGURES

Figure

1.1 A simpliﬁed cellular hierarchy of human immune cells . . . . . . . . . .

1.2 A schematic diagram of a ﬂow cytometer . . . . . . . . . . . . . . . . .

1.3 A schematic view of ﬂow cytometry (FC) samples . . . . . . . . . . . .

1.4 Removing unintended events from an FC sample . . . . . . . . . . . . .

1.5 Spectral unmixing in a pair of overlapped ﬂuorescence channels

. . . .

1.6 An FC data analysis pipeline

. . . . . . . . . . . . . . . . . . . . . . .

1.7 Description of the healthy donor (HD) dataset . . . . . . . . . . . . . .

2.1 Mean-variance relationship in samples from the HD dataset before and

after variance stabilization . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 Variance stabilizing cofactors used with the asinh transformation for the

HD dataset

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 Density plot of the variance stabilized channels from samples in the HD

dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4 The normality of the one dimensional clusters after variance stabilization

2.5 Three variance stabilization approaches applied to the Kidney microarray

data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.6 Variance stabilization of the Kidney microarray data . . . . . . . . . .

3.1 The performance of diﬀerent clustering algorithms on a healthy sample

3.2 Selecting the optimum number of clusters in a healthy sample . . . . .

3.3 Lymphocyte sub-populations in a healthy sample . . . . . . . . . . . .

3.4 The optimum number of clusters in a sample from the TCP dataset . .

3.5 Consensus clustering algorithms applied to a sample from the TCP dataset

3.6 T cell sub-populations within a sample from the TCP dataset

. . . . .

4.1 A working example of the mixed edge cover algorithm . . . . . . . . . .

4.2 Selecting the unmatch-penalty λ for the mixed edge cover algorithm . .

ix

Page

2

3

5

7

8

16

19

31

32

33

34

35

36

52

54

55

56

57

58

68

71

Figure

4.3 Registering cell populations across two representative samples from the

HD dataset

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.4 Registering populations across a pair of samples before and after stimu-

lating T cells with an anti-CD3 antibody . . . . . . . . . . . . . . . . .

4.5 Registering populations between normal and AML samples . . . . . . .

5.1 An example of a template-tree created from four hypothetical samples .

5.2 The template-tree created from all samples of the HD dataset

. . . . .

5.3 The homogeneity of meta-clusters for diﬀerent groupings of samples in the

HD dataset

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.4 Meta-clusters contained in the pre- and post- stimulation templates cre-

ated from the TCP dataset

. . . . . . . . . . . . . . . . . . . . . . . .

6.1 An algorithm for inserting a sample into the template-tree . . . . . . .

6.2 Four cases to consider when inserting a sample into the template-tree .

6.3 Sample classiﬁcation based on static templates . . . . . . . . . . . . . .

x

Page

72

74

75

80

91

93

96

105

106

109

6.4 The dynamic template-tree created from the samples of the TCP dataset

110

6.5 Heat plot showing the dissimilarity between pairs of samples in the TCP

dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

111

6.6 Levels of SLP-76 expression in each pair of samples from the TCP dataset 112

6.7 The template-tree created from the HD dataset

. . . . . . . . . . . . .

113

7.1 Cell types identiﬁed on the side scatter (SS) and CD45 channels for a

healthy and an AML positive sample . . . . . . . . . . . . . . . . . . .

7.2 The healthy and AML templates created from Tube 6 of AML dataset

7.3 Bivariate contour plots (side scatter vs. individual marker) for two meta-

clusters indicative of AML . . . . . . . . . . . . . . . . . . . . . . . . .

7.4 Classiﬁcation of the AML and healthy samples . . . . . . . . . . . . . .

7.5 Cell populations in a misclassiﬁed AML sample . . . . . . . . . . . . .

124

125

131

133

135

xi

ABBREVIATIONS

AML

Acute Myeloid Leukemia

ANOVA

ANalysis Of VAriance

CD

CI

EM

Cluster of Diﬀerentiation

Conﬁdence Interval

Expectation Maximization

EMD

Earth Mover’s Distance

FC

FS

Flow Cytometry

Forward Scatter

GMM

Gaussian mixture model

HD

HIV

Healthy Donor

Human Immunodeﬁciency Virus

HM&M

Hierarchical Matching and Merging

MANOVA Multivariate ANalysis Of VAriance

ML

MEC

MFI

PAM

Maximum Likelihood

Mixed Edge Cover

Mean Fluorescence Intensity

Partitioning Around Medoids

PBMC

Peripheral Blood Mononuclear Cells

RCS

SS

TCP

Relative Cluster Separation

Side Scatter

T Cell Phosphorylation

UPGMA

Unweighted Pair Group Method with Arithmetic Mean

VS

Variance Stabilization

xii

ABSTRACT

Azad, Ariful Ph.D., Purdue University, May 2014. An Algorithmic Pipeline for An-
alyzing Multi-parametric Flow Cytometry Data. Major Professor: Alex Pothen.

Flow cytometry (FC) is a single-cell proﬁling platform for measuring the phe-

notypes (protein expressions) of individual cells from millions of cells in biological

samples. In the last several years, FC has begun to employ high-throughput technolo-

gies, and to generate high-dimensional data, and hence algorithms for analyzing the

data represent a bottleneck. This dissertation addresses several computational chal-

lenges arising in modern cytometry while mining information from high-dimensional

and high-content biological data. A collection of combinatorial and statistical algo-

rithms for locating, matching, prototyping, and classifying cellular populations from

multi-parametric ﬂow cytometry data is developed.

The algorithms developed in this dissertation are assembled into a data analy-

sis pipeline called ﬂowMatch. This pipeline consists of ﬁve well-deﬁned algorithmic

modules for (1) transforming data to stabilize within-population variance, (2) identi-

fying phenotypic cell populations by robust clustering algorithms, (3) registering cell

populations across samples, (4) encapsulating a class of samples with templates, and

(5) classifying samples based on their similarity with the templates. Each module

of ﬂowMatch is designed to perform a speciﬁc task independent of other modules of

the pipeline. However, they can also be employed sequentially in the order described

above to perform the complete data analysis.

The ﬂowMatch pipeline is made available as an open-source R package in Bio-

conductor (http://www.bioconductor.org/). I have employed ﬂowMatch for classify-

ing leukemia samples, evaluating the phosphorylation eﬀects on T cells, classifying

healthy immune proﬁles, comparing the impact of two treatments for Multiple Scle-

xiii

rosis, and classifying the vaccination status of HIV patients. In these analyses, the

pipeline is able to reach biologically meaningful conclusions quickly and eﬃciently

with the automated algorithms. The algorithms included in ﬂowMatch can also be

applied to problems outside of ﬂow cytometry such as in microarray data analysis

and image recognition. Therefore, this dissertation contributes to the solution of

fundamental problems in computational cytometry and related domains.

1

1 INTRODUCTION

1.1 Diversity of the cellular systems

The immune system of a living organism consists of numerous components per-

forming in a coordinated manner in order to provide protection against diseases as

well as abnormally behaving host cells. The immune system must be able to detect

a wide variety of virulent agents, distinguish normal host cells from dis-regulated

pre-cancerous cells, as well as learn and store information about various external

perturbants [1]. In order to decipher the operation and the regulatory networks of

the immune system, it is crucial to obtain the quantitative description of its cellular

components.

Diﬀerent subsets of immune cells can be distinguished on a basis of their pheno-

types, which in turn determine their functions and roles. The phenotypes of each

cell are typically deﬁned by a combination of morphological features such as size,

shape, granularity etc. and the abundances of surface and intracellular markers such

as the cluster of diﬀerentiation (CD) proteins. The immune cells can be organized

in a hierarchy where cells performing general functions are positioned at the top,

while cells performing speciﬁc functions are placed at the bottom of the hierarchy.

I display a simpliﬁed diagram of the hierarchy of immune cells in Figure 1.1, where

morphological features are highlighted in the left subﬁgure and CD protein markers

expressed by common sub-types of white blood cells (leukocytes) are shown in the

right subﬁgure.

An established way to classify diﬀerent phenotypes relies on the presence of speciﬁc

proteins on the surface of cells. The surface molecules are assigned a CD (cluster of

diﬀerentiation) number related to the type of speciﬁc monoclonal antibodies (mAb)

that are shown to bind to that epitope. For example, the mature helper T cells (also

2

Figure 1.1. Simpliﬁed diagrams showing the cellular hierarchy of human
immune cells. (a) Heterogeneous immune cells develop from haematopoi-
etic stem cell (HSC). Diﬀerent types of cells have distinctive morphological
features such as size, shape, granularity etc. (b) Cluster of diﬀerentiation
(CD) protein markers are shown for the common sub-types of white blood
cells (leukocytes). (Images are modiﬁed from Wikimedia Commons under
Creative Commons license.)

known as CD4+ T cells) express CD45, CD3 and CD4 proteins. They are called

CD45+CD3+CD4+ cells in a common notation. Here, ‘+’ and ‘high’ indicate higher
abundances of a marker, and ‘−’ and ‘low’ indicate lower levels of it. Identifying the
CD4+ cell subset is pivotal in AIDS prognosis since the HIV virus infects this cell type

and signiﬁcantly reduces the number of functional CD4+ T cells towards the end of

an HIV-1 infection [2]. Similar to the characterization of T cells, other cell types can

be identiﬁed, described, and isolated on the basis of their morphology, physiology,

and CD based immunophenotyping patterns. The phenotypic patterns of cells are

used to study their roles, interactions with other cell groups, and responses to various

stimuli in healthy or diseased systems [3,4]. For these purposes, ﬂow cytometry (FC),

a proﬁling method measuring the phenotypic responses of the immune system at the

resolution of single cells, is commonly employed.

Multipotential hematopoietic stem cell(Hemocytoblast)Common myeloid progenitorMegakaryocyteThrombocytesErythrocyteMast cellMyeloblastBasophilNeutrophilEosinophilMonocyteMacrophageCommon lymphoid progenitorSmall lymphocyteB lymphocyteT lymphocytePlasma cellNatural killer cell(a)(b)3

Figure 1.2.
(a) A schematic diagram of a ﬂow cytometer showing the
hydrodynamic focusing of the ﬂuid sheath, laser, optics (in simpliﬁed
form, omitting focusing), photomultiplier tubes (PMTs), analogue-to-
digital converter, and analysis workstation. (b) At the interrogation point,
the size, granularity and expression of markers for a cell are measured by
using forward scatter, side scatter and ﬂuorescence intensities respectively.
(Images are modiﬁed from Wikimedia Commons under Creative Commons
license.)

1.2

Flow cytometry (FC)

Flow cytometry (FC) is a platform for measuring various features of individual

cells from millions of cells in a sample. The cellular features measured by FC include

several morphological features such as size, shape, granularity etc. and the abundance

of a number of proteins expressed by the cell. In typical FC experiments, cells in a

suspension (or other biological particles) ﬂow in a stream of ﬂuid passing the region

where a laser beam interrogates each cell. The light scattered by a cell in the forward

and perpendicular directions – known as Forward Scatter (FS) and Side Scatter (SS)

channels respectively – reveal the size, shape and granularity of the cell. The identity

and abundance of the proteins are measured by the ﬂuorescence signals emitted by

the laser-excited, ﬂuorophore-conjugated antibodies bound to the target proteins in a

cell [5]. I show a schematic diagram of a ﬂow cytometer and how it measures diﬀerent

LaserPMTPMTADCSSCFL-2FL-1FL-3FSCAnalysis workstationInterrogation FilterDichroicmirrorCellFlow sheathNozzlePMTCell samplePMTPMTForward Scatter (size)Side Scatter (granularity)Fluorescence(protein abundance)point(b)(a)4

features of a cell in Figure 1.2.

In a ﬂow cytometer, the mixture of ﬂuorescence

signals are roughly separated by several band-pass ﬁlters and each signal is collected

into a separate ﬂuorescence (FL) channel.

In this context, I often use the terms

“a ﬂuorescence channel” and “a protein marker” interchangeably because we infer

information about the latter through the signal collected at the former.

Current ﬂuorescence-based technology supports the measurements of up to 20

proteins simultaneously in each cell from a sample containing millions of cells [6].

Although emerging atomic mass cytometry systems such as CyTOF [7] can measure

more than 40 markers per cell, ﬂuorescence detection is still the most used tool for

single-cell measurements. FC is employed to study the complexity of the immune

system and the changes in its components upon exposure to various external per-

turbants such as pathogens, chemical compounds (drugs), or vaccination, as well as

events such as aging, autoimmune reactions, or presence of cancer. FC is now rou-

tinely employed to illustrate immune cells development and maturation [8], to study

immune responses in the presence of a pathogen, to diagnose diseases of the immune

system [9], and to develop novel vaccines (e.g., against HIV) [10].

1.3 Flow cytometry data analysis

An FC sample measuring p features (known as parameters in FC) from n cells
is represented by an n × p matrix A. The matrix element A(i, j) represents the
measurements of the jth feature in the ith cell. To this end, a cell is represented

by a p-dimensional feature vector capturing the morphology and protein expression

proﬁle of the cell, which are eﬀectively measured by the light scatter and ﬂuorescence

signals. In a typical experiment, we measure hundreds of samples with each sample

measuring multi-dimensional features for up to millions of cells. I show a schematic

view of a data set generated in a typical FC experiment in Figure 1.3. However, the

actual numbers of features, cells, and samples vary from one experiment to another.

5

Figure 1.3. A schematic view of ﬂow cytometry samples from a typical
experiment.

Analysis of a collection of FC samples can lead to diagnosis of various diseases,

monitoring of immune responses in the presence of a pathogen, development of novel

vaccines etc. However, before making useful biological conclusions, the raw FC mea-

surements mixed with various sources of noise need to pass through several analysis

steps in a systematic order. These analysis steps are often guided by speciﬁc aspects

of FC data and are customized to address the biological needs. I present a list of

attributes arising in a typical multi-parametric FC experiment and relate each at-

tribute to a necessary data analysis step in Table 1.1. This list is not exhaustive and

is subject to change depending on the design of experiment and the type of biological

questions answered by a particular experiment. I brieﬂy discuss several analysis steps

in the next few paragraphs.

1.3.1 Removing unintended cells

In the preprocessing phase, various unintended events such as doublets, dead cells,

debris, etc. are removed from the FC data. Figure 1.4 shows several preprocessing

and quality control steps used in a typical FC data analysis. A “doublet” is a pair of

attached cells, which has larger area but smaller height in the forward scatter (FS)

f1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpf1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpf1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpf1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpf1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpf1f2…fpCell-1a11a12…a1pCell-2a21a22…a2p…………Cell-nan1an2…anpp features per cell (p~ 15)n cells per sample (n~100,000)N samples per study (N~ 200)6

Diﬀerent analysis steps of FC data (right column) are originated from FC
data attributes (left column).

Table 1.1

FC data attributes

Data analysis steps

debris, dead cells, doublets

preprocessing & quality control

multiple ﬂuorescence channels (2-20)

spectral unmixing (compensation)

variance increases with mean

variance stabilization

multiple cellular features (4-20)

multidimensional distribution

many observations per sample (104-105)

several discrete cell subsets (2-50)

down-sampling

clustering

similar cell populations across samples

cluster matching or labeling

many samples per cohort

meta-clustering & templates

multiple classes of samples

classiﬁcation

channel relative to the single intact cells. Figure 1.4(a) shows how we can separate

single cells (inside the red polygon gate) from the doublets (outside of the red polygon

gate). Cell viability dyes, e.g., amine reactive viability dyes ViViD and Aqua Blue,

are often used to separate dead cells from live cells [11]. Live cells are shown with

a red polygon gate in Fig. 1.4(b) and dead cells outside of the gate are discarded

from further analysis. Furthermore, boundary events can also be removed from the

histogram of total ﬂuorescence as shown in Figure 1.4(c). Cells outside of the read

vertical lines are either too dim or too bright in terms of the total ﬂuorescence emission

and can be removed as outliers. Several other preprocessing steps are occasionally

performed as part of quality control, for example see the discussion in [12].

1.3.2 Spectral unmixing (compensation)

Flow cytometry measures the abundance of protein markers in a cell by the ﬂu-

orescence intensities of the ﬂuorophore-conjugated antibodies bound to the target

7

Figure 1.4. Removing unintended events from an FC sample. (a) Single
intact cells (inside the red polygon gate) are separated from the doublets
(outside of the red polygon gate). (b) A viability marker (ViViD) is used
to remove dead cells (outside of the red polygon gate). (c) Cells emitting
very low or very high ﬂuorescence signals (outside of the read vertical
lines) are removed as potential outlying events.

proteins. Because of the overlap of ﬂorescence spectra emitted by diﬀerent ﬂuo-

rophores, a detector intended for a particular marker also captures partial emissions

from other ﬂuorophores. The correct signal at each detector is then recovered by a

process called the Spectral unmixing or compensation [13, 14].

To see how a simple spectral unmixing method works, consider an FC system

measuring the emission of p ﬂuorophores with p detectors. Then the general form of

the compensation system is given by the following equation:

o = Ms + a,

(1.1)

where,

o = vector of the observed signals at p detectors.

M = p × p spillover matrix. The oﬀ-diagonal element M[i, j] denotes the con-
tribution of the jth ﬂuorochrome to the detector of the ith ﬂuorochrome. The

diagonal elements represent the fraction of signal found in the appropriate chan-

nel. Each column of the matrix adds to unity.

s = vector of original signal emitted from the p ﬂuorochromes.

FSHeightFSArea050000100000150000200000250000050000100000150000200000250000ViViDFSArea050000100000150000200000250000012345(b)removedeadcells(a)removedoubletsSumoffluorescenceDensity0e+004e+058e+050e+003e−066e−06(c)removeboundaryevents8

Figure 1.5. (a) A pair of correlated channels due to the overlap of the
corresponding ﬂuorochrome spectra. (b) The same pair of channels after
signals are unmixed from each other.

a = autoﬂuorescence vector of length p measuring the amount of background

ﬂuorescence.

The goal of the spectral unmixing is to calculate the actual signal vector s. The

simplest and widely used algorithm performing compensation is a straightforward

application of linear algebra that requires the solution of a linear system of equations

involving the spillover matrix M : [14, 15]:

s = M−1 × (o − a)

(1.2)

For example, Fig. 1.5(a) shows a pair of correlated channels due to the overlap of the

corresponding ﬂuorochrome spectra. The correlation is removed after the signals are

unmixed from each other by Eq. 1.2, as illustrated in Fig. 1.5(b). The accuracy of

the reconstructed signal, however, depends on the nature of errors generated by the

ﬂuorescence emission process and photo-electric circuitry of the ﬂow cytometer. The

error model can be approximated by a mixture of Poisson and Gaussian noise [15,16],

a more accurate compensation scheme is discussed by Novo et al. [15].

1.3.3 Data transformation and variance stabilization

After performing initial pre-processing, FC data is often transformed for proper

visualization and subsequent analysis. Various nonlinear functions are typically

CD8−ECDCD4−PE0.00.51.01.52.02.50123CD8−ECDCD4−PE012−0.50.00.51.01.5spectralunmixing(a)(b)9

used for this purpose, such as logarithm, hyperlog, biexponential, asinh transforma-

tions [17–20]. These transformations are aimed primarily to resolve cell populations

uniformly and to allow unimpeded visual interpretation especially by using a series

of 2-D FC scatter plots. However, owing to the nature of photon-counting statistics,

variance of a ﬂuorescence signal monotonically increases with the average signal inten-

sity (average protein expression). This signal-variance dependence creates problem

in uniform feature extraction and comparing cell populations with diﬀerent levels of

marker expressions. To remove the correlation between signal and variance, variance

stabilization (VS) is performed.

Variance stabilization (VS) [21, 22] is a process that decouples signal from the

variance such that the variance become approximately constant along the complete

range of ﬂuorescence intensities. In FC, VS can be achieved by transforming data

with properly tuned transformation parameters. Several past works followed this

approach of parameter optimization, but mostly with an objective to maximize the

likelihood of individual cell populations being generated by a mixture of multivariate-

normal distributions on the transformed scale [23, 24]. To remove the correlation

between signal and variance, I developed a variance stabilization (VS) method called

ﬂowVS that decouples signal from the variance by an inverse hyperbolic sine (asinh)

transformation function whose parameters are estimated by a likelihood-ratio test. I

will discuss variance stabilization for FC samples in more detail in Chapter 2.

1.3.4 Identifying cell populations (gating or clustering)

For a given set of markers, a cell population or cell cluster is a subset of cells in

a sample with similar physical and ﬂuorescence characteristics, and thus biologically

similar to other cells within the subset but distinct from those outside the subset. In

conventional FC practice, trained operators identify cell populations by visualizing

cells in a collection of two-dimensional scatter plots. This is traditionally a manual

process known as “gating” in cytometry. However, with the ability to monitor large

10

numbers of cellular features simultaneously, the visualization-based approach is inad-

equate to identify high-dimensional populations. To address this problem, a number

of researchers have proposed several customized clustering algorithms to identify cell

populations in FC samples. These algorithms include model-based clustering [25–27],

density based clustering [28, 29], spectral clustering [30] and other non-parametric

approaches [31]. The FlowCAP consortium (http://ﬂowcap.ﬂowsite.org/) designed a

set of challenges with an aim to identify the best clustering algorithms for diﬀerent

FC datasets and Aghaeepour et. al. [32] provides a state-of-the-art summary of the

ﬁeld.

Automated population identiﬁcation is a pivotal step in the FC data analysis.

Given the availability of a large collection of software packages for solving the cluster-

ing problem, it is not always trivial to select the best option to analyze a particular

dataset, especially when no “ground truth” or “gold standard” is available. In this

situation various cluster validation methods can be used to evaluate the quality of

diﬀerent clustering solutions from which the best option can be picked [33, 34]. How-

ever, it has been shown that an ensemble clustering computed from a consensus of a

collection of simple clustering solutions often outperforms any individual algorithm

for FC data [32]. Finding an optimal ensemble clustering is an NP-hard problem and

diﬀerent heuristics are often used to obtain an approximate solution [35]. Consider-

ing the importance of the clustering problem, I describe a new consensus clustering

algorithm that maintains a hierarchy of clustering solutions from diﬀerent algorithms.

This algorithm provides a new perspective of ensemble clustering to the FC commu-

nity. I will discuss diﬀerent clustering algorithms and a novel consensus clustering

algorithm in Chapter 3.

1.3.5 Registering cell populations across samples

Phenotypically distinct cell populations often respond diﬀerently upon perturba-

tion or change of biological conditions. This changed response results in increased

11

protein expression in each cell, or in changes in the fraction of cells belonging to a

cell type. To identify the population-speciﬁc changes, we register cell clusters across

diﬀerent samples [27,36]. The population registration problem can be solved by com-

puting a similarity measure between each pair of cell clusters across samples and

matching clusters with high similarity. Additionally, when biologically meaningful

labels for clusters are known for a sample, a population matching algorithm can label

clusters from another sample, thus solving the population labeling problem as well.

In conventional FC practice, population registration is often performed by map-

ping 2-D projections of clusters. However, the visual mapping is inadequate for high-

dimensional data. Recently two diﬀerent types of algorithms have been proposed in

order to solve the population registration problem automatically and eﬃciently. In

the ﬁrst approach, the centers of diﬀerent clusters are “meta-clustered” (cluster of

clusters) and the clusters whose centers fall into same meta-cluster are marked with

same label [23]. The second approach computes a biologically meaningful distance

between each pair of clusters across samples and then matches similar clusters by

using a combinatorial matching algorithm [27, 37]. I developed an algorithm of the

second type, called the mixed edge cover (MEC) algorithm [36, 37]. The MEC algo-

rithm uses a robust graph-theoretic framework to match a cluster from a sample to

zero or more clusters in another sample and thus solves the problem of missing or

splitting populations as well. I discuss more about the cluster matching algorithms

in Chapter 4.

1.3.6 Meta-clustering and templates

A ﬂow cytometry dataset often consists of samples belonging to a few represen-

tative classes representing multiple experimental conditions, disease or vaccination

status, time points etc. Towards this end, I assume that samples belonging to a

particular class are more similar (given a biologically meaningful similarity measure)

among themselves than samples from other classes. In this scenario it is more eﬃ-

12

cient to summarize a collection of samples with a few representative templates, each

template representing samples from a particular class [23, 27, 36]. Thereby, overall

changes across multiple conditions can be determined by comparing the cleaner and

fewer class templates rather than the large number of noisy samples themselves.

A template is usually constructed by matching similar cell clusters across samples

and combining matched clusters into meta-clusters. Clusters in a meta-cluster rep-

resent the same type of cells and thus have overlapping distributions in the marker

space. Therefore, the meta-clusters represent generic cell populations that appear in

most samples with some sample-speciﬁc variation. A template is a collection of rela-

tively homogeneous meta-clusters commonly shared across samples of a given class,

thus describing the key immunophenotypes of an overall class of samples in a formal,

yet robust, manner.

In my dissertation,

I have developed a hierarchical matching-and-merging

(HM&M) algorithm that builds templates from a collection of samples by repeat-

edly merging the most similar pair of samples or partial templates obtained by the

algorithm thus far [36]. A meta-cluster within a template represents a homogeneous

collection of cell populations and acts as a blueprint for a particular type of cell.

However, traditional null hypothesis based signiﬁcance testing (e.g., F-test or paired

t-test) often has a high probability of making a Type I error when used to evaluate

the homogeneity of a meta-cluster because of large cluster sizes. Hence, to evaluate

meta-cluster homogeneity, I propose the ratio of between-cluster to within-cluster

variance (relative cluster separation, φ), in a MANOVA model, as an alternative

method to evaluate the homogeneity of a meta-cluster. I will discuss meta-clustering

and template construction algorithm in detail in Chapter 5.

1.3.7 Classifying FC samples

Besides their use in high-level visualization and cross-class comparisons, templates

can be employed to classify new samples with unknown status. Templates work

13

as prototypes of diﬀerent biological classes, e.g., disease status, time points etc.,

by emphasizing the common properties of the class while omitting sample-speciﬁc

details. A new sample with unknown class label is predicted to come from a class

whose template the sample is most similar to. The template-based classiﬁcation is

robust and eﬃcient because it compares samples to cleaner and fewer class templates

rather than the large number of noisy samples themselves. While classifying new

samples, the templates can be dynamically updated to incorporate the information

gained from the classiﬁcation of the new samples. This approach makes it possible

to summarize the data from each laboratory using templates for each class, and

then to merge the templates and template-trees across various laboratories, as the

data is being continuously collected and classiﬁed. I will discuss the template-based

classiﬁcation algorithms in detail in Chapter 6.

1.4 The need for automation in FC data analysis

FC data is large, continuous, high-dimensional, and perturbed by Poisson and

Gaussian noise as we measure various features of individual cells for millions of intact

cells in a sample. Traditionally, after some semi-automated preprocessing, cell pop-

ulations are identiﬁed by visualizing cells as a collection of two-dimensional scatter

plots. The reader will ﬁnd it helpful to refer the Figure 3.3(b) in Chapter 3 for an

example where four types of immune cells are identiﬁed using ﬁve cluster of diﬀeren-

tiation (CD) proteins. A trained operator then visually compares these biaxial plots

from diﬀerent samples, registers populations across samples from multiple conditions

(healthy vs. disease for example) and studies the diﬀerences across conditions to

extract necessary biological information.

Recent advances in FC technology pose challenges to the traditional manual anal-

ysis in three aspects: (1) high-dimensionality of data, (2) large volume of data, and

(3) compute-intensive analysis. First, cell populations deﬁned in higher dimension

are diﬃcult to locate in 2-D projections. Furthermore, biaxial plots assume that the

14

axes are orthogonal to each other; however, often there are correlations between these

protein markers, and these are diﬃcult to analyze using biaxial projections. Second,

it is laborious and often infeasible to manually analyze an FC dataset with hundreds

of samples, each with millions of multi-parametric cells. Third, several analysis steps

require numerical calculations such as optimization of nonlinear functions and solu-

tions of matrix equations. However, a collection of tools designed to perform speciﬁc

functions but not to work together does not improve the overall analysis of FC data,

because a signiﬁcant amount of time is spent in ﬁnding appropriate tools for each

step, in identifying optimum parameters for the selected tools and, in processing

data between diﬀerent steps. Therefore, to prevent the data analysis from being the

bottleneck in scientiﬁc discovery based on cytometry, an automated and systematic

cytomics pipeline is necessary.

Even though a rich set of computational tools is available for other ﬂuorescence-

based technologies such as the microarrays [38], they can not be directly applied – as a

black box – to analyze FC data because of the technological diﬀerences. Microarrays

measure the expression of a large number of genes under diﬀerent conditions, whereas

FC measures a smaller number of proteins characteristic of a few immunophenotypes,

across a large number of samples. As a result, the objectives of various analysis steps

are often diﬀerent for these two technologies. For example, between-samples vari-

ances across a large number of genes are stabilized in microarray, whereas I stabilize

within-population variances across a collection of samples in FC. Another example

of their diﬀerence is in data clustering, where multi-parametric cells are clustered

to identify functional cell populations in FC; in contrast, genes are clustered based

on their expression patterns in microarray. In summary, the nature of the data, its

pre-processing, statistical treatment, and algorithms for downstream analysis are all

substantially diﬀerent for FC and other ﬂuorescence-based technologies. Therefore,

a customized pipeline adapted to the properties of FC data is necessary, especially

to keep up with the ever increasing dimensionally and large number of samples gen-

erated routinely in FC experiments. To address this need, recently there has been

an inﬂux of automated tools for analyzing FC data [27, 32, 39, 40]. The algorithms

and software developed in my PhD work are the latest additions to the attempt of

15

automating FC data analysis.

1.5 Contributions

This dissertation has four major contributions to computational cytometry: (a)

algorithms, (b) software, (c) biological applications, and (d) publications.

Algorithms: This dissertation addresses the need to analyze the large volume of

multi-parametric FC data by developing an algorithmic pipeline called ﬂowMatch [41].

The pipeline contains six algorithmic modules performing six steps of FC data anal-

ysis: (1) spectral unmixing to remove the eﬀect of overlapping ﬂuorescence channels,

(2) stabilizing variance to decouple signals from noise, (3) robust clustering of cells

to identify phenotypic populations, (4) registering cell clusters across samples from

multiple conditions, (5) constructing templates by preserving the common expression

patterns across samples, and (6) classifying samples based on the measured pheno-

types.

In addition to these six steps, the pipeline has several helper functions for

preprocessing and visualizing FC data.

Figure 1.6 displays the schematic view of six functional modules of the ﬂowMatch
pipeline. An FC sample is represented by an n × p matrix, where n is the number of
cells and p is the number of features (physiological properties and expression levels of

markers) measured in each cell. Subﬁg. 1.6(1) shows the overlap of two spectra (green

and yellow) emitted by two ﬂuorochromes. The yellow band pass ﬁlter captures a

signiﬁcant amount of signal from the green spectrum, which must be compensated

(e.g., by Eq. 1.2) to correctly reconstruct the signal form the yellow ﬂuorochrome.

Subﬁg. 1.6(2) displays the density plots of a single marker from several samples of

a dataset after stabilizing the variance. Observe that the variances (width) of the

density peaks (both positive and negative peaks across samples) are nicely stabilized.

Subﬁg. 1.6(3) shows the application of a clustering algorithm to a three dimensional

16

Figure 1.6. An FC data analysis pipeline. (1) unmixing of spectra to re-
move the eﬀect of overlapping ﬂuorescence channels, (2) stabilizing vari-
ances by transformation and normalization, (3) identifying cell popula-
tions by automated clustering algorithm in a high-dimensional marker
space, (4) registering cell populations across samples with a matching al-
gorithm, (5) representing a class of samples with high-level templates, and
(6) classifying samples by using the templates.

sample, where diﬀerent colors denote four phenotypically distinct cell populations.

In Subﬁg. 1.6(4), I show how functionally similar cell clusters are matched by a

population registration algorithm, where same colors are used to mark the matched

clusters. The next Subﬁg. 1.6(5) illustrates how a template is created by a hierarchical

algorithm from six samples belonging to the same class. Finally, the classiﬁcation

of a new sample based on its similarity with two class templates is described in

Subﬁg. 1.6(6).

Software: I have developed algorithms for the last ﬁve steps of the pipeline except

the spectral unmixing step. I included spectral unmixing and other related prepro-

cessing tools from related packages to make this pipeline as complete as possible. I

have developed an R package flowMatch [41,42] by implementing the steps discussed

in Fig. 1.6 in both R and C++ programming languages. This package has been made

available through Bioconductor [43] (http://www.bioconductor.org/).

I hope that

An FC samplef1…fpcell-1a11…a1p………cell-nan1…anp1. Spectral unmixing2. Variance stabilization3. Population identification4. Matching  cell populationsSamples: class ASamples: ASamples: BTBTANew sampleto classify5. Building high-level templatesTemplate (A)meta-clusters6. Sample classification17

ﬂowMatch will be a useful addition to the available FC data analysis tools and can

contribute to faster analysis of large FC datasets.

Biological applications: The ﬂowMatch pipeline contains several combinatorial

and statistical algorithms used to perform diﬀerent steps of data analysis. The com-

plete analysis is usually divided into a series of encapsulated sub-problems and each

of them is solved by a module of the pipeline.

I demonstrated the application of

diﬀerent steps of the pipeline with three data sets: healthy donor data, T cell phos-

phorylation data, and acute myeloid leukemia (AML) data. The healthy donor (HD)

dataset consists of 65 ﬁve-dimensional samples from ﬁve healthy individuals who do-

nated bloods on diﬀerent days. I use this dataset to demonstrate that by stabilizing

within-cluster variance we are able to construct homogenous meta-clusters despite the

presence of biological, temporal, and technical variations. The T cell phosphorylation

(TCP) dataset consists of 29 pairs of samples before and after stimulation with an

anti-CD3 antibody [44]. I analyzed the data in order to demonstrate that templates

can be created from multiple conditions and the meta-clusters can be matched across

experimental conditions (before and after stimulation) to assess the overall changes in

phosphorylation experiment. The acute myeloid leukemia (AML) dataset consists of

samples from 43 AML patients and 217 healthy individuals. I used ﬂowMatch pipeline

to build healthy and AML templates, to identify AML markers, and to classify AML

samples by comparing test samples against the two templates [45].

I describe the

datasets in Section1.6 in more detail. In the past, I have also tested diﬀerent com-

ponents of ﬂowMatch to solve problems in evaluating HIV vaccination success, and

detecting correlations among multiple sclerosis (MS) treatments.

Publications: The algorithms with their biological applications developed in this

dissertation have been published to several peer-reviewed journals [32, 36] (Nature

Methods, BMC Bioinformatics) and conferences [37, 46] (e.g., WABI, ACM BCB,

GLBIO, SIAM LS, Cyto, etc.). Several papers are submitted for publication [41, 45].

The ﬂowMatch pipeline was one of the top performers to solve several challenges

designed by the FlowCAP consortium at National Institute of Healthy (NIH). I have

18

developed several multithreaded algorithms for computing the maximum cardinality

matching in large graphs, which are published in several conference proceedings (SC,

IPDPS, IPDPSW) [47–49]. Aside from this dissertation, I have also developed a

robust variant of residual resampling technique for computing the uncertainty in

evolutionary trees and illustrated its use with an analysis of genome-scale alignments

of yeast [50, 51].

Diﬀerence from related work: ﬂowMatch is similar to the GenePattern Flow Cy-

tometry Suite in terms of the coverage of distinct algorithms for diﬀerent analysis

steps. However, these two pipelines are signiﬁcantly diﬀerent from each other on how

each step of the pipeline is performed. For example, GenePattern normalizes FC sam-

ples by aligning density peaks on each channel as described by Hahne et al. [52]. In

contrast, ﬂowMatch stabilizes variances of the density peaks on each channel without

shifting the signals. Likewise, other steps of the ﬂowMatch pipeline are signiﬁcantly

diﬀerent from the corresponding steps in the GenePattern Flow Cytometry Suite.

The primary diﬀerence between ﬂowMatch and other FC data analysis tools (dis-

cussed in Section 1.7) is that I consider a collection of FC sample related to each other

and analyze them collectively. For example, I characterize a group of similar samples

with representative templates and use templates in between-class comparison, clas-

siﬁcation, and other overall biological conclusions. In contrast, most of the existing

tools analyze samples individually and only make sample-speciﬁc conclusions. Finally,

ﬂowMatch is not an exhaustive pipeline and I plan to include other functionalities

into the pipeline in future.

1.6 Datasets used in this thesis

1.6.1 Healthy donor (HD) dataset

The healthy donor (HD) dataset represents a “biological simulation” where pe-

ripheral blood mononuclear cells (PBMC) were collected from ﬁve healthy individuals

on up to four diﬀerent days. Each sample was divided into ﬁve parts and analyzed

through a ﬂow cytometer at Purdue’s Bindley Biosciences Center. Thus, we have ﬁve

technical replicates for each sample from a subject, and each replicate was stained

using labeled antibodies against CD45, CD3, CD4, CD8, and CD19 protein markers.

I show a summary of the HD dataset in Fig. 1.7.

19

Figure 1.7. Description of the healthy donor (HD) dataset. The distri-
bution of samples across subject is shown in the left and the functions of
scatter and ﬂuorescence channels are described in the right.

The HD dataset includes three sources of variations: (1) technical or instrumental

variation among replicates of the same sample, (2) within-subject temporal (day-to-

day) variation, and (3) between-subject natural or biological variation. The dataset

contains 13 replicated groups, with each group containing ﬁve copies of the same

sample. Hence, the variation among ﬁve replicates within each replicated group orig-

inates from the technical variation in sample preparation, instrument calibration and

sample measurement in the ﬂow cytometer. The within-subject temporal variation

reﬂects the environmental impact on the immune system on diﬀerent days when the

blood was drawn from a subject. Finally, samples from diﬀerent subjects have natural

between-subject variations. Diﬀerent sources of variations present in the HD dataset

mate it an ideal case to demonstrate the functionality of the ﬂowMatch pipeline.

1.6.2 T cell phosphorylation (TCP) dataset

I reanalyze a T cell phosphorylation (TCP) data set from Maier et al. [44] to deter-

mine diﬀerences in phosphorylation events downstream of T cell receptor activation

SubjectsNumberofdaysbloodcollectedTotalsamplespersubjectTotalsamplesSubjectA31565SubjectB15SubjectC420SubjectD315SubjectE210ChannelNameFunctionFSForwardScatterSSSideScatterCD45Leukocyte markerCD3TlymphocytemarkerCD19BlymphocytemarkerCD4HelperTcellmarkerCD8CytotoxicTcellmarker20

in naive and memory T cells. For each of the 29 subjects in this study, whole blood

was stained using labeled antibodies against CD4, CD45RA, SLP-76 (pY128), and

ZAP-70 (pY292) protein markers before stimulation with an anti-CD3 antibody, and

another aliquot underwent the same staining procedure ﬁve minutes after stimulation.

The ﬁrst two markers (CD4, CD45RA) are expressed on the surface of diﬀerent T

cell subsets and the last two (SLP-76 and ZAP-70) are highly expressed after T cells

are phosphorylated [44].

During the stimulation anti-CD3 antibody binds with T cell receptors (TCR) and

activates the T cells, initiating the adaptive immune response. The binding with

TCR induces dramatic changes in gene expression and cell morphology, and induces

the formation of a phosphorylation-dependent signaling network via multi-protein

complexes. ZAP-70 is a kinase that phosphorylates tyrosine in a trans-membrane

protein called LAT, and LAT and SLP-76 are part of a platform that assembles

the signaling proteins [53]. I reanalyzed this dataset in order to demonstrate that

computationally meta-clusters are preserved across experimental conditions (before

and after stimulation) when the homogeneity of meta-clusters is preserved.

The AML dataset is discussed in Chapter 7.

1.7 Related work

Recent advances in FC technology have led to an inﬂux of automated tools to

analyze FC data [27, 32, 39, 40]. However, many of the automated tools solve a small

subset of the problems arising in FC data analysis. For example, spectral unmix-

ing (compensation) is discussed in [13–15] and various data transformation methods

are discussed in [17–20, 23, 24]. Automated gating or clustering is arguably the most

discussed problem in FC data analysis [26, 27, 31, 32] and Aghaeepour et al. [32] pro-

vides a state-of-the-art summary of the ﬁeld. Cluster matching and meta-clustering

have been studied only recently by [23, 27], but have received relatively less atten-

tion from the researchers. Other general-purpose and problem-speciﬁc methods are

21

also discussed in the literature [54–58]. A number of the aforementioned tools are

implemented as free, open-source R packages such as ﬂowCore [59], ﬂowViz [60], ﬂow-

Clust [61], ﬂowTrans [23], ﬂowStats [62], ﬂowType [54] and other packages available

through Bioconductor [43].

Recently Spidlen et al. introduced a web-based FC data analysis pipeline called

“GenePattern Flow Cytometry Suite” (http://www.genepattern.org) that includes 34

open-source modules performing preprocessing, normalization, gating, cluster match-

ing and other post-processing steps [39]. ﬂowMatch is similar to the GenePattern

Flow Cytometry Suite in terms of the problem it solves, but signiﬁcantly diﬀerent on

how each step is performed. For example, GenePattern normalizes FC samples by

aligning density peaks on each channel as described by Hahne et al. [52]. In contrast,

I stabilize variances of the density peaks on each channel without shifting the signals.

Likewise, other steps of the ﬂowMatch pipeline are signiﬁcantly diﬀerent from the

corresponding steps in the GenePattern Flow Cytometry Suite.

To the best of my knowledge, there is no other software tool that would pro-

vide a comprehensive pipeline for FC data analysis. However, a few software tools,

most of them commercial,

integrate one or two steps of the complete analysis

pipeline. For example, the Immunology Database and Analysis Portal (ImmPort,

https://immport.niaid.nih.gov) integrates the FLOCK software that performs nor-

malization and density based clustering [63]. Cytobank [40] is a web-based applica-

tion focusing mainly on the organization and storage of cytometry data. Finally, most

of the major commercial third party software vendors, including Tree Star, De Novo

Software, and Verity Software House, oﬀer computational tools for certain steps of the

FC data analysis. However, all these tools solve only a few steps of the overall com-

putational analysis with limited support for the other steps. I hope that ﬂowMatch

will be a useful addition to the available FC data analysis tools and can contribute

to faster analysis of FC datasets.

22

1.8 Outline of the thesis

This thesis describes various computational aspects of analyzing ﬂow cytometry

data. I have developed a systematic pipeline, ﬂowMatch containing ﬁve functionally

distinct modules for analyzing large volume of multi-parametric FC data. These ﬁve

algorithmic modules are discussed in ﬁve chapters of this thesis.

In Chapter 2, I

describe ﬂowVS, a method for stabilizing variance in FC data by transforming each

channel with nonlinear functions. Chapter 3 discusses several basic and two con-

sensus clustering algorithms and explains how multiple cluster validation indices can

simultaneously be optimized to select the “best” clustering algorithm and algorith-

mic parameters. Chapter 4 discusses a robust mixed edge cover (MEC) algorithm

for registering (labeling) cell clusters across samples. The next Chapter 5 discusses a

hierarchical matching-and-merging (HM&M) algorithm that summarizes a collection

of similar samples with templates consisting of several homogeneous meta-clusters.

I discuss how the templates are used to classify new samples in a dynamic fashion

in Chapter 6. Chapter 7 discusses algorithms for classifying and immunophenotyp-

ing the acute myeloid leukemia (AML). Concluding remarks and future directions of

research are presented in Chapter 8.

23

2 VARIANCE STABILIZATION IN FLOW CYTOMETRY

2.1 Introduction

In this chapter, I discuss ﬂowVS – a novel method for stabilizing within-population

variances across ﬂow cytometry (FC) samples. ﬂowVS stabilizes variance by trans-

forming FC samples with the inverse hyperbolic sine (asinh) function whose parame-

ters are optimized to homogenize the within-population variances. Variance stabiliza-

tion (VS) is a data-transformation process for dissociating data variability from the

mean values. In ﬂow cytometry, the purpose of VS is to decouple biological signals

(usually measured by average marker expressions of cell populations) from diﬀerent

sources of variations and noise so that only biologically signiﬁcant eﬀects are detected.

Variance inhomogeneity is an inherent problem in ﬂuorescence-based FC mea-

surements and is a bottleneck for automated multi-sample comparisons. The origin

of the problem is the ﬂuorescence signal formation and the detection process that

monotonically increases the variance of the ﬂuorescence signal with the average sig-

nal intensity [15, 16]. Due to such signal-variance dependence, a cell population (a

cluster of cells with similar marker expressions) with higher level of protein expressions

(i.e., higher ﬂuorescence emission) has higher variance than another population with

relatively low level of protein expressions (i.e., low ﬂuorescence emission). This in-

homogeneity of within-population variance creates problems with extracting features

uniformly and comparing cell populations with diﬀerent levels of marker expressions.

Furthermore, detecting statistically signiﬁcant changes among populations, such as in

an analysis of variance (ANOVA) model, explicitly requires that variance be approx-

imately stabilized in populations. By removing mean-variance dependence from FC

data, VS makes it possible to detect biologically and statistically meaningful changes

across populations from diﬀerent samples.

24

VS is an explicit preprocessing step for other ﬂuorescence-based technologies such

as the microarrays [22, 64–66]. However, unlike microarray data, explicit VS is of-

ten not performed in FC data analysis. Traditionally, FC data is transformed with

nonlinear functions to project cell populations with normally distributed clusters – a

choice that usually simpliﬁes subsequent visual analysis [17–20, 23, 26]. Recently Fi-

nak et al. used the maximum likelihood approach [23] with diﬀerent transformations

to explicitly satisfy normality of the cell populations. Ray et al. [24] transformed

each channel with the asinh function whose parameters are optimally selected by the

Jarque-Bera test of normality (a goodness-of-ﬁt test of whether sample data have the

skewness and kurtosis matching a normal distribution). While these transformations

approximately normalize FC data, they might not stabilize the variance.

The VS problem in FC, however, cannot be solved directly by applying the mature

VS techniques from the microarray literature. In microarrays, each gene is measured

multiple times (possibly under multiple conditions) and the between-sample variance

for each gene is stabilized with respect to the average expression of the gene across

samples. In contrast, variance is deﬁned by within-population, cell-to-cell variation

in FC and this within-population variance is stabilized with respect to the average

expression of markers within each population. These contrasting objectives prevent

us from applying VS methods from microarray literature directly to ﬂow cytometry.

I address the need for explicit VS in FC with a maximum likelihood (ML) based

method, ﬂowVS, which is built on top of a commonly used asinh transformation.

The choice of asinh function is motivated by its success as a variance stabilizer for

microarray data [22,66]. ﬂowVS stabilizes the within-population variances separately

for each marker (ﬂuorescence channel) z across a collection of N samples. After

transforming z by asinh(z/c) (c is a normalization cofactor), ﬂowVS identiﬁes one-

dimensional clusters (density peaks) in the transformed channel. Assume that a

total of m 1-D clusters are identiﬁed from N samples with the ith cluster having

variance σ2

i . Then the asinh(z/c) transformation works as a variance stabilizer if
2 ∼ ... ∼ σ2
m.

the variances of the 1-D clusters are approximately equal, i.e., σ2

1 ∼ σ2

25

To evaluate the homogeneity of variance (also known as homoskedasticity), I use

Bartlett’s likelihood-ratio test [67]. From a sequence of cofactors used with the asinh

function, ﬂowVS selects one with the “best” VS quality computed by Bartlett’s test.

ﬂowVS is therefore an explicit VS method that stabilizes within-cluster variances in

each marker/channel by evaluating the homoskedasticity of clusters with a Likelihood-

ratio test.

I show, with a ﬁve-dimensional healthy dataset, that ﬂowVS removes the mean-

variance dependence from raw FC data and makes the within-population variance

relatively homogeneous. Such variance homogeneity is especially useful to build meta-

clusters from a collection of phenotypically similar cell populations across samples.

Previous studies (Hahne et al. [52], for example) shifted the distribution of each

ﬂuorescence channel to ensure homogeneity in meta-clusters, but such artiﬁcial shift-

ing may hide useful biological signals. By contrast, ﬂowVS builds homogeneous

meta-clusters from variance-stabilized clusters without losing the biological diﬀer-

ences among samples. I will discuss the impact VS on comparisons among samples

(with related concepts of meta-clusters and templates) in Chapter 5.

The rest of the chapter is organized as follows. I start with a short Section 2.2 on

related work and the current transformation techniques employed in FC. In Section

2.3 I describe ﬂowVS, a method for stabilizing variance of FC data. The next Section

2.4 describes applications of this VS technique to an FC dataset and a microarray

dataset. I conclude this Chapter in Section 2.5 by discussing limitations of ﬂowVS

and possible future work.

2.2 Related work

From the beginning of the twentieth century, VS has been widely studied for its

central role in making heteroskedastic data easily tractable by standard methods.

Heteroskedasticity appears in various datasets mostly because the data follows a

distribution with correlated mean and variance, e.g., the Poisson distribution. For

26

well-known distribution families, VS is usually performed by transforming data with

an analytically chosen function f . For example, f (z) =(cid:112)z + 3/8 works as a good

(asymptotic) stabilizer for a random variable z following the Poisson distribution

[68]. Variance stabilizers for several well-known distribution families are described

in [68, 69]. For unknown distributions, heuristic and data-driven stabilizers are often

used, e.g., see [21, 70, 71].

However, traditional transformations are often inadequate for low-count (photon

limited) signals [22,72] because of unknown error patterns in ﬂuorescence data. Hence

various ad hoc variance stabilization schemes have been developed for diﬀerent types

of ﬂuorescence data. In microarrays, the VS problem has been addressed by vari-

ous non-linear transformations [22, 64–66]. Most notably, the widely used approach

by Huber et al. [22] uses the inverse hyperbolic sine (asinh) transformation whose

parameters are selected by a maximum-likelihood (ML) estimation.

For ﬂow cytometry data, researchers have used various non-linear transformations,

such as the logarithm, hyperlog, generalized Box-Cox, and biexponential (e.g., logicle

and generalized arcsinh) functions [17–20, 23, 26]. In the past work, the parameters

of these transformations were adjusted in a data-driven manner to maximize the

likelihood (ﬂowTrans by Finak et al. [23]), to satisfy the normality (ﬂowScape by Ray

et al. [24]), and to comply with simulations (FCSTrans by Qian et al. [73]). ﬂowTrans

estimates transformation parameters for each sample by maximizing the likelihood of

data being generated by a multivariate-normal distributions on the transformed scale.

ﬂowScape optimizes the normalization factor of asinh transformation by the Jarque-

Bera test of normality. FCSTrans selects the parameters of the linear, logarithm,

and logicle transformations with an extensive set of simulations. In contrast to these

approaches that transform a single sample, ﬂowVS transforms a collection of samples

together for stabilizing within-population variations. Note that normalizing data may

not necessarily stabilize its variance, e.g., for a Poisson variable z, (cid:112)z + 3/8 is an

approximate variance-stabilizer, whereas z2/3 is a normalizer [21].

27

2.3 Variance stabilization for ﬂow cytometry data

2.3.1 The goal of variance stabilization

The aim of variance stabilization (VS) in FC is to make within-population vari-

ances of diﬀerent cell populations approximately equal and thereby independent of

the average protein expressed by populations. Recall that the expression of a protein

is measured by the intensity of a channel capturing the ﬂuorescence of a particular

wavelength. VS therefore stabilizes the within-population ﬂuorescence variance and

makes it independent of the mean ﬂuorescence intensities (MFI) of the cell popula-

tions. In this context, I use the terms “a ﬂuorescence channel” and “a protein marker”

equivalently because we infer information about the latter through the signal collected

at the former. However, I will use “ﬂuorescence channel” more frequently because the

nature of ﬂuorescence emissions – not the protein expressions – dominates the mean-

variance relationship in FC data. I do not stabilize variance on the scatter channels

because, as pointed out by Finak et al. [23], there are few beneﬁts to transforming

forward and side scatter channels.

2.3.2 Channel-speciﬁc variance stabilization

I assume that compensated ﬂuorescence channels are independent and stabilize

variance on each channel (a column of the data matrix) separately. Besides be-

ing simple, one-dimensional VS prevents unnecessary correlation among transformed

channels incurred by multi-dimensional VS. Note that the correlations among ﬂuores-

cence channels due to spectral overlap are compensated before we stabilize variance.

Even though the protein expressions can still be correlated [18], I do not include such

correlations in the VS process because the nature of such problem-speciﬁc correlation

is diﬃcult to model.

Since the actual error model of FC data is unknown, it is not trivial to select

a function to transform this data. Even though researchers have studied a number

28

of normalization functions, they are often selected arbitrarily [23, 24]. Considering

the similarity in ﬂuorescence-based data collections between FC and microarrays, I

decided to use an inverse hyperbolic sine (asinh) function that has been shown to

successfully stabilize variance in ﬂuorescence readouts from microarray data [22, 66].

This choice of asinh function is also motivated by its success in FC data visualization

and normalization [23, 24]. Stabilizing variance with other transformations can be

performed using the same ﬂowVS framework but is not discussed here.

To transform a ﬂuorescence channel z, I use the asinh transformation with a single

parameter c:

asinh(z/c) = ln(z/c +(cid:112)(z/c)2 + 1).

(2.1)

In this transformation, c is called the normalization cofactor whose value is optimally

selected to stabilize variance in channel z. Let σ2

ij be the variance of the ith cluster
deﬁned in channel/marker z in the jth sample. My objective is to select a cofactor

for the asinh transformation such that after transforming channel z in each sample,

variance σ2

ij of every cluster becomes approximately homogeneous.

In a more general form, asinh transformation is expressed with three parame-
ters, a ∗ asinh(b + z/c), where in addition to the cofactor c, a denotes a scaling after
transformation, and b denotes a translation before transformation. I set a = 1 since

other values do not aﬀect downstream analysis, and b = 0 to avoid shifting of cell

populations. Hence I am left with a single parameter, c, that I aim to set in order to

stabilize the variance. Note that other transformations such as logarithmic, hyper-

log [17], logicle [18], Box-Cox [26] etc., may also stabilize the variance but a detailed

analysis covering all these transformations is out of the scope of this study.

2.3.3 ﬂowVS : an algorithm for per-channel variance stabilization

Given a collection of N FC samples, the ﬂowVS algorithm stabilizes the variance

in a ﬂuorescence channel z with the following steps.

29

1. Selecting a sequence of cofactors: I select an evenly spaced increasing sequence

of cofactors c1, c2, ..., cl to be used with the asinh transformation. The start and

end values (c1 and cl) are empirically selected so that the sequence includes a

variance stabilizing cofactor.

2. Transforming data and evaluating homoskedasticity for each cofactor: For each

cofactor cq ∈ {c1, c2, ..., cl}, the following steps are performed.

(a) Transforming channel/marker z in each sample: Let zj be a vector de-
noting the selected channel in the jth sample where 1 ≤ j ≤ N . The
algorithm transforms zj by the asinh function: z(cid:48)
j = asinh(zj/cq), where z(cid:48)
is the same channel after the transformation.

j

(b) Detecting 1-D density peaks (1-D clusters): I estimate the density of each

transformed ﬂuorescence vector z(cid:48)
The peaks in the density of z(cid:48)

j by a kernel density estimation method.

j are identiﬁed as regions of high local den-

sity and signiﬁcant curvature (also called landmarks in [52]). To identify

the 1-D density peaks, ﬂowVS uses the curv1Filter function from the

flowCore package [59] in R. Here a density peak represents a 1-D cluster

of cells and therefore can also be identiﬁed by a clustering algorithm [54].
Let Pj be the collection of density peaks identiﬁed from z(cid:48)
j.

(c) Collecting density peaks from all sample: Density peaks from all samples
are collected into a set P such that P = ∪1≤j≤N Pj. Let P contain a total
of m density peaks where the ith peak contains ni cells with mean µi and

variance σ2
i .

(d) Testing homoskedasticity: The performance of the asinh transformation

with cofactor cq is evaluated by a test of variance homogeneity (ho-

moskedasticity). For this purpose, I use Bartlett’s test [67], a well-known

likelihood-ratio test for homoskedasticity. Assuming n = (cid:80)

1≤i≤m ni to
p to be the pooled variance of m

be the total number of cells in P and σ2

density peaks, I compute Bartlett’s statistics as follows:

p) −(cid:80)m
(cid:16)(cid:80)m

i=1

(cid:17)
i=1(ni − 1) ln(σ2
i )
ni−1 − 1
n−m

1

(n − m) ln(σ2

1 + 1

3(m−1)

B(cq) =

30

.

(2.2)

Bartlett’s statistics B(cq) computes the degree of homogeneity across all

1-D clusters in channel z after it is transformed by asinh(zj/cq).

3. Finding a cofactor for optimum VS: The optimum variance stabilization is

achieved by a transformation giving minimum value of Bartlett’s statistics.

Therefore, the asinh transformation with the cofactor

cq∗ = arg

l

min
q=1

B(cq),

(2.3)

gives the optimum VS for the channel/marker z. Channel zj in each sample is

then transformed by asinh(zj/cq∗) and used in subsequent analysis.

2.4 Results

I demonstrate how the ﬂowVS algorithm stabilizes variance with the HD dataset

described in Section 1.6.1. Recall that the HD dataset consists of 65 samples from ﬁve

healthy individuals who donated blood samples on diﬀerent days. Each sample was

divided into ﬁve replicates and each replicate was stained using labeled antibodies

against CD45, CD3, CD4, CD8, and CD19 protein markers. Before variance stabi-

lization each sample is preprocessed, compensated for spectral overlap, and gated on

FS/SS channels to identify lymphocytes. Since lymphocytes always express CD45

protein (CD45 is a common leukocyte marker), I omit this marker from the rest of

the discussion.

2.4.1 Selecting the optimum cofactors for the asinh transformation

For each sample of the HD dataset, the ﬂowVS algorithm identiﬁes density peaks

in CD3, CD4, CD8, and CD19 markers/channels by following step 2(b) in Sec-

tion 2.3.3. In each of these four channels, the algorithm identiﬁes two density peaks

31

Figure 2.1. Mean Fluorescence Intensity (MFI) of each 1-D cluster is plot-
ted against the variance of the cluster for diﬀerent choice of cofactors used
with the asinh transformation. Clusters in each marker are shown with
the same symbol and color.
(a) no transformation: variance increases
monotonically with the mean, (b) small cofactor: VS is not achieved, (c)
reasonable value of cofactor (same for all channels): mean-variance depen-
dence remains except for CD4 channel/marker, and (d) optimal values of
cofactors: variance is approximately stabilized for each marker/channel.

representing high-expressing (“positive”) and low-expressing (“negative”) cell popu-
lations (e.g., CD3−, CD3+ clusters in the CD3 marker/channel). Therefore, from the
65 samples in the HD dataset, I obtain 130 (65 × 2) 1-D clusters for each marker,
giving a total of 520 (65× 2× 4) 1-D clusters in CD3, CD4, CD8, and CD19 channels.
For each of these 520 clusters, I compute the within-cluster variance and av-

erage marker expression (Mean Fluorescence Intensity, MFI). Figure 2.1 plots the

mean-variance relationship for every cluster (density peak) before transforming the

channels and after they are transformed by asinh function with diﬀerent cofactors.

In this ﬁgure, clusters identiﬁed in channels transformed with diﬀerent cofactors are

shown in diﬀerent panels and in each panel, clusters in a marker are shown with

the same symbol and color. Subﬁg. 2.1(a) reveals the non-linear correlation between

(a) No Transformation(b) Cofactor = 1(c) Cofactor = 10,000(d) Cofactor = optimal0.0e+005.0e+081.0e+091.5e+092.0e+09012340.000.050.100.150.000.050.100.150.200.250e+005e+041e+05−5051001230123Mean Fluorescence Intensity (MFI) VarianceMarkers:  CD19   CD3   CD4   CD8   32

Figure 2.2. Finding the optimum values of the cofactors in asinh trans-
formation for each ﬂuorescence channel in the HD dataset.

cluster variance and mean, which is typically observed in raw FC data before ap-

plying any transformation. The mean-variance dependence is not alleviated after

transforming the data by asinh function with arbitrary cofactors as can be seen in

Subﬁg. 2.1(b,c). Finally, Subﬁg. 2.1(d) shows that the variances of the 1-D clusters

become approximately stabilized and independent of the means after the optimum
variance stabilization is performed. On CD3 marker, for example, CD3−, CD3+ clus-

ters (shown by green triangles in Subﬁg. 2.1(d)) have approximately stable variances

and no visible correlation exists between the variances and the cluster means.

The optimum cofactor for the asinh transformation is selected by minimizing

Bartlett’s statistics separately for each of the four markers. Figure 2.2 shows Bartlett’s

statistics computed in each channel after it has been transformed by asinh function

with a sequence of cofactors. A minimum is observed for every channel and the

cofactor is set to the value of the minimizer of Bartlett’s statistics. The variance

stabilizing cofactors for diﬀerent markers are: (a) 5,000 for CD8, (b) 6,000 for CD19,

(c) 7,000 for CD3, and (d) 10,000 for CD4. Therefore, the channels of the HD

dataset are transformed by asinh function with the optimum cofactors. As shown

in Subﬁg. 2.1(d), the optimum transformations approximately stabilize variances in

diﬀerent channels.

I plot the density of the variance stabilized channels in Fig. 2.3, where diﬀerent

colors are used to denote the samples from ﬁve diﬀerent subjects. In Fig. 2.3, both

positive and negative density peaks (clusters with high or low marker expression)

CD3CD4CD8CD190e+002e+054e+056e+052.0e+054.0e+056.0e+058.0e+051.0e+061.2e+061e+052e+053e+054e+055e+051e+052e+053e+054e+055101520510152051015205101520Cofactor in asinh transformation ( x 1000)Bartlett's test statistics33

Figure 2.3. Density plot of the variance stabilized channels across all
samples in the HD dataset. Diﬀerent colors used for samples from diﬀerent
subjects.

spread approximately equally across all samples, conﬁrming the homogeneity of vari-

ances in one dimensional clusters. For this dataset, the density curves from the same

subjects are tightly grouped together as expected. However, clusters across subjects

may not be well aligned due to the between-subject variations. Aligning density

peaks across samples – as was done by Hahne et al. [52] – is not an objective of the

VS algorithm, because such shifting of density may potentially eclipse true biological

signals across samples.

2.4.2 Normality of the variance-stabilized clusters

In addition to stabilizing the variances, the transformed channels approximately

follow the normal distribution. To see this, I draw the Quantile-Quantile plots (Q-

Q plots) [74] for eight 1-D clusters obtained from a representative sample in the

HD dataset in Figure 2.4.

In each Q-Q plot, the distribution of a 1-D cluster is

compared with the standard normal distribution by plotting their quantiles against

each other. If a cluster is normally distributed (i.e., linearly related to the standard

normal distribution), the points in the Q-Q plot approximately lie on a straight line.

All eight Q-Q plots in Fig. 2.4 show linearity in their central parts, except small

deviations at the ends, indicating that the 1-D clusters approximately follow normal

distributions with heavier tails. As I will discuss in Section 5.3, the normality of

34

Figure 2.4. The Q-Q plots for the eight 1-D clusters obtained from a
representative sample in the HD dataset. Every Q-Q plot shows linearity
in the central part, except for a little deviation at the end, indicating that
the clusters approximately follow a normal distributions with heavier tails.

clusters is a desired condition for the analysis of variance (ANOVA) model used to

evaluate the homogeneity of a collection of similar clusters, also known as a meta-

cluster.

2.4.3 Application to microarray data

The VS approach based on optimizing Bartlett’s statistics can also be used to

stabilize variance in microarray data. However, the initial steps of ﬂowVS need to

be adapted for microarrays. Assume that the expressions of m genes are measured

from N samples in a microarray experiment. After transforming the data by the

asinh function, the mean µi and variance σ2

i of the ith gene gi are computed from
the expressions of gi in all samples. ﬂowVS then stabilizes the variances of the genes

by transforming data using the asinh function with an optimum choice of cofactor.

Unlike FC, a single cofactor is selected for all genes in the microarray data.

I have applied the modiﬁed ﬂowVS to the publicly available Kidney microarray

data provided by Huber et al. [22]. The Kidney data reports the expression of 8704

35

(a) Selecting optimum cofactor for ﬂowVS

(b) VS by diﬀerent methods

Figure 2.5. (a) For Kidney microarray data [22], ﬂowVS selects the opti-
mum cofactor for the asinh transformation by minimizing Bartlett’s statis-
tics. The cofactors are shown in the natural logarithm scale. (b) The
standard deviation and mean of each gene from the Kidney data are plot-
ted before transformation and after variance stabilization by ﬂowVS, VSN,
and DDHFm. Loess regression is used to smoothen the curves.

genes from two neighboring parts of a kidney tumor by using cDNA microarray tech-

nology. For diﬀerent values of the cofactor, ﬂowVS transforms the Kidney data with

the asinh function and identiﬁes the optimum cofactor by minimizing Bartlett’s statis-

tics. Subﬁg. 2.5(a) shows that a minimum value of Bartlett’s statistics is obtained
when the cofactor is set to exp(6) (∼ 400). The optimum cofactor is then used with
the asinh function to transform the Kidney data.

I compare the VS performance of ﬂowVS with two software packages, VSN by

Huber et al. [22] and DDHFm by Motakis et al. [75]. Similar to ﬂowVS, VSN uses

asinh transformation whose parameters are optimized my maximizing a likelihood

function [22]. DDHFm applies a data-driven Haar-Fisz transformation (HFT) [75, 76]

to stabilize the variance. Both VSN and DDHFm are developed for stabilizing variance

in microarray data and can not be applied to ﬂow cytometry data.

Before transforming the Kidney data and after transforming it by ﬂowVS, VSN,

and DDHFm, I plot the mean and standard deviation of every gene in Subﬁg. 2.5(b).

0510152070008000900011000Cofactor of asinh transformation (log scale)Bartlett's Statistics0.00.20.40.60.81.00.000.020.040.060.080.10Mean expression by a geneStandard deviationNo TransformationVS by flowVSVS by VSNVS by DDHFm36

Figure 2.6. Variance stabilization of the Kidney microarray data [22] by
(a) ﬂowVS and (b) VSN [22]. Each black dot plots the standard deviation
of a gene against the rank of its mean. The red lines depict the running
median estimator. If there is no mean-variance dependence, then the red
lines should be approximately horizontal.

In this ﬁgure, I have applied a loess regression to obtain smooth average curves. We

observe in Subﬁg. 2.5(b) that the standard deviation of the untransformed Kidney

data increases monotonically with the mean. Both VSN and ﬂowVS approaches

stabilize the variance approximately for all genes in this data. However, the Haar-

Fisz transformation achieves good VS properties only for genes with higher levels of

expressions.

To take a closer look at the transformed data by ﬂowVS and VSN, I plot the

variances of the genes against the ranks of the means with two subﬁgures in Fig. 2.6.

These ﬁgures are generated by meanSdPlot function from the VSN package. Here,

the ranks of the means distribute the data evenly along the x-axis and thus make it

easy to visualize the homogeneity of variances. Both VSN and ﬂowVS remove the

mean-variance dependence since the red lines are approximately horizontal in both

Subﬁg. 2.6(a) and Subﬁg. 2.6(b). Therefore, ﬂowVS performs equally well compared

to the state-of-the-art approach developed for the microarray data.

37

2.5 Conclusions

I describe a variance stabilization framework, ﬂowVS, that removes the mean-

variance correlations observed in cell populations from ﬂow cytometry samples. This

framework transforms each marker/channel by the asinh function whose normaliza-

tion cofactor is optimally selected by Bartlett’s likelihood-ratio test.

I show, with

a ﬁve-dimensional healthy dataset consisting of 65 FC samples, that ﬂowVS re-

moves the non-linear mean-variance dependence from raw FC data and makes the

within-population variances relatively homogeneous across all populations. ﬂowVS

also performs comparably to the state-of-art variance stabilization approaches for the

microarray data.

Variance homogeneity (homoskedasticity) is a desirable property for comparing

populations across conditions, building meta-clusters from phenotypically similar pop-

ulations, and analyzing meta-clusters in an ANOVA model. However, unlike the

earlier approach by Hahne et al. [52], ﬂowVS does not artiﬁcially shift populations

to align them in the marker space. By stabilizing the variances, ﬂowVS homoge-

nizes similar cell populations and establishes the foundation of biologically meaningful

meta-clusters and templates as will be discussed in Chapter 5.

The VS framework presented here has several limitations. First, ﬂowVS stabilizes

variance separately in each marker/channel. This approach is inadequate to stabilize

covariances across multiple channels, which is necessary when channels are correlated.

Second, ﬂowVS repeatedly identiﬁes 1-D cell clusters (density peaks) and evaluates

the homogeneity of clusters by the likelihood-ratio test. Therefore, this framework

does not perform well when cell clusters are not easily identiﬁable. Third, ﬂowVS

stabilizes variance more accurately when more samples are simultaneously passed to

the framework. Hence, the approach is not suitable for normalizing a single sample or

stabilizing variances of sequentially arriving samples. Note that we stabilize between-

sample variances in microarray data; therefore, VS can not performed on a single

microarray sample. Finally, Bartlett’s test used in ﬂowVS assumes that the deviation

38

from normality is relatively modest.

If data deviates signiﬁcantly from normality,

other likelihood ratio tests can be employed, such as Levenes test [77] or the Brown-

Forsythe test [78]. However, I tested ﬂowVS with several FC datasets and in every

case Bartlett’s test outperforms the Levenes and Brown-Forsythe tests in selecting

variance stabilizing trnasformations.

ﬂowVS operates as an independent module in the FC data analysis pipeline. It

does not depend on the preprocessing algorithms applied before VS nor on the post-

analysis methods such as matching, meta-clustering, and classiﬁcation algorithms.

Hence, ﬂowVS is capable of working with other downstream algorithms developed

by other researchers, such as FLAME by Pyne et al. [27] and ﬂowTrans by Finak et

al. [23].

39

3 POPULATION IDENTIFICATION BY CLUSTERING ALGORITHMS

3.1 Introduction

In this chapter, I discuss clustering algorithms for identifying phenotypically dis-

tinct cell clusters in a ﬂow cytometry (FC) sample. These algorithms partition a

multidimensional sample into several phenotypic clusters such that cells within a

cluster are biologically similar to each other but distinct from those outside the clus-

ter. A phenotypic cell cluster usually represents a particular sub-type of cells with

speciﬁc biological function and often called a cell population in ﬂow cytometry. Ana-

lyzing cellular functions at the level of populations instead of individual cells conveys

more robust biological information because of the natural variations within cells of

the same type. Therefore, identifying cell populations from the mixture of diﬀerent

cell-types turns into an important step in any FC data analysis pipeline.

Traditionally, cell populations are identiﬁed by a manual process known as “gat-

ing”, where cell clusters are recognized in a collection of two-dimensional scatter

plots (see Fig. 3.3(b) for an example). However, with the ability to monitor a large

number of protein markers simultaneously and to process a large number of sam-

ples with a robotic arm, manual gating is not feasible for high-dimensional or high-

throughput FC data. To address the gating problem, researchers have proposed

several automated clustering algorithms, such as CDP [25], FLAME [27], FLOCK [28],

flowClust/Merge [26, 79], flowMeans [31], MM [80], curvHDR [81], SamSPECTRAL [30],

SWIFT [82], RadialSVM [83], etc. For a summary of these algorithms, see Table 1

of [32]. Aghaeepour et al. [32] provides a state-of-the-art summary of the ﬁeld.

Diﬀerent algorithms perform better

for diﬀerent FC datasets as was

observed in a set of

challenges organized by the FlowCAP consortium

(http://flowcap.flowsite.org/) [32]. Given the large number of algorithmic op-

40

tions, it is often diﬃcult to select the best algorithm for a particular dataset. When

the “ground truth” or “gold standard” about the clustering pattern is unavailable,

we can evaluate the quality of a clustering solution with the cluster validation meth-

ods [33, 34]. The validation methods evaluate how well a given partition captures the

natural structure of the data based on information intrinsic to the data alone. They

can be used in selecting the optimum parameters for a clustering algorithm (e.g., the

optimum number of clusters), as well as choosing the best algorithm for a dataset.

I describe several cluster validation methods that can evaluate the quality of the

clustering solution given by an algorithm. In general terms, there are three major

cluster validation approaches based on external, internal, and relative validation cri-

teria [33, 34]. The internal validation techniques evaluate how well a given partition

captures the natural structure of the data based on information intrinsic to the data,

and therefore suitable to select optimum parameters for a clustering algorithm.

I

discuss ﬁve popular internal cluster validation methods and show that they can be

simultaneously optimized to select the algorithm with the best performance on an

FC sample as well as the parameters with the algorithm.

If an agreement among the validation methods can not be reached when choosing

an algorithm, we use a consensus of several clustering solutions [32,84]. I present two

heuristic algorithms that compute consensus clusterings from a collection of partitions

(cluster ensembles). The ﬁrst heuristic approach is called Clue developed by Hornik et

al. [35,84], while the second heuristic approach is flowMatch developed by myself [36].

Using a representative sample, I show that consensus clustering performs better than

the individual algorithms under diﬀerent cluster validation methods. The superior

performance of consensus clustering was also observed in [32], where the consensus

clustering by Clue [84] outperformed the “best performing” algorithm based on their

similarities with the manual (visual) gating (when evaluated by an external validation

method called the F-measure).

The rest of the chapter is organized as follows. In Section 3.2, I discuss several

simple clustering algorithms that can be used as oﬀ-the-shelf tools to cluster FC

data. Section 3.3 discusses diﬀerent cluster validation methods. The next Section 3.4

discusses the two heuristic algorithms for constructing a consensus clustering from

a collection of partitions (cluster ensembles). In Section 3.5, I demonstrate diﬀerent

aspects of clustering algorithms with two FC samples from two separate datasets. I

41

conclude the chapter in Section 3.6.

3.2 Clustering algorithms

Clustering (automated gating) is arguably the most researched topic in compu-

tational cytometry [25–28, 31, 32, 58, 79–83, 85]. A state-of-the-art summary of this

ﬁeld is discussed by Aghaeepour et al. [32]. These algorithms often take few parame-

ters whose values must be set appropriately to obtain good clustering solutions. For

example, the spectral clustering package SamSPECTRAL [85] takes two arguments (in

addition to other arguments), (a) normal.sigma – a scaling parameter that deter-

mines the“resolution” in the spectral clustering stage and (b) separation.factor –

a threshold controlling clusters separation. To obtain a good clustering solution from

SamSPECTRAL, these two parameters need to be selected carefully for every dataset.

As a second example, the simple and fast algorithm flowMeans [31] also depends on a

parameter MaxN that inﬂuences the quality of clustering. I will show how the selection

of parameter inﬂuences clustering solution, with an example in Section 3.5.1.

The algorithms discussed in FC literature are built on top of a few fundamen-

tal algorithms, such as the k-means, Gaussian mixture modeling, spectral clustering,

hierarchical clustering, etc. [33]. Here, I move one step back to see how the basic

algorithms perform, in a completely unsupervised setting, in clustering FC samples.

For this purpose, I selected six popular algorithms whose eﬃcient implementations

are available as open-source packages. The algorithms, their computational complex-

ity, and the R packages that implement them are listed in Table 3.1. K-means is a

popular algorithm that partitions n observations into k clusters in which each obser-

vation belongs to the cluster with the nearest mean [86,87]. Clara (Clustering LARge

42

Table 3.1

Several clustering algorithms are listed along with their complexity and
the R packages implementing them.
In the complexity, n denotes the
number of cells in a sample and p idenotes the number of features (di-
mension) measured pre cell. The parameter l is the number of iterations
required before an algorithm converges. For Clara, m denotes the number
of subsamples and s denotes the number of items in each subsample.

Clustering algorithm Computational complexity R package

K-means [86, 87]

Clara (PAM) [88]

Hclust [33]

GMM [90]

SOTA [92]

Spectral [93, 94]

O(nl)

O(n + ms2)

O(n2)

O(nl)

O(n log n)

O(n3)

stats [96]

cluster [97]

fastcluster [89]

Rmixmod [91]

clValid [98]

kernlab [99]

Applications) is a sampling based algorithm that creates a collection of m subsam-

ples of size s from n observations. Once k representative objects have been selected

from the sub-dataset, each observation of the entire dataset is assigned to the nearest

medoid [88]. Hclust is a hierarchical clustering algorithm that builds a hierarchy of

data points into k clusters. Here, I used the Unweighted Pair Group Method with

Arithmetic Mean (UPGMA) method [33, 89]. GMM is the Gaussian mixture mod-

eling algorithm that models a sample with a mixture of k normal distributions and

assigns observations into k Gaussian components by the Expectation-Maximization

(EM) algorithm [90, 91] . The Self Organizing Tree Algorithm (SOTA) uses an unsu-

pervised neural network with a binary tree topology and recursively divides clusters

with the largest diversity until k clusters remain [92]. The spectral clustering works

by embedding the data points into the subspace of the k largest eigenvectors of a

normalized aﬃnity/kernel matrix [93, 94]. An informative discussion about diﬀerent

clustering algorithms can be found in [95].

43

I apply each of the six algorithms to cluster an FC sample. For slower algorithms,

such as the spectral clustering, I downsample the data into a smaller size so that the

algorithms ﬁnish in a reasonable amount of time. I always use the default arguments

of these algorithms except the number of clusters k. However, I often perform a

second phase to estimate the statistical parameters of the clusters identiﬁed by the

clustering algorithms. For this purpose, I characterize an FC sample with a mixture of

k normally distributed clusters of p-dimensional points. Each cluster is characterized

by a multi-dimensional normal distribution and is represented by two parameters µ,
the p-dimensional mean vector, and Σ, the p × p covariance matrix [26]. To estimate
the parameters of k clusters, I use the Expectation-Maximization (EM) algorithm [90].

3.3 Cluster validation methods

Clustering is an unsupervised process of identifying phenotypically similar cell

populations from an FC sample. When clustering patterns and the number of clusters

are not known a priori, the clustering solution is evaluated for quality assurance

[33, 34, 100]. Cluster validation usually answers questions like “how well does the

resulting partition ﬁt the data?”, “how many clusters are there in a sample?”, and

“from a collection of algorithms, which algorithm provides the best partition?”.

In general terms, there are three major cluster validation approaches based on

external, internal, and relative validation criteria [33,34]. External validation methods

evaluate a clustering result based on an a priori knowledge of correct class labels

or the “gold standard”.

Internal validation techniques evaluate how well a given

partition captures the natural structure of the data based on information intrinsic to

the data alone. Relative validation methods compare two partitions to identify their

relative diﬀerences. While external and relative validation techniques depend on some

benchmarking or “gold standard”, internal validation methods do not depend on any

prior knowledge. Given the limited number of “gold standards” in ﬂow cytometry,

internal validation is the most practical approach for most FC dataset, and it is

44

the focus of my discussion. However, occasionally prior human interpretation (e.g.,

manual gating) is available for a subset of samples of an FC dataset [32].

In this

scenario, I discuss the application of external cluster validation methods brieﬂy in

the latter part of this section. The following discussion is limited to validating hard

clustering where each data item is assigned to exactly one cluster. Evaluation methods

for fuzzy clustering are discussed in [100–102].

3.3.1 Internal cluster validation methods

Consider an n × p data matrix A storing n p-dimensional observations. In ﬂow
cytometry, A represents a biological sample measuring p features from n cells. Let

d(x, y) be the Euclidean distance between two data items, x and y. I use d2(x, y) to

denote the squared Euclidean distance between x and y. Assume that A is partitioned
into k clusters C = {c1, c2, ..., ck}, where the ith cluster ci contains |ci| data items
with mean µi.

Most internal cluster validation methods use the concepts of within-cluster com-

pactness and between-cluster separation. The former concept minimizes the intra-

cluster distances, while the latter maximizes the between-cluster distances. In the

discussion on internal validation methods, I use ∆(ci) to denote the intra-cluster dis-

tance of a cluster ci and D(ci, cj) to denote the between-cluster distance from ci to cj.

Diﬀerent cluster validation methods deﬁne the intra- and inter-cluster distances dif-

ferently. Based on these deﬁnitions, I discuss ﬁve popular internal cluster validation

methods that I use to evaluate automated gating of FC samples.

Calinski-Harabasz (CH) Index: Calinski and Harabasz [103] deﬁned the intra-

cluster distance ∆(ci) of a cluster ci as the sum of squared distances from each data
item x ∈ ci to the cluster center µi. They deﬁned the separation D(ci) of cluster ci
as the squared distance between the center µi and the overall center µ of the entire

sample. Then the Calinski-Harabasz (CH) index [103] is deﬁned as the ratio of the

average cluster separation to the average within-cluster distance.

45

(n − k) (cid:80)
(k − 1) (cid:80)

ci∈C

ci∈C

D(ci)

∆(ci)

.

(3.1)

(cid:88)

x∈ci

∆(ci) =

d2(x, µi), D(ci) = |ci| d2(µi, µ),

CH =

A large value of the CH index denotes larger separation among clusters relative to
the average within-cluster distance. The CH index is limited to the interval [0, +∞]
and should be maximized. The time needed to compute the CH index is O(n + k),

which is linear in the number of data points, and thus faster for large data matrices.

Dunn’s Index: Dunn deﬁned the intra-cluster distance ∆(ci) of a cluster ci as the
maximum distance between pairs of data items x, y ∈ ci and the between-cluster
distance D(ci, cj) for a pair of clusters ci and cj as the minimum distance over all
pairs of data items x ∈ ci and y ∈ cj. Dunn’s index [104] then measures the ratio of
the smallest between-cluster distance to the largest intra-cluster distance.

(cid:18)

d(x, y),

∆(cl) = max
x,y∈cl
1
(∆(cl)

Dunn =

max
cl∈C

D(ci, cj) = min

x∈ci,y∈cj

(cid:19)

d(x, y),

(3.2)

min

ci,cj∈C,ci(cid:54)=cj

D(ci, cj)

.

Dunn’s index is limited to the interval [0, +∞] and should be maximized. The time
complexity for computing Dunn’s index is O(n2 + k2), which reduces to O(n2) for

bounded k. Therefore, Dunn’s index is computationally expensive when the data

matrix is large.

Average Silhouette Width (ASW): Let a(xi) be the average distance from the ith

data item xi to all other data items within the same cluster, and let b(xi) be the

lowest average distance from xi to a cluster to which xi does not belong. Then the

silhouette width of xi is computed as follows:

S(xi) =

b(xi) − a(xi)

max{b(xi), a(xi)}.

(3.3)

The Average Silhouette Width (AWS) of the partition C is computed by averaging
S(xi) over all data items [105]. The AWS is limited to the interval [−1, 1] and should

46

be maximized. The time to compute the AWS is O(n2), and similar to Dunn’s index,

it is computationally expensive when the data matrix is large.

Davies-Bouldin Index: Davies and Bouldin [106] deﬁned the intra-cluster distance

∆(ci) of a cluster ci as the square root of the average squared distance from each
data item x ∈ ci to the cluster center µi. They deﬁned the between-cluster distance
D(ci, cj) for a pair of clusters ci and cj as the distance between their clusters centers

µi and µj. Then the Davies-Bouldin index is deﬁned as follows:

(cid:40)

(cid:88)

x∈ci

1
|ci|

(cid:41)1/2

∆(ci) =

d2(µi, x)

, DB =

(cid:88)

ci∈C

1
k

max
cj∈C
ci(cid:54)=cj

(cid:26)∆(ci) + ∆(cj)

(cid:27)

.

(3.4)

d(µi, µj)

The Davies-Bouldin index is limited to the interval [0, +∞] and should be minimized.
The time to compute the Davies-Bouldin index is O(n + k2), which is linear in the

number of data points. Therefore it is faster to compute for large data matrices.

S Dbw Index: Let σ2(ci) be a p-dimensional vector whose qth component σ2

q (ci)
contains the variance of data items x ∈ ci in the qth dimension. Also let σ2 be a
p-dimensional vector whose qth component σ2
q contains the variance of data items
from all clusters in the qth dimension. Then the average intra-cluster distance ∆(C)

of the partition C is computed as follows:

(cid:40)(cid:88)

(cid:41)1/2

,

(cid:107)σ2(ci)(cid:107)

(3.5)

∆(C) =

1
k

ci∈C

where (cid:107).(cid:107) is the L2 norm. Assume that the density ρ(ci) of the cluster ci is deﬁned as
the number of data points that lie within a hyper-sphere centered at µi with ∆(C)

(3.6)

(3.7)

as the radius.

ρ(ci) =

(cid:88)

x∈ci

f (x, µi), where

f (x, µi) =

0,

if d(x, µi) > ∆(C)

1, otherwise

The average inter-cluster density can be computed as

ρ(C) =

1

k(k − 1)

ρ(ci ∪ cj)

max{ρ(ci), ρ(cj)} ,

(cid:88)

ci,cj∈C

Table 3.2

Summary of the cluster validation indices.
In the complexity, n is the
number of data points in a sample and k is the number of clusters. The
dimension of a sample p is omitted from the calculation of complexity.

47

Cluster validation methods

Calinski-Harabasz [103]

Dunn [104]

Average Silhouette Width [105]

Davies-Bouldin [106]

S Dbw [107]

O(n + k)

Range Optimization Time complexity
[0, ∞]
[0, ∞]
[-1, 1]
[0, ∞]
[0, ∞]

O(n2 + k2)

O(n + k2)

minimize

minimize

maximize

maximize

maximize

O(n2)

O(nk2)

where ρ(ci ∪ cj) is the density computed after merging ci and cj and then using
Eq. 3.6. The S Dbw index [107] is then deﬁned as the summation of the normalized

intra-cluster distance and average inter-cluster density:

S Dbw =

(∆C)2
(cid:107)σ2(cid:107) + ρ(C).

(3.8)

The S Dbw index is limited to the interval [0, +∞], and should be minimized. The
time to compute the S Dbw index is O(nk2), which is linear in the number of data

points, and can be computed fast for large data matrices.

Table 3.2 gives a summary of these ﬁve internal cluster validation methods. Be-

sides these ﬁve internal cluster validation methods, several other methods have also

been proposed in the literature, such as Ball-Hall [108], C [109], Ray-Turi [110],

Scott-Symons [111], and other indices. The papers [34, 95, 112] provide more details.

Diﬀerent cluster validation methods are also implemented in several R packages such

as clv [113], clValid [114], clusterCrit [115].

3.3.2 External cluster validation methods

Unlike internal cluster validation methods, external methods evaluate a clustering

result based on a prior knowledge of correct class labels or the “gold standard”. In

48

FC, we often seek completely unsupervised clustering because of the unavailability

of “gold standards”. However, occasionally prior human interpretation (e.g., manual

gating ) is available for a subset of a larger FC dataset [32]. Then the external cluster

validation methods can be applied to evaluate the consensus between the clustering

solution provided by an algorithm and the known “ground truth”.

In ﬂow cytometry, F-measure [116] is a commonly used external method to eval-

uate the closeness of a partition to the “gold standard” or manual gating. Assume
that C = {c1, c2, ..., ck} is a set of clusters computed by a clustering algorithm while
T = {t1, t2, ..., tl} is a set of true clusters of the same sample. Then, precision is the
number of data points in the computed cluster cj that belong to the correct cluster

ti and recall is the number of data points in the true cluster ti that are recovered by

the computed cluster cj. The F-measure F (ti, cj) between ti and cj is the harmonic
mean of precision and recall. Let |ti| and |cj| be the number of data points in ti
and cj respectively and |ti ∩ cj| be the number of points belonging to both ti and
cj simultaneously. Then the precision, recall, and F-measure between ti and cj are

deﬁned as follows.

Precision(ti, cj) =
F (ti, cj) = 2 · Precision(ti,cj ) · Recall(ti,cj )

Precision(ti,cj )+Recall(ti,cj )

Recall(ti, cj) =

|ti∩cj|
|cj|

,

|ti∩cj|
|ti|

(3.9)

The overall F-measure for the partitioning C with respect to T is computed as

F (T, C) =

|ti|
n

{F (ti, cj)},

max
cj∈C

(3.10)

(cid:88)

ti∈T

where n is the number of data points in the sample.

Several other external cluster validation methods were also proposed in the lit-

erature, such as Rand index [117], Jaccard coeﬃcient [118], Minkowski score [119],

Fowlkes-Mallows index [120], etc. External cluster validations based on combinatorial

optimization have also been used, such the R-metric, transfer distance or partition dis-

tance that computes the minimum number of augmentations and removals of points

needed to transform one partition into another [121–124]. Note that the external clus-

ter validation approaches always compare two partitions of the same sample. These

49

methods are used to compare the quality of a clustering algorithm relative to the

“gold standard” and to compare the performance of multiple algorithms applied to

the same sample. However, they cannot be used to compute the dissimilarity between

partitions from two diﬀerent samples. In Chapter 4, I will discuss a combinatorial

algorithm for computing dissimilarities between a pair of partitions from diﬀerent

samples.

3.3.3 Selecting the number of clusters (cell populations)

Most clustering algorithms take the number of clusters k as an input and assign
the data points into k clusters. However, the optimum number of clusters k∗ is often

not known in unsupervised clustering problems. Especially in FC, the number of phe-

notypically distinct cell populations may not be known in advance. In this situation,

a clustering algorithm is run for diﬀerent number of clusters in a range [kmin, kmax].

The clustering quality for each k is then computed by internal cluster validation meth-
ods and an optimum number of clusters k∗ is selected by maximizing/minimizing the

validation indices. For example, the values of avg. silhouette width (ASW), Calinski-

Harabasz (C-H), and Dunn indices are maximized and Davies-Bouldin and S Dbw

indices are minimized to obtain the optimum number of clusters. However, if diﬀer-
ent cluster validation methods disagree with each other about k∗, a consensus (e.g.,
majority voting) of them is used to select k∗.

3.3.4 Selecting the “best” algorithm

Given a collection of algorithms, which algorithm should we use to cluster a sample
for the selected optimum number of clusters k∗? To select an algorithm for clustering

a particular sample, I consider the following three conditions. First, if most clustering

algorithms perform equally well under all validation indices, then I select the fastest

of the better performing algorithms. Second, if an algorithm consistently performs

better than others under several validation methods, then I select the best-performing

50

algorithm. Finally, when no agreement can be reached about the best performing

algorithm because diﬀerent validation methods favor diﬀerent algorithms, I compute

a consensus of the clustering solutions provided by the algorithms.

3.4 Consensus clustering

To describe how a consensus clustering is computed, we ﬁrst need a dissimilarity

measure between a pair of partitions. Assume that a partition is deﬁned as a binary

membership matrix P such that P [i, j] = 1 if the ith object belongs to the jth cluster

and otherwise, P [i, j] = 0. Then the dissimilarity between two partitions P and Q is

deﬁned as

||P − QΠ||,

d(P, Q) = min

(3.11)
where the minimum is taken over all permutation matrices Π, and ||·|| is the Frobenius
norm (so that ||Y ||2 = tr(Y (cid:48)Y )). This dissimilarity measure computes the minimum
number of augmentations and removals of items needed to transform one partition

Π

into another and is called the transfer distance or partition distance [121–123]. The

partition distance can be computed by formulating an edge-weighted matching prob-

lem in a bipartite graph and solving it by eﬃcient combinatorial algorithms (e.g., the

Hungarian method) in O(k3) time, where k is the number of clusters in the parti-

tions [121, 122, 125].

Given a collection of partitions E (possibly generated by several algorithms), a

consensus clustering algorithm ﬁnds a new partition P such that the total dissimi-

larity between P and each partition in E is minimized [35, 126, 127]. The initial set

of partitions E is often called a cluster ensemble [35, 84]. An optimum consensus
partition P ∗ minimizes the total dissimilarity between P and each partition in the

(cid:88)

Q∈E

ensemble E:

P ∗ = argmin

P

||P − QΠ||.

min

Π

(3.12)

This optimization is an instance of multidimensional assignment problem, which is

known to be NP-hard (by reducing it to the 3-dimensional matching problem [128]).

51

Hence, various heuristics have been developed to solve the consensus clustering prob-

lem. Here I will discuss two heuristic approaches to approximately compute a con-

sensus clustering.

The ﬁrst heuristic approach is called Clue developed by Hornik et al. [35, 84].

Clue initializes the consensus partition P with a randomly selected partition from

the ensemble. In the ith iteration, the algorithm randomly selects a partition Q not

already included in the consensus clustering. The algorithm then optimally matches

the clusters between Q and Pi−1 (the consensus partition created thus far) and creates

an updated consensus partition Pi by taking a weighted average of Pi−1 and QΠi,

where Πi is the permutation matrix found by the optimum matching.

The second heuristic approach is flowMatch developed by myself [36]. flowMatch

computes the dissimilarity between partitions by a mixed edge cover (MEC) algorithm

that allows a cluster from a partition to be matched to zero or more clusters in

another partition [37]. Let N be the number of partitions in the ensemble E.

In

each iteration, the flowMatch algorithm ﬁnds the most similar pair of partitions,

merges them into an intermediate consensus partition and continues. The merging

is performed by matching clusters across two partitions and collapsing the matched

clusters into meta-clusters. Let P be the consensus-partition with K meta-clusters

created by the above algorithm. The collection of these meta-clusters then deﬁnes

the consensus partition. I will discuss this algorithm in more detail in Chapter 4 and

Chapter 5.

3.5 Results

3.5.1 Identifying cell populations in a healthy sample

Data description: I cluster a representative sample from the HD dataset described

in Section 1.6.1. Each sample in this dataset measures the abundance of CD45, CD3,

CD4, CD8, and CD19 protein markers in peripheral blood collected from a healthy

individual. I selected a representative sample from this dataset to demonstrate diﬀer-

52

Figure 3.1. Evaluating the performance of six clustering algorithms
(shown in diﬀerent colors) by ﬁve internal cluster validation methods
(shown in diﬀerent panels). A representative 5-D sample from the HD
dataset is clustered by the algorithms for a sequence of k. Each clus-
tering solution is then evaluated by ﬁve cluster validation methods. The
optimum number of clusters, k∗ is selected by maxima in the top three
methods and by minima in the bottom two methods.

ent aspects of clustering algorithms. The selected sample is compensated to remove

the eﬀect of spectral overlap, transformed to stabilize variance, and gated on FS/SS

channels to identify lymphocytes. The preprocessed ﬁve-dimensional data is then

clustered to identify diﬀerent subsets of lymphocytes in the healthy immune system.
Selecting the optimum number of clusters (k∗): I have applied six clustering (Ta-

ble 3.1) algorithms to the 5-D healthy sample for diﬀerent number of clusters in the

interval 2-10. The range for k can be increased if the optimum solution is not found

in the selected range. Each clustering solution is evaluated by ﬁve internal cluster

validation methods described in Table 3.2. Fig. 3.1 shows the values of diﬀerent clus-
ter validation indices for diﬀerent algorithms. The optimum number of clusters k∗ is

selected by maxima in the top three methods (Calinski-Harabasz, Dunn, and Average

silhouette width) and by minima in the bottom two methods (Davies-Bouldin and

Calinski−HarabaszDunnAvg.Sil.WidthDavies−BouldinS_Dbw20004000600080000.51.01.50.00.20.41.01.21.41.60.40.60.81.0246810246810246810246810246810NumberofclustersValueoftheindicesK−meansClaraHclustGMMSOTASpectralAlgorithms53

S Dbw). Form Fig. 3.1 we observe that all validation methods unanimously indicate

k = 4 as the optimum number of clusters across all clustering algorithms except for

the spectral clustering. The spectral clustering does not perform well because a user

needs to pass a set of carefully tuned arguments to the algorithm for better perfor-
mance [85]. For this sample, I select k∗ = 4 as the optimum number of clusters as

per the consensus of the ﬁve cluster validation methods.

Researchers have proposed several ad hoc criteria to select the optimum number
of clusters k∗ for FC data. For example, the flowMeans algorithm [31] developed
by Aghaeepour et al. starts with a relatively large number of clusters (Max k) and

merges two closest clusters in each iteration. The algorithm then plots the distances
between the merged clusters at each iteration and selects the value of k∗ where a

sharp change in the segmented regression lines is observed. I cluster the same healthy

sample used in the previous paragraph by the flowMeans software package [129] for

three choices of Maximum k (parameter MaxN in flowMeans package) and plot the
results in Fig. 3.2. Observe that flowMeans algorithm selected three diﬀerent k∗
(shown by red circles) for three diﬀerent choices of initial number of clusters. Only
Fig. 3.2(b) selects the correct k∗ as unanimously suggested by ﬁve well-established

cluster validation methods in Fig. 3.1. Therefore, flowMeans algorithm depends on a
hidden parameter (Max k) when selecting k∗. flowMeans estimates the initial number
of clusters to 5 when the user does not supply it; however, Fig. 3.2(a) shows that the

auto tuning fails to identify the correct number of clusters for this sample. Hence,

I prefer using well-known cluster validation methods to select optimal number of
clusters k∗.

Selecting the “best” algorithm: Which clustering algorithm should we use to clus-

ter this sample? Fig. 3.1 shows that except for spectral clustering, all clustering

algorithms perform equally well since the validation indices have optima at k = 4.

In this case, computing a consensus clustering does not improve the quality of the

overall clustering solution because the individual clusterings from ﬁve algorithms (for

54

Figure 3.2. Selecting the optimum number of cell populations in a sample
from the HD dataset by the flowMeans package [31, 129]. The maximum
number of clusters (MaxN parameter) is set to: (a) 5 clusters (automatically
selected by algorithm), (b) 10 clusters, and (c) 20 clusters. The optimum
number of clusters is selected by detecting change point in the segmented
regression lines and is shown with a red ﬁlled circle in each subﬁgure.

k = 4) have the same quality under diﬀerent validation methods. Therefore, I select

the fastest k-means algorithm to cluster this sample.

Identifying lymphocyte sub-populations: The four clusters chosen by the k-means

algorithm represent four biologically distinct lymphocyte sub-populations deﬁned

in the ﬁve dimensional marker space. For visualization purposes, I show the cell

populations by a collection of 2-D projections in Figure 3.3(b), where cell pop-

ulations are shown in four diﬀerent colors denoting (a) red: natural killer cells
(CD45+CD3−CD19−), (b) blue: B cells (CD45+CD3−CD19+), (c) black: helper
T cells (CD45+CD3+CD4+), and (d) green: cytotoxic T cells (CD45+CD3+CD8+).

Here, every cell cluster is CD45+ because CD45 is a common leukocyte antigen present

in all lymphocytes and I pre-selected lymphocytes on the forward and side scatter

channels.

3.5.2 Identifying cell sub-populations in T cells

Data description: As a second example, I cluster a pre-stimulation sample from the

T cell phosphorylation (TCP) dataset described in Section 1.6.2. The selected sample

measures the abundance of four protein markers expressed on T cells: CD4, CD45RA,

020406080Numberofclusters(k)Distancebetweenmergedclusters5432102060Numberofclusters(k)Distancebetweenmergedclusters10864202060Numberofclusters(k)Distancebetweenmergedclusters20161284(a) Max k=5(b) Max k=10(c) Max k=2055

Figure 3.3. (a) Simultaneous optimization of ﬁve cluster validation cri-
teria (scaled to [0,1]) suggests that four cell populations are present in
the healthy sample. Here three of the indices are maximized and two
are minimized. (b) Bivariate projections of lymphocyte sub-populations:
red (natural killer cells), blue (B cells), black (helper T cells), and green
(cytotoxic T cells).

SLP-76 and ZAP-70. The ﬁrst two markers (CD4, CD45RA) are expressed on the

surface of diﬀerent T cell subsets and the last two (SLP-76 and ZAP-70) are highly

expressed after T cells are phosphorylated [44]. Since I selected a pre-stimulation

sample (for simplicity), I consider only CD4, CD45RA to identify diﬀerent subsets of

T cells by using clustering algorithms.

Selecting the optimum number of clusters (k∗): I have applied six clustering al-

gorithms to the selected 2-D sample. The algorithms were run for diﬀerent number

of clusters and each clustering solution is evaluated by ﬁve cluster validation indices.

The values of the cluster validation indices are shown in Fig. 3.4. The optimum num-
ber of clusters k∗ is selected by maxima in the top three methods (Calinski-Harabasz,

−11−202−1131234024−112−202−1130.000.250.500.751.00246810NumberofclustersClusterValidationIndicesCD45CD4CD8CD3CD19CD3CD8CD4NKCells(CD3-CD19-)BCells(CD3-CD19+)HelperTCells(CD3+CD4+)CytotoxicCells(CD3+CD8+)(b)(a)0.000.250.500.751.00246810Davies-BouldinS_DbwASWDunnC-HIndex56

Figure 3.4. A representative 2-D sample from the TCP dataset is clustered
using six clustering algorithms for a sequence of k (number of clusters).
Each clustering solution is evaluated by ﬁve cluster validation methods
(shown in diﬀerent panels). The optimum number of clusters k∗ is selected
by the maxima in the top three methods and by the minima in the bottom
two methods.

Dunn, and Average silhouette width) and by minima in the bottom two methods

(Davies-Bouldin and S Dbw). Form Fig. 3.4 we observe that all validation methods

unanimously indicate k = 4 as the optimum number of clusters across all cluster-

ing algorithms except for the spectral clustering. Therefore, for this sample, I select
k∗ = 4 as the optimum number of clusters.

Selecting the “best” algorithm: Unlike the HD sample (Fig. 3.1), the values of the
cluster validation indices are diﬀerent across the algorithms for k∗ = 4 as can be seen

in Fig. 3.4. Furthermore, diﬀerent algorithms perform best under diﬀerent validation

indices. For example, the hierarchical clustering is the best algorithm under Dunn’s

index, while K-means and Clara are the best performers under Calinski-Harabasz

index. Therefore, creating a consensus clustering is useful for this sample.

Calinski−HarabaszDunnAvg.Sil.WidthDavies−BouldinS_Dbw50001000015000200000.51.01.52.02.50.10.20.30.40.50.60.70.91.11.30.20.40.60.81.0246810246810246810246810246810NumberofclustersValueoftheindicesK−meansClaraHclustGMMSOTASpectralAlgorithms57

Figure 3.5. Five cluster validation methods are used to compare the
quality of the “best-performing” algorithms with two consensus clustering
methods (Clue and flowMatch) for a 2-D sample from the TCP dataset.
A “better” clustering solution is denoted by higher values of the ﬁrst three
indices and lower values of the last two indices.

I compute consensus solutions by two heuristic algorithms, Clue and flowMatch,

discussed in Section 3.4. The consensus clusterings are computed from the solutions

of six clustering algorithms after the number of clusters is set to four (k = 4). Once

again I evaluate the performance of the consensus clustering solutions by ﬁve cluster

validation methods whose values are scaled to [0, 1] for comparison purpose. I show

the values of the validation indices in ﬁve diﬀerent panels in Fig. 3.5. In addition to the

consensus partitions, I show the validation indices of the best-performing algorithm

under each validation method in its respective panel. According to Table 3.2, a

“better” clustering solution is denoted by higher values of the ﬁrst three indices

and lower values of the last two indices. We observe in Fig. 3.5 that the consensus

solutions perform better under four validation methods (except the Dunn’s index)

than the best performing algorithms. The consensus clustering based on flowMatch

performs slightly better than the solution based on Clue under all validation methods.

The relatively poor performance of the consensus methods under Dunn’s index

can be explained if we look closely at the deﬁnition of the within-cluster and between-

cluster distances used in Eq. 3.2. Notice that the within-cluster distance is deﬁned by

the diameter of a cluster and the between-cluster distance is deﬁned as the minimum

distance between a pair of clusters. These deﬁnitions are not robust especially in the

Calinski−HarabaszDunnAvg. Sil. WidthDavies−BouldinS_Dbw0.000.250.500.751.00Algorithms after setting k = 4Validation IndexAlgorithms Best−Algorithm Consensus−Clue Consensus−flowMatch58

Figure 3.6. The consensus clustering computed by the flowMatch al-
gorithm created from the solutions of six clustering algorithms with
k = 4. Four T cell sub-populations are shown in diﬀerent colors; black:
CD4+ CD45RAlow T cells, green: CD4+ CD45RAhigh T cells, red: CD4−
CD45RAhigh T cells, and blue: CD4− CD45RAlow T cells.

presence of outlying data items that are far apart from their cluster centers. Therefore,

Dunn’s index is less robust when evaluating the quality of robust consensus clustering

solutions.

Identifying T cell sub-populations: I select the consensus clustering by flowMatch

algorithm as the ﬁnal clustering solution for the selected TCP sample. The consensus

clustering solution for this sample is shown in Fig. 3.6, where four clusters representing

diﬀerent T cell sub-populations are shown in diﬀerent colors: (a) CD4+ CD45RAlow T
cells in black, (b) CD4+ CD45RAhigh T cells in green, (c) CD4− CD45RAhigh T cells
in red, and (d) CD4− CD45RAlow T cells in blue. Here ‘+’ and ‘high’ indicate higher
abundances of a marker, and ‘−’ and ‘low’ indicate lower levels of it. Two clusters
with high CD4 expression, CD4+ CD45RAlow and CD4+ CD45RAhigh cells, are called

the memory and naive T cells respectively. Few domains of the CD4+ cell subsets are

phosphorylated upon stimulated by anti-CD3 antibody. To study the eﬀect of this

stimulation was the main purpose of the TCP dataset generated originally by Maier

0.00.51.01.50.00.51.01.52.02.5CD4CD45RA59

et al. [44]. I will discuss algorithms to automatically detect phosphorylation changes

across pre- and post-stimulated samples in Chapter 4 and Chapter 5.

3.6 Conclusions

We can achieve better conﬁdence in a computed clustering when several algo-

rithms produce similar clusterings. I demonstrated that several simple, oﬀ-the-shelf

clustering algorithms can be used to compute more accurate and robust partition of

an FC sample than a specialized algorithm. Internal cluster validation methods can

be used to select parameters of an algorithm such as the optimal number of clusters.

More than one validation method yet again provide more conﬁdence and robustness

in model selection.

I have discussed a set of ﬁve cluster validation methods – Calinski-Harabasz, Dunn,

Average silhouette width, Davies-Bouldin and S Dbw – that can be simultaneously

optimized to select algorithm parameters, as well as the best-performing algorithm for

an FC sample. However, it is possible that diﬀerent validation methods disagree about

the best performing algorithm because diﬀerent validation methods favor diﬀerent

algorithms. Then a consensus of diﬀerent clustering algorithm usually provides a

“better” solution. I use the flowMatch algorithm (originally developed for creating

a template from similar samples) to create consensus clustering from a collection

of partitions (cluster ensembles). By comparing the consensus clustering with the

“best performing” algorithm, I showed that the consensus solution performs better

when evaluated by diﬀerent cluster validation methods. The superior performance

of consensus clustering was also observed in the clustering challenges organized by

the FlowCAP consortium (http://flowcap.flowsite.org/). In these challenges,

more than 15 clustering algorithms developed by diﬀerent independent researchers

were used to cluster same set of samples. However, often the consensus clustering by

Clue [84] outperformed the “best performing” algorithm based on their similarities

with the manual (visual) gating [32].

60

Clustering (automated gating) is arguably the most researched topic in computa-

tional cytometry. More than twenty algorithms customized for FC data are available

as software packages to be used by cytometrists. However, the large number of options

often confuses cytometrists due to the lack of validation methods needed to select a

clustering algorithm for a particular dataset. I argue that several cluster validation

methods should be used to evaluate the clustering quality and that a consensus clus-

tering be constructed whenever necessary. This approach produces a robust clustering

solution and increases conﬁdence on the quality of clustering in FC data.

61

4 REGISTERING CELL POPULATIONS ACROSS FC SAMPLES

4.1 Introduction

Cell populations with diﬀerent phenotypes and functions often respond diﬀer-

ently upon perturbation by stimuli or change of biological conditions. To track these

population-speciﬁc changes, we need to register corresponding cell clusters across sam-

ples. The population registration is a process where phenotypically similar cell clusters

are matched to establish the correspondence of clusters across samples [27, 37]. Fur-

thermore, the matched clusters are often labeled with abstract or biologically relevant

descriptions, thus solving the population/cluster labeling problem [39].

I solve the population registration problem with a combinatorial mixed edge cover

(MEC) algorithm [37]. Given a pair of clustered sample, I create a bipartite graph

whose vertices are denoted with cell clusters from the samples. An edge of the graph

is created by joining a pair of clusters with the dissimilarity between the clusters as

the edge-weight. The MEC algorithm then matches vertices (clusters) in the bipartite

graph by optimizing an appropriate objective function. Unlike conventional matching

algorithms, the MEC algorithm allows a cluster from one sample to be matched with

zero or more clusters in another sample and thus solves the problem of missing or

splitting biological populations.

In addition to solving the population registration

problem, an optimal MEC solution provides a combinatorial dissimilarity measure

between a pair of partitions from diﬀerent FC samples. This between-sample dissim-

ilarity works as a building block of the meta-clustering and classiﬁcation approaches

discussed in Chapter 5 and Chapter 6.

The ability to register multi-dimensional populations across FC samples is useful

in various applications of ﬂow cytometry [27, 36, 37, 130, 131]. In a cluster labeling
application, cell clusters in a collection of samples S are labeled based on the given

62

labeling of another FC sample A. This problem can be solved by matching clusters
between A and each sample B ∈ S, and labeling each cluster in B same as to the
matched cluster from A. I give an example of labeling diﬀerent sub-populations of

lymphocytes in samples from a healthy dataset.

In addition to labeling clusters,

the MEC algorithm allows an objective way of evaluating the phenotypic diﬀerences

between the matched clusters. By mapping clusters across two samples before and

after stimulating T cells, I demonstrate how we can assess the population-speciﬁc

eﬀects of the stimulation experiment. Furthermore, I register diﬀerent cell types in a

sample from an Acute Myeloid Leukemia (AML) patient with a healthy sample and

demonstrate a conventional procedure of AML diagnosis.

The MEC algorithm is similar – only in principle – to the FLAME approach pro-

posed by Pyne et al. [27], while diﬀering from it in signiﬁcant ways. First, FLAME

does not match clusters directly across a pair of samples. Instead, it constructs a tem-

plate of a class of samples and matches generic meta-clusters from the template to the

clusters from each sample; therefore, performs a global registration of clusters. In con-

trast, MEC algorithm performs a direct, sample-to-sample cluster matching, thereby

emphasizes the local patterns. In fact, the approach taken by FLAME is more sim-

ilar to the meta-clustering algorithm discussed in Section 5. Second, FLAME solves

a relaxed min-cost ﬂow problem [132] by an integer-programming solver, whereas

MEC uses a combinatorial algorithm to solve a relaxed minimum-weight matching

in a bipartite graph. Several other subtle diﬀerences also exist between these two

approaches, such as the methods used to compute distance between clusters and the

use of cluster sizes in matching. The cluster labeling approaches [23, 39] discussed

in FC literature are very diﬀerent from the MEC algorithm. These labeling algo-

rithms run a second stage of clustering from the cluster-centers and hence perform a

global labeling similar to the ﬁrst phase of FLAME. I will discuss more about this

approaches in the next Chapter 5.

The rest of this chapter is organized as follows. At ﬁrst, I discuss diﬀerent meth-

ods to compute dissimilarity between a pair of clusters, which is used by population

63

registration algorithms.

In Section 4.3, I describe the mixed edge cover algorithm

with a proof of its optimality. Section 4.4 describes diﬀerent properties of the MEC

algorithm and their implications on the population registration problem.

In Sec-

tion 4.5, I demonstrate, with three representative datasets, that the MEC algorithm

matches phenotypically similar populations across samples. I conclude this chapter

in Section 4.6.

4.2 Dissimilarity between a pair of cell clusters

Computing distances between clusters is an integral part of any cluster-matching

algorithm. In the past, researchers have used various parametric and non-parametric

methods in this purpose, such as the Euclidean distance [27], Mahalanobis distance

[23], the Kullback-Leibler (KL) divergence [36, 37], and the Earth Mover’s distance

(EMD) [133]. To compute dissimilarity between two clusters c1 and c2, the parametric

methods use distribution parameters of the clusters while non-parametric methods use

statistical signiﬁcance testing. I discuss very brieﬂy several widely used parametric

and non-parametric dissimilarity measures.

Parametric dissimilarity measures: To compute parametric distances, it is as-

sumed that a cell cluster approximately follows a known probability distribution.

Dissimilarity between a pair of cell clusters is then computed by the dissimilarity

between the corresponding multivariate probability distributions. To model cell pop-

ulations, researchers have used several well-characterized distribution families, such

as normal, skew-normal, t, skew-t distributions [23, 25–27, 36]. For simplicity, I as-

sume normally distributed cell populations in the rest of my discussion, but other

distributions are equally applicable to the dissimilarity methods discussed below.

Let c1(µ1, Σ1) and c2(µ2, Σ2) be two cell populations modeled by multivariate

normal distributions with mean vectors µ1, µ2 and covariance matrices Σ1, Σ2 re-

spectively. The Euclidean distance computes the distance between the centers (µ1

and µ2) of the distributions without considering the spreads of the distributions. The

symmetric version of the Kullback-Leibler (KL) divergence [134,135] uses both centers

and covariances of the distributions to compute dissimilarity dKL(c1, c2) between c1

64

and c2:

dKL(c1, c2) =

1
2

(µ1 − µ2)(cid:62)(Σ−1

1 + Σ−1

2 )(µ1 − µ2) +

1
2

tr(Σ−1

1 Σ2 + Σ−1

2 Σ1 − 2I). (4.1)

The symmetrized KL divergence, however, is not a metric because it does not satisfy

the triangle inequality. Mahalanobis distance [136] uses the pooled estimate of com-

mon covariance Σp from the two distributions to compute distance between clusters:

Σp =

(n1 − 1)Σ1 + (n2 − 1)Σ2

n1 + n2 − 2

,

dM D(c1, c2) =

(µ1 − µ2)(cid:62)Σ−1

p (µ1 − µ2). (4.2)

1
2

Note that, the above deﬁnition of Mahalanobis distance satisﬁes metric properties,

whereas the Mahalanobis distance deﬁned by Aghaeepour et. al. [31] (Equation 3.7)

is not a metric since it fails to satisfy triangle inequality [133].

Non-parametric dissimilarity measures: The non-parametric measures use sta-

tistical signiﬁcance testing to compute dissimilarity between cell populations. For

example, the Kolmogorov-Smirnov (KS) statistic [137, 138] computes the maximum

absolute vertical diﬀerence between two cumulative distribution functions (CDFs).

Another non-parametric measure uses chi-squared statistics after applying adaptive

probability binning [133] that divides a p-dimensional cell population into bins such

that each bin contains the same number of cells. The normalized chi-squared statis-

tics is then used to compute the dissimilarity between the populations. The earth

mover’s distance (EMD) [133, 139] considers the histograms of two populations as

two piles of dart in multivariate space and computes the minimum cost of moving

one pile into another. Here the cost of moving dart is deﬁned as the amount of dirt

moved times the distance by which it is moved. EMD can be eﬃciently computed by

ﬁrst applying adaptive probability binning on the cell populations and then solving

transportation problem on the bins across the clusters [139].

In the rest this chapter, I used Mahalanobis distance to compute dissimilarity

between a pair of clusters because it is a metric and uses the centers and covariance

matrices of the clusters. However, every algorithm described in this thesis works with

other dissimilarity measures as well.

65

4.3 The mixed edge cover (MEC) algorithm

4.3.1 Overview of the algorithm

Given a dissimilarity measure between cell cluster, I develop an algorithm to

optimally register clusters across a pair of FC samples. I make the algorithm robust

by allowing a cluster from one sample to be matched to zero or more clusters in

another sample. This approach covers possible circumstances when a cell cluster in

one sample is absent from another sample, or when a cluster in one sample splits into

two or more cell populations in a second sample, which can happen due to biological

reasons or due to the limitations of clustering methods.

I characterize an FC sample by a mixture of cell clusters. Consider two FC
samples A and B containing of ka and kb cell clusters such that A = {a1, a2, ..., aka}
and B = {b1, b2, ..., bkb}, where ai is the ith cluster from A and bj is the jth cluster from
B. I developed a robust variant of matching algorithm called the Mixed Edge Cover

(MEC) algorithm that matches a cluster from A to zero or more clusters from B [37].
Suppose mec is a matching of clusters across A and B such that mec(ai) ∈ P(B)
and mec(bj) ∈ P(A), where P(A) (P(B)) is a subset (possibly empty) of clusters in
A (B). When a cluster ai (or bj) remains unmatched under mec, i.e., mec(ai) = ∅,
I set d(ai,−) = λ where the ﬁxed cost λ is used as a penalty for leaving a cluster
unmatched, and is set to a value such that the number of such clusters remains

small. I select λ empirically by plotting the total number of unmatched clusters in

all pair wise matchings of samples against λ, and ﬁnding a “knee” in the curve [37].

The cost of mec is therefore computed as the summation of the dissimilarities of all

66

pairs of matched clusters and the penalties coming from the unmatched clusters. A

minimum-weight mixed edge cover is a mixed edge cover with the minimum cost:

 ka(cid:88)

(cid:88)

kb(cid:88)

(cid:88)

 .

argmin

d(ai, bj) +

d(bi, aj)

(4.3)

i=1

bj∈mec(ai)

i=1

aj∈mec(bi)

Here d(ai, bj) is the dissimilarity between clusters ai and bj.

4.3.2 Bipartite graph model

I compute a minimum-weight mixed edge cover (MEC) algorithmically in a com-
plete bipartite graph G(A, B, E) created from a pair of sample, A = {a1, a2, ..., aka},
and B = {b1, b2, ..., bkb}. In the bipartite graph G, each cluster ai ∈ A represents a
vertex in one part and each cluster bi ∈ B from represents a vertex in the other part.
The edge set E is created by joining each pair (ai, bj) ∈ (A × B) of vertices with an
edge of weight d(ai, bj). Here, d(ai, bj) denotes the dissimilarity between ai and bj

and is computed by using Mahalanobis distance from Equation 4.2.

Since low edge weight implies high similarity among vertices (clusters) I match

vertices connected by edges with small weights and leave a vertex unmatched when

it has no low-weight edge adjacent to it. In the above graph model, a mixed edge

cover (MEC) is a collection of edges EC and vertices Vum such that each vertex in
A∪B\Vum has at least one edge incident on it and Vum remains unmatched with ﬁxed
penalty λ for each vertex. Thus, a minimum-weight MEC is an MEC that minimizes

the following objective function:

 (cid:88)

(ai,bj )∈EC

 .

min

d(ai, bj) + λ ∗ |Vum|

(4.4)

According to graph-theoretic terms, an MEC is a generalization of an edge cover

represented by a subset of edges such that each vertex in the graph has at least one

edge incident on it. An edge cover again is a generalization of a matching represented

by a subset of edges such that each vertex in the graph has at most one edge incident

on it.

67

4.3.3 MEC algorithm on the bipartite graph

A mixed edge cover in G can be computed from an edge cover in a transformed
graph G(cid:48) obtained from G by introducing two new distinguished vertices a0 ∈ A and
b0 ∈ B representing two dummy clusters one in each sample. In G(cid:48), I add an edge
{a0, b0} with d(a0, b0) = 0, and edges {ai, b0} for each ai ∈ A, {bi, a0} for each bj ∈ B,
with d(ai, b0) = d(bj, a0) = λ. For each such edge {ai, b0} (or {bj, a0}) included in a
minimum-weight edge cover computed on G(cid:48), I leave the ai (bj) unmatched in a MEC
computed on G, thereby paying a price of λ for each unmatched vertex. A minimum-
weight edge cover in G(cid:48) can be computed in polynomial time by making a copy of the

graph and connecting each vertex to its twin in the copy by an edge with weight equal

to twice the minimum weight among original edges incident on it. A minimum-weight

perfect matching in this graph can be used to compute a minimum-weight edge cover

in the original graph [132].

Following the above discussion, a minimum-weight MEC in G can be computed

in the following step:

1. Add dummy vertices: Create a new augmented graph G(cid:48) from G by adding
two distinguished vertices a0 ∈ A and b0 ∈ B representing two dummy clusters
one in each sample. In G(cid:48) I add an edge {a0, b0} with d(a0, b0) = 0, and edges
{ai, b0} for each ai ∈ A, {bj, a0} for each bj ∈ B, with d(ai, b0) = d(bj, a0) = λ.
Here λ is the penalty for leaving a vertex unmatched.

2. Duplicate Graph: Let G(cid:48)(cid:48) be a disjoint copy of G(cid:48). I create a new graph ¯G by
taking the union of G(cid:48) and G(cid:48)(cid:48) and adding an edge {v(cid:48), v(cid:48)(cid:48)} connecting every
vertex v(cid:48) in G(cid:48) with its twin v(cid:48)(cid:48) in G(cid:48)(cid:48). The weight of edge {v(cid:48), v(cid:48)(cid:48)} is set to
2µ(v(cid:48)), where µ(v(cid:48)) is the minimum weight of the edges of G(cid:48) incident on v(cid:48).
3. Compute matching: Compute a minimum-weight perfect matching M in ¯G.
4. Compute edgecover from matching: Obtain a minimum-weight edge cover EC(cid:48)
of G(cid:48) by replacing every edge {v(cid:48), v(cid:48)(cid:48)} ∈ M by an edge of weight µ(v(cid:48)) in G(cid:48)
incident on v(cid:48).

68

Figure 4.1. Steps of the MEC algorithm: (a) two FC samples A and B,
each with three cell clusters, (b) a complete bipartite graph G is created
from A and B, (c) an augmented graph G(cid:48) is obtained by adding two
dummy clusters a0 and b0 as described in step 1 of the MEC algorithm,
(d) an identical copy of G(cid:48) is combined with it to obtain ¯G, (e) a minimum-
weight perfect matching M is computed in ¯G, (f) a minimum-weight edge
cover EC(cid:48) in G(cid:48) is constructed after replacing each edge of M connecting
G(cid:48) and its copy with an edge of minimum weight within G(cid:48), (g) a minimum-
weight MEC is computed from EC(cid:48) by removing dummy clusters and their
adjacent edges, and ﬁnally (h) the clusters are matched across A and B.

5. Compute MEC from edge cover: Remove all edges {ai, b0} and {bj, a0} from
EC(cid:48) to obtain a reduced edge cover EC in G. Put all vertices in G not covered

by EC to the set of unmatched vertices (clusters) Vum. The resulting edge cover

EC together with the set of unmatched vertices Vum is a solution to the mixed

edge cover problem in G.

I show a workﬂow of the MEC algorithm with two hypothetical samples A and

B each with three clusters in Figure 4.1. In this example, a single cell population

is split into two clusters in sample B requiring one-to-many matching of clusters.

Additionally a cluster in sample A remains unmatched because it does not have

any corresponding cluster in sample B. The MEC algorithm covers both cases and

therefore provides a robust solution to the population registration problem.

A B 0 b0 a0 λ € G € " G € G€ E" C € MECVum A B Sample A Sample B Sample A Sample B € MCluster matching A pair of samples (a) (b) (c) (d) (e) (f) (g) (h) 69

4.3.4 Proof of correctness

Lemma: The Algorithm described above computes an optimum mixed edge

cover in G.

Proof: The correctness of the algorithm for computing the edge cover EC(cid:48) in the
graph G(cid:48) is shown in [132]. I obtain a mixed edge cover in G by deleting, the vertices
a0 and b0 and the edges incident on these vertices in EC(cid:48). Let Vum be the set of the
vertices adjacent to a0 and b0, which will be identiﬁed as unmatched vertices. Let
EC be the edges remaining from the edge cover EC(cid:48) in the modiﬁed graph G \ Vum.
I claim that EC together with Vum is an optimal solution for the mixed edge

(cid:80)
(ai,bj )∈EC d(ai, bj) = (cid:80)

cover problem in G. Assume that there is an optimal solution in G consisting of
the set of unmatched vertices Vum and an edge cover EC∗ in G \ Vum. Clearly
(ai,bj )∈EC∗ d(ai, bj), for otherwise one of the solutions could
be improved upon, thereby contradicting their minimality in G \ Vum respectively.
It remains to prove that there is no other MEC solution in G with a diﬀerent set of
unmatched vertices and smaller cost. Let ˜EC together with ˜Vum gives a MEC solution

in G with a cost smaller than the MEC solution given by EC and Vum (Equation 4.4).
Then ˜EC together with an edge {o, a0} or {o, b0} for every o ∈ ˜Vum and the edge
{a0, b0} is an edge cover in G(cid:48) with cost smaller that the cost of EC(cid:48), contradicting
the optimality of EC(cid:48).

4.3.5 Complexity of the MEC algorithm

For a graph with n vertices and m edges, a minimum-weight edge cover can be
computed in time O(n(n + m log n)) [132]. For a pair of sample A = {a1, a2, ..., aka},
and B = {b1, b2, ..., bkb}, let k = ka + kb be the total number of clusters. By the
construction of the graph model n = O(k), m = O(k2). Therefore the time complexity

of a MEC algorithm is O(k3 log k). The number of cell clusters k is usually small (less

than 50 in typical experiments). As such, the dissimilarity between a pair of samples

can be computed in seconds on a desktop computer.

70

4.4 Properties of mixed edge cover

To understand the conditions for an unmatched cluster, let bj be the nearest

cluster in sample B from a cluster ai in sample A. Then ai is always unmatched if

d(ai, bj) > 2λ and is never unmatched if d(ai, bj) < λ. If 2λ < d(ai, bj) < λ, ai will

be unmatched if and only if it is not matched to a vertex in duplicate graph during

step 3 of the algorithm.

The edges contained in a minimum-weight MEC do not create any path of length

greater than two. Hence, MEC never creates a cycle in the optimum solution. To

see this, consider an MEC solution mec consisting of an edge cover EC and a set

of unmatched vertices Vum. The graph induced by EC in G does not have a path

of three edges since the middle edge can be removed from the optimal cover, thus

reducing its weight further, contradicting the optimality of mec. Therefore, mec does

not contain a path of length greater than two.

In fact, mec is a union of disjoint

“stars” (trees of height 1) where each star has no more than one vertex of degree

greater than one, preventing cycle or long chain of matched vertices. This property

allows a cluster from sample A to be matched to the corresponding but spitted set of

clusters in sample B and vice versa. However, if a cell population is split up in both

samples, the MEC algorithm is unable to match all parts across samples because this

will require a path of length greater than 2 in the MEC solution, therefore violating

the disjoint “stars” constructions. This limitation, however, cannot be solved by an

algorithm that considers only the between sample dissimilarities.

4.5 Results

4.5.1 Registering populations across samples from two healthy subjects

Data description: I register cell populations across two ﬁve-dimensional samples

collected from two healthy subjects. These two samples are part of the HD dataset

described in Section 1.6.1 where blood was collected from ﬁve healthy individuals

71

Figure 4.2. Selecting the unmatch-penalty, λ for the HD dataset. Each
black curve plots the numbers of unmatched clusters, Vum across a pair of
HD samples for a sequence of unmatch-penalty λ in the range [0,6]. The
red curve is a smooth-average of all individual curves and represents the
general trend for the whole dataset. From the average red curve, λ = 3.5
(shown as blue dashed line) is selected as a suitable unmatch-penalty
because, at this value, the curve becomes stable and horizontal.

on diﬀerent days to study natural and instrumental variations among samples. For

demonstration purpose, I randomly selected two samples from diﬀerent subjects in

the HD dataset. Each sample is preprocessed and clustered independently to identify

four cell clusters. Figure 3.3 in Chapter 3 displays these clusters with a collection of

two dimensional projections.

Selecting the unmatch-penalty, λ : To determine the unmatch-penalty λ for the

HD dataset, I compute the optimum mixed edge cover (MEC) between each pair

of samples in this dataset for diﬀerent choices of λ in the range [0,6]. The number

of unmatched clusters, Vum obtained by each MEC solution is plotted against the

corresponding λ value in Figure 4.2. Each black curve in Figure 4.2 represents the

the number of unmatched clusters for diﬀerent choices of λ when MEC algorithm is

applied to a particular pair of samples. I have applied local polynomial regression

(loess) method to smoothen the curves. The red curve is a smooth-average of all

individual curves and represents the general trend for the whole dataset. Observe

that an increase of λ quickly decreases the size of Vum, thus allowing more clusters to

012345602468Penalty for leaving a cluster unmatched, lNumber of unmatched clusters, Vumcutoff value72

Figure 4.3. Cell populations are matched by the MEC algorithm across
two representative samples in the HD dataset.
In addition to showing
individual cells with dots, I draw the 95th quantile of each cell population
with a dashed ellipse.
I show a pair of matched clusters in same color
and join them by a line with arrowheads. Although the cell populations
are deﬁned in ﬁve dimensions, I show a 2-D projection for visualization
purpose.

be matched ( from Equation 4.4). From the average red curve, λ = 3.5 (shown as blue

dashed line in Figure 4.2) is selected as a suitable unmatch-penalty because, at this

value, the curve becomes stable and horizontal. Since the samples are very similar

(healthy) in this dataset, we do not expect many unmatched clusters and therefore

λ = 3.5 looks like a reasonable choice.

I use λ = 3.5 for any MEC computation

between two samples in the HD dataset.

Registering populations: I now apply the MEC algorithm, with λ = 3.5, to match

cell clusters across the selected pair of samples. For visualization purpose, I project

the matched populations onto two dimensions (CD3 and CD19) in Figure 4.3.

I

selected CD3 and CD19 markers for projection because they cleanly deﬁne three

functional cell subsets – T cells, B cells and Natural Killer (NK) cells. The MEC

algorithm, however, does not use these biological labels, but views each cluster as

an unlabeled distribution of cells deﬁned only by the distribution parameters.

In

Figure 4.3, I show a pair of matched clusters in same color and join them by a line

with arrowheads. The matched clusters represent functionally equivalent cell subsets

CD19CD3−101234−1012345CD19CD3−10123401234T cells B cells T cells B cells NK cells NK cells Sample from subject ASample from subject B73

and therefore conﬁrm that the algorithm is actually matching biologically equivalent

cell populations across samples. Additionally the proportion of lymphocytes in each

clusters matches closely across the samples: T cell (71.1%, 75.4%), B cells (18.4%,

15.1%) and NK cells (10.5%, 9.5%). The proportions closely follow the lymphocyte

proportions within a healthy immune system described by Berrington et al. [140] and

further validate the eﬀectiveness of the clustering and matching algorithms. Note

that, cell clusters are actually deﬁned in ﬁve dimensions (Fig. 3.3), but I show a

simpliﬁed 2-D projection for visualization purpose.

In Figure 4.3, it may seem trivial to match these three clusters across samples

simply by visual inspection. However, the clusters are deﬁned in ﬁve dimensions and

therefore it is impractical to visually match the clusters. For example, we are unable

to distinguish helper and cytotoxic T cell in the 2-D scatter plot shown in Figure

4.3 because we need additional set of markers (CD4 and CD8) to diﬀerentiate them

from one another. Furthermore, the matching algorithm uses statistical parameters of

clusters to compute their dissimilarity, which is not easy to perceive by visualization.

The MEC algorithm is completely unsupervised and matches clusters solely based on

their statistical parameters without using the biological labels (e.g., T cell, B cells

etc.) of the clusters. However, if the cluster labels are available for a sample, then

the algorithm has the ability to label another sample based on the matching pattern,

thus solving the cluster labeling problem.

4.5.2 Registering populations before and after stimulating T cells

Data description: As a second example, I use MEC algorithm to register cell pop-

ulations across two four-dimensional samples collected before and after stimulating T

cells in whole human blood. These two samples are part of the TCP dataset described

in Section 1.6.2 where whole blood was collected from 29 subjects and stained using

labeled antibodies against CD4, CD45RA, SLP-76, and ZAP-70 protein markers be-

fore and ﬁve minutes after stimulation with an anti-CD3 antibody. The downstream

74

Figure 4.4. Registering (matching) populations by the MEC algorithm
across a pair of samples before and after stimulating T cells with an anti-
CD3 antibody. Matched clusters are marked with same color and are
joined them by a line with arrowheads. The cell populations are deﬁned
in four dimensions, but I show a 3-D projection for visualization purpose.

phosphorylation event caused by the stimulation increases the levels of SLP-76, and

ZAP-70 proteins in diﬀerent T cell subsets [44].

I randomly selected a pair of samples from the same subject before and after the

stimulation. Each sample is clustered independently to obtain four cell clusters with

the following expression proﬁles: (a) CD4+ CD45RAlow, (b) CD4+ CD45RAhigh, (c)
CD4− CD45RAhigh, and (d) CD4− CD45RAlow. (Recall that ‘+’ and ‘high’ indicate
higher abundances of a marker, and ‘−’ and ‘low’ indicate lower levels of it.)

Registering populations: I select unmatch-penalty λ for the TCP dataset following

the similar procedure discussed in Section 4.5.1. The MEC algorithm is then used to

register cell population across the selected pair of samples. For visualization purpose,

I show the matching solution in three-dimensional projections (CD4, CD45RA and

SLP-76) in Fig. 4.4, where matched clusters are shown in same colors. By comparing

the matched clusters in Fig. 4.4, we observe an increased level of SLP-76 proteins after

the stimulation (and ZAP-70, although this is not included in the Fig.). The mapping

of clusters across pre- and post-stimulation samples can assess the population-speciﬁc

eﬀects of the stimulation experiment.

0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4CD45RA0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4CD45RA(a) Before Stimulation(b) After Stimulation75

Figure 4.5. Registering diﬀerent clusters between normal and AML sam-
ples. Matched clusters are marked with same color. The proportion of
myeloid blasts (shown in red) increases signiﬁcantly in the AML sample.

4.5.3 Registering population in diagnosing Acute Myeloid Leukemia (AML)

Acute Myeloid Leukemia (AML) is often diagnosed by abnormal increase (greater

than 20% of the white blood cells) of premature myeloid blast cells [141,142]. In ﬂow

cytometry, the myeloid blasts can be identiﬁed in SS vs. CD45 plot. Here, the side

scatter (SS) measures the granularity of cells and CD45 is a marker for the leukocytes.

To show the ﬁrst step of AML diagnosis, I use a normal and an AML samples from

the AML dataset [32]. I only consider SS channel and CD45 marker for this analysis.

I cluster the healthy and the AML samples with the k-means algorithm and obtain

ﬁve clusters in each sample. The ﬁve clusters represent lymphocytes, lymphoid blasts,

myeloid cells, myeloid blasts, and monocytes. The myeloid blasts are identiﬁed by

medium side scatter and medium CD45 expressions. Next, I match cell clusters in

order to detect same cell types between the samples. The result is illustrated in

Fig. 4.5, where a pair of matched clusters is shown in same color. After registering

clusters, we observe that the fraction of myeloid blasts (shown in red) increases from

1.5% in healthy sample to 28% in the AML sample. This observation conﬁrms that

0.20.40.60.80.20.40.60.8CD45−ECD(log)SS(log)0.20.40.60.80.20.40.60.8CD45−ECD(log)SS(log)LymphocytesLymphoid blastsMyeloid cellsMyeloid blastsMonocytesNormalAML1.5%28%76

the second sample has Acute Myeloid Leukemia. The mixed edge cover algorithm is

able to detect abnormally behaving cell populations indicative AML and therefore,

can be used in automated diagnosis of this cancer.

4.6 Conclusions and future work

Population registration or labeling is a fundamental problem in ﬂow cytometry

since it is used to evaluate population level diﬀerences across biological conditions.

To solve this problem computationally, I have developed a robust mixed edge cover

(MEC) algorithm that registers high-dimensional clusters across a pair of FC samples.

The MEC algorithm uses a robust graph-theoretic framework to match a cluster from

a sample to zero or more clusters in another sample and thus solves the problem of

missing or splitting clusters. I demonstrated, with three representative datasets, that

this algorithm correctly matches phenotypically similar clusters despite heterogeneity

across samples. Given a sample with known cluster labels, the MEC algorithm labels

clusters from another sample, thus solving the cluster labeling problem.

Beside matching and labeling populations, an optimal MEC solution computes

a combinatorial dissimilarity between a pair of FC samples. This between-sample

dissimilarity works as a building block of the meta-clustering and classiﬁcation ap-

proaches discussed in Chapter 5 and Chapter 6.

MEC algorithm has three limitations. First, it does not use the proportion of

cells in the populations while matching them across samples. It has been observed

that samples from same biological status approximately preserve the proportion of

cells in diﬀerent populations (e.g., see the discussion in Section 4.5.1 and also by

Pyne et al. [27]). Hence, cell proportions can be used directly in Eq. 4.4 to provide a

second level of veriﬁcation. However, care must be taken when using cell proportion

to match populations from diﬀerent disease status. For example, the proportion

of CD4+ cells reduces signiﬁcantly after HIV infection, therefore this proportion of

CD4+ cells will not match between healthy subject and HIV patient. Second, MEC

77

algorithm can match populations more accurately if it uses the relative arrangement

of populations within a sample.

In this approach, each sample is modeled by a

network of populations and two such networks are aligned to match populations

across samples. This approach has been extensively used to align protein and gene

regulatory networks [143, 144]. Aligning two networks, however, is an NP-complete

problem; therefore, approximation algorithms are often used to align large networks.

Finally, the dissimilarity measure given by the MEC solution is not a metric since it

fails to satisfy triangle inequality. Distance metrics are especially useful for creating

hierarchical organization of samples, as will be discussed in next Chapter 5.

In current work, I am improving the MEC algorithm by addressing the limitations

discussed in the previous paragraph. In particular, I am developing a between-sample

distance metric similar in spirit of the earth mover’s distance [133, 139] such that

the combinatorial dissimilarity measure becomes a metric, as well as remains robust

similar to the MEC.

78

5 META-CLUSTERS AND CLASS TEMPLATES

5.1 Introduction

Consider a collection of ﬂow cytometry samples belonging to a few representa-

tive classes with each class of samples indicating the same biological status (e.g., a

disease).

I describe an algorithm that builds a template for each class of samples

by emphasizing the common properties of the class while omitting sample-speciﬁc

details [23,27,36]. Samples within a class usually have shared populations expressing

similar phenotypes, whereas samples from diﬀerent classes contain some unrelated

populations. Cell populations with similar phenotypes in diﬀerent samples of a class

can be combined into a meta-population (also called a meta-cluster ) representing

a generic phenotype shared by the populations. A set of relatively homogeneous

meta-clusters forms the core pattern of a class of samples and groups together into a

prototypic template. I summarize the concepts of meta-cluster and template in Table

5.1 and in Figure 5.1(a).

I have developed a hierarchical matching-and-merging (HM&M) algorithm for con-

structing templates from a collection of samples. The algorithm repeatedly merges

the least dissimilar (most similar) pair of samples not already included in a template.

The dissimilarity between a pair of samples is computed by the cost of an optimal

mixed edge cover (MEC) solution discussed in Chapter 4. Towards this end, I as-

sume that samples belonging to a particular class have smaller dissimilarity among

themselves than samples from other classes. The HM&M algorithm builds a binary

template-tree representing the hierarchical relationships among the samples. A leaf

node of the template-tree represents a sample and an internal (non-leaf) node rep-

resents a template created from the samples. Figure 5.1(b) shows an example of a

template-tree created from four hypothetical samples, S1, S2, S3, and S4. An internal

79

Summary of concepts – cell population, sample, meta-cluster, and tem-
plate – used in this chapter.

Table 5.1

Terms

Meaning

Cell population

a group of cells expressing similar features, e.g., helper T cells,

(cell cluster)

B cells, etc.

Sample

a collection of cell populations within a single biological sample

Meta-cluster

a set of biologically similar cell clusters from diﬀerent samples

Template

a collection of meta-clusters from samples of same class

node in the template-tree is created by matching similar cell clusters across the left

and right children and merging the matched clusters into meta-clusters. Fig. 5.1(c)

illustrates the creations of the internal node T (S3, S4) in Fig. 5.1(b) by matching clus-

ters across samples S3 and S4. The root of the template-tree deﬁnes a class-template

when all samples in the leaf nodes belong to the same biological class, and otherwise,

the tree can be cut at an appropriate height to discover multiple class templates.

Just as a sample is characterized by a mixture of cell populations, a template

is characterized by a ﬁnite mixture of homogeneous meta-clusters. The homogene-

ity of meta-clusters needs to be evaluated statistically since there is no accepted

method for evaluating the biological homogeneity of clusters. However, conventional

methods for statistical signiﬁcance testing (e.g., F-test or paired t-test) have a high

probability of making a Type I error when used to evaluate the homogeneity of a

meta-cluster because clusters in an FC sample are typically large [145, 146]. Instead,

the ratio of between-cluster to within-cluster variances, within a multivariate analysis

of variance (MANOVA) model, can evaluate the homogeneity of a meta-cluster more

eﬀectively [147]. Based on a baseline experiment with a healthy dataset, I discuss a

tolerable limit for the between-cluster variance in a homogeneous meta-cluster.

The ability to systematically characterize a class of multi-dimensional samples

with a well-deﬁned template is useful in various applications of ﬂow cytometry. In

80

Figure 5.1.
(a) The concepts of sample, cluster, template, and meta-
cluster are illustrated graphically. Cells are denoted with dots, clusters
with solid ellipses and meta-clusters with dashed ellipses. (b) An example
of a hierarchical template-tree created from four hypothetical samples
S1, S2, S3 and S4. A leaf node of the template-tree represents a sample
and an internal (non-leaf) node represents a template created from its
children in the tree.
(c) One step of the HM&M algorithm creating a
template T (S3, S4) from a pair of samples S3 and S4. The algorithm ﬁrst
matches clusters across S3 and S4 by the mixed edge cover algorithm and
then merges the matched clusters to construct new meta-clusters.

addition to providing a cogent description of the core population structure that is

shared among samples within a class, the templates also allow an objective way of

assessing the overall diﬀerences in those structures across classes. I demonstrate the

application of templates with a healthy donor (HD) dataset and a T cell phospho-

rylation (TCP) dataset. For the HD dataset, the algorithm is able to construct ﬁve

well-separated templates for ﬁve healthy subjects, despite diﬀerent sources of within-

subject variations. For the TCP dataset, the algorithm creates pre- and a post-

stimulation templates from 29 pairs of samples collected before and after stimulating

blood cells with an anti-CD3 antibody. By matching meta-clusters across templates,

we can better assess the population-speciﬁc eﬀects of the stimulation experiment.

Related work: Several researchers have used the concepts of templates and meta-

clusters to summarize collection of ﬂow cytometry samples [23, 27, 39]. FLAME,

A templateA sampleA cluster(population)A cellA meta-clusterA clusterS1S4S2S3S4S3Cluster matchingby MEC algorithmMatched clustersare merged to getmeta-clusters(a) Terminology(b) Template tree (c) One phase of the     HM&M algorithmT(S1, S2, S3, S4)T(S1, S2)T(S3, S4)81

proposed by Pyne et al. [27], pools cluster medoids from a class of samples and

applies a second stage of clustering on the medoids to construct the global meta-

clusters. ﬂowTrans, developed by Finak et al. [23], starts with seed meta-clusters

and assigns each cluster to a meta-cluster to which it is most similar. The HM&M

algorithm is signiﬁcantly diﬀerent from both FLAME and ﬂowTrans in several ways.

First, FLAME and ﬂowTrans both build a single template from samples of the same

class. Therefore, these algorithms need to know the class label of each sample, which

is often unknown in practice. In contrast, the HM&M algorithm is able to identify

templates as the roots of well-separated branches of a template-tree in an unsupervised

manner. This approach also permits multiple templates representing diﬀerent sub-

classes within a single class, and therefore, is more ﬂexible to capture sample diversity.

Second, instead of clustering population centers, the HM&M algorithm optimally

matches populations across samples and then merges the matched clusters into meta-

clusters (see Figure 5.1(c) for an example). Like FLAME, but unlike ﬂowTrans,

this algorithm allows a cluster forming a self-contained meta-cluster by itself when

the cluster is signiﬁcantly diﬀerent from all other clusters. Finally, the hierarchical

organization of samples shown in Fig. 5.1(b) provides additional ﬂexibility in creating

multi-layer templates, classifying samples, and updating templates dynamically.

The rest of the chapter is organized as follows. In Section 5.2, I describe a hi-

erarchical algorithm for creating templates from a collection of samples. Section 5.3

discusses a statistical framework for analyzing the homogeneity of meta-clusters. I

demonstrate the application of templates with two representative FC datasets in Sec-

tion 5.4. I ﬁnish this chapter in Section 5.5 with concluding remarks.

5.2 An algorithm for constructing templates

5.2.1 Dissimilarity between samples or templates

The template construction algorithm characterizes both a sample and a template

with a ﬁnite mixture of multivariate normal distributions each component of which

82

is a cluster or a meta-cluster. To compute the dissimilarity between a pair of samples

or templates, I create a complete bipartite graph with the clusters (meta-clusters) in

each sample (template) as vertices, and each edge is weighted by the Mahalanobis

distance between its endpoints. The cost of an optimal mixed edge cover (MEC) in

the bipartite graph gives the dissimilarity between the samples (templates). This dis-

similarity measure is similar in spirit with the R-metric, transfer distance or partition

distance that computes the minimum number of augmentations and removals of cells

needed to transform one partition into another [121–123]. However, the partition

distance can only compare two partitions of the same sample, whereas MEC based

dissimilarity can work with partitions from the same sample, or from two diﬀerent

samples. Partition distance matches a cluster to at most one cluster, while MEC is

able to match a cluster to zero or more clusters. Therefore, the latter approach is

more robust in the presence of missing or splitting cell populations.

5.2.2 The hierarchical matching-and-merging (HM&M) algorithm

Consider a collection of N ﬂow cytometry samples {S1, S2, ..., SN}. Each sample
is clustered independently to identify phenotypically distinct cell populations. The

HM&M algorithm organizes the samples into a template-tree data structure as was

described in Fig. 5.1. Each node vi in the template-tree represents either a sample

(leaf node) or a template (internal node). Let vi consist of ki clusters or meta-clusters,
}. vi is called an “orphan” if it does not have a parent in the
vi = {ci
template-tree. At each step, the HM&M algorithm identiﬁes the most similar pair of

2, . . ., ci
ki

1, ci

orphan nodes and merges them into a new node denoting a template of the merged

nodes. This process continues until a single orphan node (root) remains. The HM&M

algorithm can be described with the following three steps.

1. Initialization: Create a node vi for each of the N samples Si. Deﬁne the set of
orphan nodes, Orphan = {v1, v2, ..., vN}. Repeat the following matching and merging
steps until a single orphan node remains.

2. Matching: Compute the dissimilarity D(vi, vj) between every pair of nodes vi

and vj in the current Orphan set by the cost of an optimal mixed edge cover solution.

3. Merging: Find a pair of orphan nodes (vi, vj) with minimum dissimilarity

83

z

then cj

y = mec(ci

from each set of matched clusters, i.e., cl

x ∈ vi is matched to cj

the mapping of clusters from vi to vj. That is, if ci

D(vi, vj) and merge them to create a new node vl. Let mec be a function denoting
y ∈ vj,
x), where 1 ≤ x ≤ ki and 1 ≤ y ≤ kj. Create a new meta-cluster cl
x)}. Let kl be the number
of new meta-clusters created above. Then the new node vl is created as a collection
}. The distribution pa-
of these newly created meta-clusters, i.e., vl = {cl
rameters, (µl
z are estimated by the

z), of each of the newly formed meta-clusters cl

z = {ci

x ∪ mec(ci

1, cl

2, ..., cl
kl

z, Σl

Expectation-Maximization (EM) algorithm. The height of vl is set to D(vi, vj). The

node vl becomes the parent of vi and vj, and the set of orphan nodes is updated to
orphan = orphan \ {vi, vj} ∪ {vl}. If there are orphan nodes remaining, we return to
the matching step, and otherwise, we terminate.

5.2.3 Creating templates from a template-tree

Let the samples {S1, S2, ..., SN} belong to M disjoint classes where M may or may
not be known. Then, the following three cases are considered to create templates from

the template-tree.

(a) Class label of each sample is known: A template-forest with M disjoint trees is

constructed where each tree includes samples belonging to the same class. The roots

of the M trees represent the templates of the M classes of samples.

(b) M is known but the class label of each sample is unknown: A single template-

tree is created from N samples. Then, the tree is cut at a suitable height so that M

disjoint subtrees are produced. The root of each subtree represents a template of the

samples placed in the leaves of that subtree.

(c) Both M and the class labels of the samples are unknown: A single template-

tree is created from N samples. The templates are created from the roots of the well-

84

separated branches of the template-tree such that within-class variations (heights of

the subtrees) are small relative to the between-class variations (heights of the ances-

tors of the subtrees). In this context, the HM&M algorithm is similar to the spirit

of the hierarchical clustering algorithm UPGMA [33, 95], with signiﬁcant diﬀerences

in the distance computation and management of the internal nodes. Assume that

M well-separated templates are produced from the template tree. Then, N sam-

ples are predicted to be generated from these M classes. This approach leads to an

unsupervised classiﬁcation of samples discussed in the next chapter.

5.2.4 Computational complexity

The HM&M algorithm requires O(N 2) dissimilarity computations and O(N )

merge operations for creating a template from a collection of N samples. Let k

be the maximum number of clusters or meta-clusters in any of the nodes of the

template-tree. Then a dissimilarity computation takes O(k3 log k) time whereas the

merge operation takes O(k) time when distribution parameters of the meta-clusters

are computed by maximum likelihood estimation. Hence, the time complexity of the

algorithm is O(N 2k3 log k), which reduces to O(N 2) for bounded k.

5.3 The homogeneity of meta-clusters and templates

A template summarizes the common features of a group of similar samples. These

common features are captured by a collection of meta-clusters (meta-populations)

formed by combining cell clusters expressing similar phenotypes in diﬀerent samples.

If a template correctly represents a collection of samples with the same biological

status, each meta-cluster would contain a homogeneous collection of cell clusters with

similar phenotypes. However, there is no standard method for computing biological

homogeneity of a collection of cell populations. Therefore, I consider a statistical

procedure, in a Multivariate Analysis of Variance (MANOVA) model, to evaluate

85

the homogeneity of meta-clusters. For simplicity, I ﬁrst discuss the homogeneity of

one-dimensional meta-clusters, followed by the multi-dimensional case.

5.3.1 Analyzing homogeneity of a one-dimensional meta-cluster

Let C be a meta-cluster consisting of k one-dimensional (1-D) clusters c1, c2, ..ck

deﬁned within a single marker/channel. A 1-D cluster usually represents a distri-

bution of cells with a marker either being expressed or not being expressed. For
example, CD3+ and CD3− represent two 1-D clusters in CD3 channel, with the for-

mer expressing high levels of CD3 marker and the latter expressing low levels of it.

CD3 is a marker of T lymphocytes, and therefore, a meta-cluster denoting T cells is

biologically homogeneous if it contains only CD3+ cell clusters.

Let the ith cluster ci ∈ C contain ni cells and be normally distributed with mean µi
i . The normality assumption was justiﬁed in Chapter 2, where I showed

and variance σ2

that cell clusters usually follow normal distribution after stabilizing their variances.

In spite of variance stabilization, I still use σ2

i to denote the variance of the ith cluster
(instead of using a common variance) to emphasize that the variances can not be

made exactly equal by the variance stabilization process. The mean and variance

of each cluster are estimated by the E-M algorithm (alternatively, with an unbiased

maximum likelihood estimator) after the clusters are identiﬁed as was discussed in

Chapter 3.

Let the entire meta-cluster C contain n cells in total with mean µ. The separation

of a cluster ci from the meta-cluster C can be approximated by the squared deviation
of their centers (µi − µ)2. In behavioral and biological sciences, (µi − µ)2 is generally
called the “eﬀect-size” because it indicates the eﬀect of the ith treatment [147]. In

the meta-clustering context, it denotes the “cluster separation” of the ith cluster from

the meta-cluster center. The between-cluster variation σ2

b of a meta-cluster is then

computed with the average separation of the clusters:

k(cid:88)

i=1

σ2
b =

1

n − k

(ni − 1)(µi − µ)2.

(5.1)

86

The within-cluster variance, σ2

w, is estimated by a weighted average of all individual

cluster variances (pooled variance):

σ2
w =

1

n − k

k(cid:88)

i=1

(ni − 1) σ2
i .

(5.2)

I calculate the “Relative Cluster Separation” (φ) after dividing σ2

b by σ2

w and taking

a square root of the ratio:

φ =

σb
σw

.

(5.3)

Note that the square of the above ratio, φ2, is also known as the signal-to-noise ratio

(SNR) [148] or Cohen’s f 2 statistics [147]. φ is a dimensionless number and can take

values between zero (when the clusters collapse into a single point) and an indeﬁnitely

large number (when the clusters become further apart relative to σw). For example,

φ = 0.1 conveys that the average separation among clusters (σb) is one-tenth of

their (pooled) standard deviation (σw), indicating a signiﬁcant overlap (homogeneity)

among the clusters. In contrasts, φ = 2 conveys a relatively inhomogeneous group of

clusters because the average between-cluster separation is twice as large as the within-

cluster standard deviation. A meta-cluster is considered relatively homogeneous when

φ is small relative to a predeﬁned threshold. For FC data, this threshold can be set to

one, i.e., a collection of clusters is relatively homogeneous when φ < 1, and otherwise,

inhomogeneous.

I justify this choice of threshold in Section 5.4.1 with a healthy

dataset. A guideline, although controversial, for setting the threshold at three levels

– .1 for small, .25 for medium and, .4 for large eﬀect – is suggested by Cohen for

behavioral studies [147]. However, I found these levels too small for relatively large

cell clusters observed in FC samples.

I compute the uncertainty associated with φ by computing the conﬁdence interval

around it. Assume, for simplicity, that the clusters within a meta-cluster have equal
sizes n(cid:48) ( here, n(cid:48) = n/k, where n is the total size of the meta-cluster and k is the

number of cluster in the meta-cluster). Then the conﬁdence interval for φ is calculated

from the conﬁdence interval of the non-central F distribution whose non-centrality

parameter λ is calculated with:

87

(5.4)
Let [λL, λU ] be the 100(1−α)% conﬁdence interval for λ, then the following equations
hold:

λ =

n(cid:48)σ2
σ2
w

b

= n(cid:48)φ2.

(cid:34)(cid:114)

p

(cid:114)

p[λL ≤ λ ≤ λU ] = 1 − α
n(cid:48) ≤ φ ≤
λL

λU
n(cid:48)

= 1 − α.

(cid:35)

(5.5)

(5.6)

[146,149].

(cid:20)(cid:113) λL

n(cid:48) ,

(cid:21)

(cid:113) λU

n(cid:48)

Hence, the conﬁdence interval [φL, φU ] for φ is calculated with

Note that I employ φ to evaluate the homogeneity of a meta-cluster obtained from

any meta-clustering algorithm. However, a meta-clustering algorithm can directly

minimize φ and obtains the “optimum” homogeneity of meta-clusters. This approach

is very similar to Fisher’s linear discriminant analysis that maximizes the separation

between clusters relative to within-cluster variations [90]. I leave this optimization

approach as a future work and will not discuss it any further.

5.3.2 Comparison with null hypothesis based signiﬁcance testing

Consider a meta-cluster consisting of k cell clusters, where the ith cluster contains

ni cell with mean µi. To evaluate the homogeneity of this meta-cluster in an Analysis

of Variance (ANOVA) model, we can consider a null hypothesis of no diﬀerence among

cluster centers:

H0 : µ1 = µ2 = ··· = µk.

(5.7)

The normality and homoskedasticity assumptions required for the ANOVA model are

approximately satisﬁed by the variance stabilization step discussed in Chapter 2. The

validity of the above null hypothesis can be tested by an F-test that measures the

following F-statistics:

1
k−1

Fobs =

k(cid:80)

ni(µi − µ)2

i=1

σ2
w

,

(5.8)

88

where, µ is the mean of the entire meta-cluster and σ2

w is the pooled variance of

the clusters as deﬁned in Eq. 5.2. The p-value of the F-test is computed with the

probability of obtaining a test statistic at least as extreme as Fobs assuming that the
null hypothesis is true, i.e., we compute P (F ≥ Fobs), where F is a random variable
following F-distribution with k − 1 and n − k degrees of freedom. In a meta-cluster
analysis, p-value evaluates whether the diﬀerence among cluster locations can occur

by chance. The null hypothesis H0 is rejected when the p-value is less than a certain

signiﬁcance level (often 0.05 or 0.01). Hence, we can declare a meta-cluster to be

inhomogeneous (H0 is rejected) when the p-value of the F-test is less the signiﬁcance

level, and otherwise, declare it to be homogeneous (H0 in not rejected).

The F-test depends on the size of clusters because the cluster size (ni) appears on

the numerator of Fobs in Eq. 5.8. In the Null Hypothesis based Signiﬁcance Testing

(NHST) framework, large clusters produce high Fobs (low p-value of the F-test) and

therefore, tend to declare a meta-cluster to be inhomogeneous even though the average

cluster-separation is relatively small. As a matter of fact, given suﬃciently large

cluster sizes, an F-test always rejects H0 unless the locations of the clusters collapse

at a single point, which is extremely unlikely in practice.

In ﬂow cytometry, the

number of cells in a cluster is typically large, often in the range of tens of thousands

cells. Hence, NHST has a high probability of making a Type I error, even at a very low

alpha such as at .001, and incorrectly declares a meta-cluster inhomogeneous when

the cluster sizes are large. In contrast to the F-test, the relative cluster separation (φ)

does not depend on the cluster sizes and is therefore more applicable to meta-cluster

analysis in ﬂow cytometry.

To see the relationship between φ and the paired t-test, consider a meta-cluster
consisting of two equal-size (n(cid:48)) clusters, with means µ1 and µ2 and a common variance
σ2. In this case, Eq. 5.3 simpliﬁes to

1

2|µ1 − µ2|

σ

=

d
2

,

φ =

(5.9)

89

where d is the standardized mean diﬀerence between two clusters, also known as

Cohen’s d [147]. In this settings, a two-group t-test statistics (tobs) is computed by

(cid:114) n(cid:48)

2

tobs =

· µ1 − µ2

σ

.

(5.10)

Similar to Fobs in Eq. 5.8, tobs depends on the cluster sizes. Consequently, the t-test

can also report a small diﬀerence to be highly signiﬁcant when the cluster sizes are

large relative to the within-cluster variance. Therefore, φ can also be used to assess

the separation of a pair of clusters instead of traditional t-test.

5.3.3 Analyzing homogeneity of high-dimensional meta-clusters

I analyze the homogeneity of high-dimensional meta-clusters in a ﬁxed-eﬀect Mul-

tivariate Analysis of Variance (MANOVA) model [150]. As before, let C be a p-

dimensional meta-cluster consisting of k clusters, c1, c2, ..ck, with the ith cluster ci

containing ni cells and the size of the entire meta-cluster to be n = (cid:80)k

i=1 ni. As-
sume that the ith cluster ci is modeled by a multivariate normal distribution with a
p-dimensional mean vector µi and a p×p covariance matrix Σi. The mean vector µ of
the entire meta-cluster C is estimated by 1
i=1 niµi. Similar to the one-dimensional
n
setting, I compute the within-cluster covariance matrix, Σw, and the between-cluster

(cid:80)k

covariance matrix, Σb, as follows:

k(cid:88)

Σb =

1

n − k

Σw =

1

n − k

(ni − 1)Σi

i=1

k(cid:88)
(ni − 1)(µi − µ)(µi − µ)
(cid:114) 1

i=1

trace(Σ−1

w Σb).

φ =

p

(5.11)

(5.12)

(cid:124)

.

(5.13)

The relative cluster separation, φ, in multidimensional setting is then computed with:

In MANOVA, trace(Σ−1
and is computed by the summation of the eigenvalues of Σ−1

w Σb) is known as the Lawley-Hotelling statistics [150–152]

w Σb. I divide the Lawley-

Hotelling statistics by p so that φ becomes independent of the dimensionality and

90

take a square root of it to keep it in the original unit of measurement. Similar to the

univariate case, φ < 1 denotes that the between-cluster variation is less than naturally

occurring within-cluster variation, and therefore, the meta-cluster can be considered

homogeneous. As pointed out by Ito et al.

[153, p. 75-78], φ is a robust estimator of

the homogeneity of meta-clusters even in the presence of limited heteroskedasticity

of covariances in large clusters. Therefore, this measure can be applied to analyze

homogeneity of heteroskedastic clusters as well.

In the multi-dimensional setting, computing an exact conﬁdence interval around

φ is diﬃcult because the exact distribution of the Lawley-Hotelling statistics is not

known for general k and p. According to the discussion in [152, 154, 155], I ap-

proximatethe distribution with a non-central high-dimensional F distribution with
degrees of freedom a and b and the non-centrality parameter, λ, where a = p(k − 1),
b = p(n − k − p − 1) + 2, and λ = φ2(a + b + 1). The conﬁdence interval [φL, φU ]
around φ is therefore computed with [
a+b+1], where [λL, λU ] is the conﬁ-
dence interval of the non-centrality parameter, λ. I calculate the conﬁdence interval

(cid:113) λL

(cid:113) λU

a+b+1,

for λ by using the R package MBESS [156]. Note that T 2

w Σb) is
Hotelling’s generalized T 2 statistics [150–152] and is equivalent to the F statistics in

g = (n − k)trace(Σ−1

the univariate case. Similar to the univariate case, T 2

g also depends on cluster sizes

and has a high probability of making a Type I error by declaring trivial diﬀerences

as statistically signiﬁcant when cluster sizes are large.

5.4 Results

5.4.1 Creating templates from healthy samples

Data description: The healthy donor (HD) dataset consists of 65 samples from ﬁve

healthy individuals who donated blood on diﬀerent days. Each sample was divided

into ﬁve replicates and each replicate was stained using labeled antibodies against

CD45, CD3, CD4, CD8, and CD19 protein markers. Section 1.6.1 provides a detail

91

Figure 5.2. (a) The template-tree created by the HM&M algorithm from
all samples of the HD dataset. Leaves of the dendrogram denote samples
from ﬁve healthy individuals. An internal node represents a template and
the height of an internal node measures the dissimilarity between its left
and right children. The sample-speciﬁc subtrees are drawn in diﬀerent
colors. (b) Bivariate projections of the combined healthy template (the
root of the tree in Subﬁg. (a)) are drawn in terms of the meta-clusters.
Here, each meta-cluster is represented by a homogeneous collection of cell
clusters that are drawn with the 95th quantile contour lines. Clusters
participating in a meta-cluster are drawn in same color.

description about this dataset. Each sample of the HD dataset was preprocessed,

variance stabilized, and clustered to identify cell populations (see Fig. 3.3).

Creating healthy templates: Figure 5.2(a) shows the template-tree created from

the HD dataset. A leaf node of the tree denotes a healthy sample, and an internal

node represents a template created from samples placed in the underlying subtree.

The height of an internal node measures the dissimilarity between its left and right

children. We observe that 65 samples from the ﬁve healthy subjects are organized

into ﬁve well-separated branches shown in ﬁve diﬀerent colors in Fig. 5.2(a). From

the roots of these ﬁve subtrees, we can construct ﬁve subject-speciﬁc templates, e.g.,

TA represents a template created from 15 samples from subject A . In this dataset,

92

the variations within a subject-speciﬁc template arise from the environmental impact

on individual immune system on diﬀerent days and the technical variation in ﬂow

cytometry sample preparation and measurement. By contrast, the between-subject

variations arise from the natural biological variations among healthy subjects. In this

dataset, we observe more natural between-subject variations than the temporal and

instrumental variations. Hence, samples from the ﬁve subjects create concise and well

separated templates representing immune proﬁles for diﬀerent healthy individuals.

The HD dataset includes three sources of variations – the technical, day-to-day

within-subject, and between-subject variations. The template-tree captures these

multi-level variations with diﬀerent internal nodes that can be used as multi-layer

templates. In the lower level, a day speciﬁc template is constructed from ﬁve replicates

of a sample collected on a particular day from a subject. In the middle level, samples

from a subject collected on diﬀerent days create a subject-speciﬁc template (the roots

of colored subtrees in Fig. 5.2(a)). Finally, in the top level, the root of the whole tree

represents a combined template representing a healthy immune proﬁle of these ﬁve

subjects. This multi-level construction is especially useful to design a multi-level

sample classiﬁcation framework, which is the topic of the next chapter.

Meta-clusters in the healthy template: The template created from the HD dataset

(the root of the tree in Fig. 5.2(a)) represents a healthy immune proﬁle of the ﬁve

subjects. This template consists of four meta-clusters denoting four biologically dis-

tinct cell sub-types within lymphocytes (we have isolated lymphocytes on the scat-

ter channels in the pre-processing steps). Each meta-cluster is a collection of bi-

ologically equivalent cell populations from diﬀerent samples. Figure 5.2(b) shows

2-D projections of these meta-clusters in terms of the participating clusters. The

95th quantiles of the clusters within each meta-cluster are shown in same color

denoting (1) green: CD8+ T cells (CD45+CD3+CD8+), (2) black: CD4+ T cells
(CD45+CD3+CD4+), (3) blue: B cells (CD45+CD3−CD19+), and (4) red: natural
killer cells (CD45+CD3−CD19−). These meta-clusters represents core population

pattern of healthy lymphocytes excluding the subject-speciﬁc variations.

93

Figure 5.3. The homogeneity (Relative Cluster Separation, φ) of four
healthy meta-clusters shown in diﬀerent panels. The meta-clusters are
created from three diﬀerent groupings of the healthy samples shown in
diﬀerent colors.

Homogeneity of meta-clusters: How homogeneous are the meta-clusters contained

in diﬀerent templates of the HD dataset? Here, I discuss the homogeneity of three

levels of templates: (a) the healthy template created from all 65 samples, (b) 5 subject-

speciﬁc templates, each of which is created from samples from a subject, and (c)

13 day-speciﬁc templates, each of which is created from ﬁve replicates of a sample

collected on the same day from a subject. Every template consists of four meta-

clusters similar to the healthy template described in Fig. 5.2(b). We can evaluate the

homogeneity of the high-dimensional meta-clusters in each template with the Relative

Cluster Separation (RCS), φ, as discussed in Section 5.3.3.

Fig. 5.3 shows the RCS (φ) of four meta-clusters (diﬀerent panels) denoting four

subtypes of cells across three groups of templates (diﬀerent colors). For the subject-

speciﬁc and day-speciﬁc templates, I computed the the average RCS of the meta-

clusters in each group of templates. Recall that a high value of φ indicates low

homogeneity (high inhomogeneity) of a meta-cluster and vice versa. We observe, in

each panel of Fig. 5.3, that a meta-cluster becomes increasingly inhomogeneous (i.e.,

φ decreases) as we increase variations from diﬀerent sources. This is expected because

variations in data (even though from natural sources) reduce the uniformity of the cell

populations. However, we do not expect any biologically signiﬁcant variation within

a meta-cluster (denoting a cell-type) because the observed variations are originated

from natural sources among healthy individual. The highest value of φ is less than

CD4+TcellsNKcellsBcellsCD8+Tcells0.000.250.500.751.00GroupingofSamples(φ)Avg.RCSofmeta-clustersinsamplesfrom:Day-specifictemplates  Subject-specifictemplates  HealthytemplateRCS94

one for any meta-cluster in Fig. 5.3. Therefore, we consider a meta-cluster to be

biologically homogeneous when φ < 1. That is, a meta-cluster is homogeneous when

the between-cluster variation is less then the pooled within-cluster variation. This

assertion is satisﬁed by the healthy meta-clusters, as expected, because all samples

are from the same biological status.

The threshold for φ can be adjusted for a biological experiment depending on the

natural variability expected in the experimental condition. Therefore, it is advisable

to run a pilot study similar to the HD dataset to determine baseline/trivial homogene-

ity measurements, which can subsequently be used to assess biologically signiﬁcant

variations across diﬀerent classes of samples.

5.4.2 Creating templates from the TCP dataset

Data description: T cell phosphorylation (TCP) dataset was originally generated

by Maier et al. [44] to study the eﬀect of phosphorylation upon stimulating blood

with anti-CD3 antibody. The abundance of four protein markers (CD4, CD45RA,

SLP-76, and ZAP-70) was measured before and ﬁve minutes after stimulating whole

blood with an anti-CD3 antibody [44]. I reanalyzed 29 pairs of samples of this dataset

to demonstrated the creation of templates and the detection of general eﬀect of stimu-

lation at the meta-cluster level. Section 1.6.2 provides a detail description about this

dataset. Each of the 58 samples in the TCP dataset was preprocessed and clustered

independently to identify cell populations (Section 3.5.2).

General eﬀects of stimulation on phosphorylation responses: During the stimu-

lation, anti-CD3 antibody binds with T cell receptors (TCR) and activates the T

cells, initiating the adaptive immune response. The binding with TCR induces dra-

matic changes in gene expression and cell morphology, and induces the formation of

a phosphorylation-dependent signaling network via multi-protein complexes. ZAP-70

is a kinase that phosphorylates tyrosine in a trans-membrane protein called LAT, and

LAT and SLP-76 are part of a platform that assembles the signaling proteins [53].

95

Previous studies have shown that diﬀerent T cell subsets (naive, memory, eﬀec-

tor) display diﬀerent phosphorylation responses upon stimulation [44, 157–159]. In

these studies, each sample was gated to identify cell populations of interest, and

each pair of samples – before and after stimulation – were compared to detect the

phosphorylation responses. However, Maier et al. [44] reported that the autoimmune

disease-associated allele at CTLA4 gene on chromosome 2q33 alters phosphorylation

responses in naive and memory T cells. Thus, depending on their genetic proﬁles,

diﬀerent subjects might display diﬀerent phosphorylation responses upon stimulation.

It is therefore challenging to summarize the general eﬀect of phosphorylation from

observing the stimulation eﬀect in individual samples. An alternative and robust

approach is to create a pre-stimulation and a post-stimulation template. By match-

ing meta-clusters across these templates we can better assess the population-speciﬁc

eﬀects of the stimulation experiment.

Creating pre- and post-stimulation templates: By applying the HM&M algo-

rithm, I create a pre-stimulation template from 29 samples before stimulation and

a post-stimulation template from 29 samples after the stimulation. Both tem-

(a) CD4+CD45RAlow memory T
plates consist of four meta-clusters denoting:
cells, (b) CD4+CD45RAhigh naive T cells, (c) CD4−CD45RAhigh cells, and (d)
CD4−CD45RAlow cells. Fig. 5.4.2 shows three-dimensional projections of these meta-

clusters: pre-stimulation meta-clusters in blue and post-stimulation meta-clusters in

red. We observe an increased levels of SLP-76 protein in every meta-cluster after

stimulation than its pre-stimulation state. However, the increment is more clear in

naive and memory T cells, as was observed in earlier publications [44, 157–159]. Sim-

ilar phosphorylation eﬀect, although smaller than SLP-76, was observed for ZAP-70

protein as well. Therefore, two templates can concisely represent stimulation states of

58 samples in terms of the generic meta-clusters, and comparing meta-clusters across

templates evaluates the overall phosphorylation shifts across conditions.

Homogeneity of meta-clusters: How homogeneous are the pre- and post-

stimulation meta-clusters? To answer the question more rigorously, I create a com-

96

(a) CD4+ CD45RAlow memory T cells

(b) CD4+ CD45RAhigh naive T cells

(c) CD4− CD45RAhigh cells

(d) CD4− CD45RAlow cells

Figure 5.4. Three-dimensional projections of the meta-clusters created
from the TCP dataset: Pre- and post-stimulation meta-clusters are shown
in blue and red, respectively. The four meta-clusters represent:
(a)
CD4+CD45RAlow memory T cells, (b) CD4+CD45RAhigh naive T cells,
(c) CD4−CD45RAhigh cells, and (d) CD4−CD45RAlow cells.

bined template from all 58 samples in the TCP dataset. Table 5.2 shows the Rela-

tive Cluster Separation (RCS, φ) with the 95% conﬁdence intervals for every four-

dimensional meta-cluster from three templates (pre-stim, post-stim, and combined).

The combined meta-clusters in Table 5.2 are less homogeneous (i.e., larger values of

φ) than the pre- and post-stimulation meta-clusters. As expected, the homogeneity of

meta-clusters decreases with the increase of variations in the TCP dataset, as was also

0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4Before stimulationAfter stimulationCD45RA0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4CD45RA0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4CD45RA0.00.51.01.50.00.51.01.52.02.50.00.51.01.52.02.5SLP76CD4CD45RATable 5.2

Relative Cluster Separation (φ) with 95% conﬁdence intervals (CI) for
each of the four meta-clusters in the TCP dataset. Meta-clusters are
computed from (a) all 58 samples across before and after stimulation, (b)
29 samples before stimulation, and (c) 29 samples after stimulation.

97

Meta-cluster

φ [95% CI]

Before stimulation

After stimulation

Combined

CD4+CD45RAlow

0.541 [0.537, 0.545]

0.495 [0.491, 0.499]

1.023 [1.018, 1.026]

CD4+CD45RAhigh
CD4−CD45RAlow
CD4−CD45RAhigh

0.647 [0.642, 0.651]

0.545 [0.540, 0.550]

1.056 [1.051, 1.060]

0.328 [0.324, 0.332]

0.291 [0.287, 0.294]

0.476 [0.472, 0.478]

0.565 [0.561, 0.568]

0.364 [0.360, 0.367]

0.400 [0.397, 0.403]

observed in the HD dataset. In particular, the homogeneity of meta-clusters denoting

the naive and memory T cells decreases by a factor of two (twofold increment of φ)

in the combined template. For these two meta-clusters, the values of RCS are greater

than one (φ > 1) in the combined template indicating higher between-cluster variance

than the within-cluster variance. Therefore, the combined template is biologically in-

homogeneous based on the homogeneity threshold (φ = 1) discussed earlier for the

HD dataset. The inhomogeneity in the combined template implies that the combined

template is created from a heterogeneous collection of samples from more than one

biological classes, and one should not build a single template from these collection of

samples. Therefore, the RCS statistics provides an objective way of constructing and

evaluating templates and prevents us from building templates from inhomogeneous

collection of samples from multiple biologically distinct classes (such as the pre- and

post-stimulation samples in the TCP dataset).

5.5 Conclusions and future work

Templates and meta-clusters can succinctly summarize a large collection of sam-

ples belonging to a few biological classes. With a collection of homogeneous meta-

98

clusters, a template provides a concise description of a biological condition and reduces

the complexity of data by emphasizing the key characteristics of a class while masking

statistical noises and low-level details. I discuss a hierarchical matching-and-merging

(HM&M) algorithm for constructing templates that describe distinct biological states

available in a collection of samples. The HM&M algorithm can operate both in su-

pervised (class labels of samples are known) and unsupervised settings (class labels

of samples are not known). Templates created in an unsupervised setting can lead to

a robust classiﬁcation scheme, as will be discussed in the next chapter.

A meta-cluster within a template performs as a blueprint for a particular type

of cells and represents the generic cell population with a statistical description while

omitting sample-speciﬁc variations. Meta-clusters can be employed for measuring

general eﬀect on cell populations as biological conditions changes across templates.

As an example, the memory and naive T cells upon stimulated by anti-CD3 antibody

display increased levels of SLP76 and ZAP70 proteins, an indication of increased

phosphorylation in these T cell subpopulations. Despite sample-speciﬁc variations,

the T cell subpopulations from 29 pre-stimulation samples can be encapsulated with a

set of homogeneous meta-clusters. Therefore, we can evaluate the population-speciﬁc

eﬀect of the stimulation by registering these meta-clusters with their corresponding

meta-clusters in a post-stimulation template.

I discuss a statistical

framework,

in an multivariate analysis of variance

(MANOVA) model, for evaluating the homogeneity of meta-clusters. For a collec-

tion of variance-stabilized clusters within a meta-cluster, this approach computes the

ratio of between-cluster to within-cluster variance and uses the ratio to evaluate the

homogeneity of the meta-cluster. Based on the natural variations among healthy in-

dividuals, a meta-cluster can be declared relatively homogeneous when the ratio of

between- to within-cluster variance is less than one.

In continuing work, I plan to investigate the use of networks instead of trees to

organize the templates, similar in spirit to the use of networks rather than trees in

phylogenetics [160]. Another issue is that the combinatorial dissimilarity measure

between two samples is not a metric, and when the dissimilarity is extended to two

templates, this value does not monotonically increase in the hierarchical matching and

merging algorithm. I plan to investigate other dissimilarity measures in this regard.

99

100

6 CLASSIFYING FC SAMPLES BASED ON TEMPLATES

6.1 Introduction

Consider a collection of ﬂow cytometry samples, each sample consisting of ﬂuores-

cence measurements of protein markers made at the single-cell level from hundreds

of thousands of cells, indicating diﬀerent cell types present in each sample. I describe

an algorithm to dynamically classify such samples into several classes based on phe-

notypically distinct templates. As described in Chapter 5, the class templates can

be constructed by ﬁrst organizing the samples into a template-tree data structure,

and then identifying the templates by the roots of the well separated branches. In

this way, templates work as prototypes of diﬀerent biological classes (e.g., disease

status, time points, etc.) and emphasize the common properties of the class while

omitting sample-speciﬁc details. In this chapter, I discuss classifying new samples

by comparing them with templates and dynamically updating the templates (and

the template-tree) as new samples are classiﬁed. The template-base classiﬁcation is

robust and eﬃcient because it compares samples to cleaner and fewer class templates

rather than the large number of noisy samples themselves.

The concepts of cluster, meta-cluster, sample, and template are explained in Chap-

ter 5. Brieﬂy, a template is a collection of relatively homogeneous meta-clusters

commonly shared across samples of a given class, thus describing the key immune-

phenotypes of an overall class of samples in a formal, yet robust, manner [23, 27, 36].

Here, a meta-clusters or meta-population is a generic (abstract) population formed

by combining cell populations expressing similar phenotypes in diﬀerent samples.

Clusters participating in a meta-cluster usually represent the same type of cells and

thus have overlapping distributions in the marker space. Therefore, a template is

characterized by a mixture of (normally distributed) meta-clusters.

101

Besides their use in high-level visualization and between-class comparisons, tem-

plates can be employed to classify new samples with unknown status. In this chapter,

I use this approach to classify samples in terms of their expression of markers of the

immune system. In the static classiﬁcation approach, I build a ﬁxed number of tem-

plates, each representing samples from a particular class, and organize them into a

template-tree data structure. A new sample is then predicted to come from a class

whose template it is most similar to. In the dynamic classiﬁcation approach, I update

the templates and also the template-tree, as new samples are classiﬁed.

I demonstrate the use of template-based classiﬁcation with two diﬀerent datasets.

The ﬁrst dataset measures the diﬀerences in phosphorylation events before and after

stimulating T cells in human whole blood with an anti-CD3 antibody. By creating

pre-stimulation and post-stimulation templates, we can classify samples according

to their stimulation status. The second dataset studies the natural variations among

diﬀerent subsets of immune cells in ﬁve healthy individuals. Blood was collected on up

to four diﬀerent days from each subject and ﬁve technical replicates were created from

each subject. Five templates could succinctly represent samples from ﬁve individuals

despite the within-subject temporal and technical variations, demonstrating the fact

that technical and day-to-day variations are smaller than the natural variation across

individuals in this dataset.

Template-based classiﬁcation has been used in several areas such as face recog-

nition, speech recognition, character recognition, etc.

In face recognition [161], a

template library is created with one or more digital images from each person. An

unclassiﬁed image is compared to each database image by computing correlations of

diﬀerent features (eyes, nose, mouth etc.) and is classiﬁed as the one giving the high-

est cumulative score. In speech recognition [162, 163], a template is created for each

speaker by a sequence of consecutive acoustic feature vectors and an incoming signal is

classiﬁed by comparing it with the templates using the Dynamic Time Warping algo-

rithm. In character recognition [164], representative prototypes for each character are

created from diﬀerent writing styles and an incoming character is classiﬁed by com-

102

paring it to existing prototypes using a feature matching algorithm. The algorithms

discussed in this chapter have similarities to these methods in principle but diﬀers

from them signiﬁcantly in how the templates are created, represented, and compared

with incoming samples. In contrast to these approaches, I maintain a hierarchy of the

training samples in order to use their relationships in future classiﬁcation. A tem-

plate is then represented with the shared features of all samples in a class whereas

the methods discussed above use representatives from the training set. Furthermore,

the dynamic template algorithm continuously updates templates as new samples are

classiﬁed, which improves the accuracy of future classiﬁcation.

The rest of this chapter is organized as follows.

In Section 6.2, I describe the

classiﬁcation methods based on static templates created from a collection of training

samples. Section 6.3 outlines a robust dynamic classiﬁcation algoritm. The next

Section 6.4 demonstrates the application of template-based classiﬁcation with two

representative datasets. I conclude this chapter in Section 6.5.

6.2 Classifying Samples with Static Templates

6.2.1 Creating static templates from a collection of FC samples

Consider a collection of N FC samples belonging to M disjoint classes. In Sec-

tion 5.2, I described a hierarchical matching-and-merging (HM&M) algorithm that

organizes N samples into a binary template-tree data structure. A node in the tree

represents either a sample (leaf node) or a template (internal node). In both cases

a node is characterized by a ﬁnite mixture of multivariate normal distributions each

component of which is a cluster or meta-cluster. The height of an internal node in

the template-tree is measured by the dissimilarity between its left and right children.

By recursion, a template denoted by a relatively lower internal node represents a

relatively homogeneous collection of samples and vice versa.

After building a template-tree, we can cut the tree at a suitable height so that

M disjoint subtrees are produced. The root of each subtree represents a template of

103

the samples placed in the leaves of that subtree. The class (label) of a template is

determined by the label of the majority of the samples in the subtree rooted at the

template. However, if the number of classes M is not known a priori , M is set to the

number of well-separated branches based on the relative heights of the subtrees. The

roots of these well-separated subtrees represent the class templates, where within-class

variations (heights of the subtrees) are small relative to the between-class variations

(heights of the ancestors of the subtrees).

6.2.2 Classifying new samples with static templates

Let T1, T2, . . ., TM be M templates created from a collection of N samples, where

the ith template Ti summarizes samples of the ith class. The dissimilarity D(S, Ti)

between a sample S and a template Ti is computed by the mixed edge cover (MEC)

algorithm described in Chapter 4.

(Note that both a sample and a template are

characterized by ﬁnite mixtures of multivariate normal distributions each component

of which is a cluster or meta-cluster.) The new sample S is predicted to belong to

the class whose template it is most similar (least dissimilar) to:

i∗ = arg min
1≤i≤M

D(S, Ti),

class(S) = class(Ti∗).

(6.1)

During classiﬁcation, if the sample’s dissimilarity with the closest template is above

a threshold (i.e., it is not similar to any of the class templates), then it represents a

new class not represented by a template. Hence we need to create a new template for

this sample. I address this issue in the next section.

The template-based classiﬁcation is fast because we need to compare a new sample

only with M templates instead of with N samples. Let K be the maximum number of

clusters or meta-cluster present in a samples or template. Then the time complexity

of a classiﬁcation is O(M K 3 log K), where O(K 3 log K) time is required to compute

dissimilarity (mixed edge cover) between samples. Typically the number of distinct

classes (M ) is much smaller than the number of samples N . Hence, computing O(M )

dissimilarity is faster than classifying the sample from scratch, which requires O(N )

104

dissimilarity computations.

6.3 Building dynamic templates

6.3.1 The algorithm

The classiﬁcation method based on static templates has two limitations. First,

the algorithm requires a signiﬁcant number of samples from diﬀerent biological classes

to construct meaningful class templates. Hence, this approach is inadequate when

samples arrive sequentially or in batches, as for instance in a longitudinal study of

an epidemic. Second and more important, the algorithm builds a ﬁxed set of static

templates and does not update templates as new samples are classiﬁed. Therefore,

future classiﬁcation can not use the information gained from samples classiﬁed with

the static template-tree.

I address both of these limitations with dynamic updates of templates as new

samples are classiﬁed. The update operation is performed by inserting the new sample

into the current template-tree and updating necessary internal nodes (templates) in

the tree. Subsequent classiﬁcation tasks are performed on the regularly updated

templates. This approach also works when we do not have any training dataset to

begin with. In that case, the template-tree is created from the scratch by repeated

insertion of samples in a dynamic fashion starting with empty templates. Consider

an existing template-tree TT (possibly empty) with r as the root node. Note that r

can be considered as the template of all samples in the leaves of the tree. In order to

insert a new sample S in TT, I ﬁrst create a singleton node v from S. If TT is an empty

tree I make v the root of the template-tree, and otherwise, I insert v into the tree TT

by invoking the procedure insert shown in Fig. 6.1 with r and v as the parameters.

The procedure insert works in a recursive fashion. It follows a path from the

root to a node (a leaf or internal node), to be identiﬁed by the algorithm, where the

new node v is inserted. The procedure then backtracks by updating the mixtures of

1: procedure insert(u, v)

(cid:46) Insert leaf node v in the subtree rooted at u

105

if u is a empty then

(cid:46) Inserting in an empty tree

return v

end if

if u is a leaf then

w ← empty node, wl ← u, wr ← v, x ← w

else

D ← min{D(ul, ur), D(ul, v), D(ur, v)}
if D(ul, ur) = D then

w ← empty node, wl ← u, wr ← v, x ← w

else if D(ul, v) = D then

ul ← insert(ul, v), x ← u

else

ur ← insert(ur, v), x ← u

end if

end if

(cid:46) Case 1

(cid:46) Case 2

(cid:46) Case 3

(cid:46) when D(ur, v) = D, Case 4

2:

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

update node x by matching and merging meta-clusters from xl and xr

height(x) = D(xl, xr)

return x

(cid:46) Going up in the tree

20: end procedure

Figure 6.1.
(template or sample)

Inserting a leaf node (sample) v in a subtree rooted at u

the internal nodes found in the return path back to the root. I consider four cases

while inserting v in a subtree rooted at u. The cases are illustrated in Fig. 6.2. In the

ﬁrst case u is a leaf node, and I create a new node w and make u and v the children of

w. I create a template from the samples in the leaves u and v and save it in node w.

In the other cases u is an internal node. Let ul and ur be the left and right children

of u, respectively. I compute dissimilarities D(ul, ur), D(ul, v) and D(ur, v) between

106

Figure 6.2. Four cases to consider when inserting a leaf node v into the
subtree rooted at u. (a) case 1 (u is also a leaf): a new internal node w is
created and is made the parent of u and v, (b) case 2 (u is a non-leaf and
the left and right children of u are more similar to each other than to v):
a new internal node w is created and is made the parent of u and v, (c)
case 3 (u is a non-leaf and the left child ul of u is more similar to v than
to the right child ur):
insert v into the subtree rooted at ul by calling
insert(ul, v), and (d) case 4 (u is a non-leaf and the right child ur of u
is more similar to v than to the left child ul):
insert v into the subtree
rooted at ur by calling insert(ur, v). The dotted parts in Subﬁgure (c)
and (d) are determined by the insert function in a recursive fashion.

each pair of nodes from ul, ur, and v. If D(ul, ur) is the smallest among the three

dissimilarities, then v cannot be inserted in a subtree rooted at u. Thus I create a

new node w and make u and v the children of w. I create a new template from the

template u and sample v, save it in node w and return. When D(ul, v) is the smallest

dissimilarity, I insert v in a subtree rooted at ul by calling the procedure insert

with ul, v as parameters. In this case the left subtree of u gets updated. Similarly, if

D(ur, v) is the smallest then v is inserted in the right subtree rooted at ur.

6.3.2 Computational complexity

To insert a new sample, we need to traverse a path starting from the root to a leaf

or an internal node in a template-tree. In the worst case the length of the traversed

path is the height of the template-tree. Let N be the number of samples and h be
the height of a template-tree where (N − 1) ≤ h ≤ log2(N ). The former equality

ulur(a) case 1ul,vuur,vuuluvw(c) case 3(d) case 4(b) case 2uvw107

holds when the tree is completely unbalanced (a chain) whereas the latter equality is

satisﬁed when the tree is balanced. At each node in the traversed path we need to

compute three dissimilarities and one update operation (when backtracking). Let K

be the maximum number of clusters or meta-clusters in a node of the template-tree

and p be the dimension (number of features) of the data. A dissimilarity computation

takes O(K 3 log K) time whereas an update operation takes O(K 3 log K)+O(Kp) time

when meta-cluster parameters are computed by the maximum likelihood estimation.

Hence, the time complexity of inserting a sample in a template-tree is O(hK 3 log K).

6.3.3 Classifying a sample

To classify a new sample S, it is inserted into the current template-tree using

the procedure described in Fig. 6.1. The class of S is predicted to be the class of

the template created from the subtree where S is inserted. At the time of insertion

the template-tree is dynamically updated to reﬂect the information gained from the

new sample. The dynamic template approach is especially useful in unsupervised

classiﬁcation where the class labels of the samples are not known in advance.

In

that case, the class templates are created from the well-separated subtrees such that

within-class variations (heights of the subtrees) are small relative to the between-class

variations (heights of the ancestors of the subtrees). In this context, the algorithm

is similar to the spirit of the hierarchical clustering algorithm UPGMA, with signiﬁ-

cant diﬀerences in the distance computation and management of the internal nodes.

Furthermore, when a new sample is highly dissimilar to every existing template, the

algorithm automatically creates a new branch in the tree indicating a new class. This

approach therefore has the ability to discover unknown classes from the incoming

samples, which, for example, is very useful in detecting new strains of a disease.

The algorithm inserts samples into the template-tree in a particular order, which

can determine the relative positions of nodes in the template-tree. How sensitive

is the template-based classiﬁcation to the order in which the samples are inserted

108

into the template-tree? If the between-class variation is signiﬁcantly higher than the

within-class variation (as is the case in the two datasets studied in this chapter), the

classiﬁcation accuracy is unaﬀected by the small diﬀerences in the subtrees of the

template-tree. In current work, we are studying diﬀerent rearrangement techniques

for creating robust template-tree insensitive to the order of sample insertions.

6.4 Results

6.4.1 Classifying stimulation status of T cells

I apply the template-based classiﬁcation algorithm to classify the stimulation sta-

tus of 29 pairs of samples collected before and after stimulating blood with anti-CD3

antibody. Each of the 29 pairs of samples in the T cell phosphorylation (TCP) dataset

measures the abundance of four protein markers (CD4, CD45RA, SLP-76, and ZAP-

70) [44]. During the stimulation, anti-CD3 antibody binds with T cell receptors

(TCR) and phosphorylate few domains of naive and memory T cells. The eﬀect of

phosphorylation is revealed by the higher expressions of SLP-76 and ZAP-70 proteins

in T cells after the stimulation. Section 1.6.2 describes this dataset in detail.

For a pair of samples from the ith subject, I denote the unstimulated sample by
i− and the stimulated sample by i+. Each of the 58 samples in the TCP dataset
was preprocessed and clustered independently to identify four cell populations: (a)
CD4+CD45RAlow T cells, (b) CD4+CD45RAhigh T cells, (c) CD4−CD45RAhigh T
cells, and (d) CD4−CD45RAlow T cells (cf. Section 3.5.2). (Recall that ‘+’ and ‘high’
indicate higher abundances of a marker, and ‘−’ and ‘low’ indicate lower levels of it.)
Classiﬁcation with static templates: I divide 29 pairs samples randomly into a

training set and a test set. From the training samples, the HM&M algorithm con-

structs a template-tree where the left and right children of the root represent the pre-

and post-stimulation templates. Fig. 6.3 illustrates the classiﬁcation process with a

template tree created from six pairs of samples. After constructing the tree, it is cut

beneath the root to create the pre-stimulation (Tbefore) and post-stimulation (Tafter)

109

Figure 6.3. Illustration of sample classiﬁcation based on static templates.
The HM&M algorithm creates two templates, Tbefore for before-stimulation
and Tafter for after stimulation classes, from six pairs of samples in the TCP
dataset. A new sample is compared with the templates, and is classiﬁed
with the template it is most similar to.

templates. To predict the stimulation status of the ith sample Si in the test set, I com-

pute the dissimilarity D between Si and each of the templates with the cost of the op-

timum mixed edge cover algorithm. Si is predicted to come from the pre-stimulation

class when Si is more similar to Tbefore than to Tafter (i.e., D(Si, Tbefore) < D(Si, Tafter)),

and otherwise, from the post-stimulation class. In Fig. 6.3, I show a sample from the

test set above the two templates. The algorithm correctly classiﬁes it as a pre-

stimulation sample, and the correctness of the classiﬁcation can be veriﬁed visually

as this sample does not show a phosphorylation shift in SLP-76. (The 3-D scatter

plots are shown for visualization only; classiﬁcation is performed in 4-D.)

I study the accuracy of the template-based classiﬁer with a cross-validation. At

each stage of the cross-validation, training and test sets are created from 10 and 48

samples respectively. The status of each test sample is predicted by comparing it with

the templates created from the training set. A sample is considered to be misclassiﬁed

110

Figure 6.4. A dynamic template-tree created incrementally by adding the
samples in the TCP dataset one after another. Minus and plus signs are
appended to the subject number to indicate pre- and post-stimulation
samples. Pre-stimulation samples are in blue, and post-stimulation sam-
ples are red. The height of a node measures the dissimilarity between its
left and right children, whereas the horizontal placement of a sample is
arbitrary.

when its predicted class is diﬀerent from the actual class. This process is repeated

58 times for diﬀerent combinations of training and test sets. I observed that three

pre-stimulation samples, 9-, 10- and, 11-, were consistently classiﬁed with the after-

stimulation class whenever they were present in the test set. No other sample is

classiﬁed into a wrong class in the cross-validation. I consider these three samples

as outliers, show that they are likely to have been stimulated before the experiment,

and discuss their properties further in the following section.

Classiﬁcation with dynamic templates: In order to demonstrate the classiﬁcation

approach based on dynamic templates, I build a template-tree incrementally from the

samples in the TCP dataset. Starting with an empty tree, the algorithm described

in Sec. 6.3 inserts the samples one after another into the current tree. Fig. 6.4 shows

the complete template-tree where pre-stimulation samples are shown in blue and

post-stimulation samples are shown in red. Aside from three outlying samples, all

samples create two well-separated branches of the root denoting the pre- and post-

Dissimilarity Between Samples (Templates)0102030401−12−16−17−13−14−20−15−24−25−27−21−26−28−29−19−22−23−4−2−3−5−7−8−6−18−9−10−1+2+3+4+7+8+5+6+14+10+19+15+21+25+23+24+26+28+29+22+27+9+13+17+20+11+16+12+18+11−Before Stimulation (−)After Stimulation (+)111

Figure 6.5. Heat plot showing the dissimilarity between pairs of samples
in the TCP dataset where the color of a square corresponds to the dissim-
ilarity of a pair of samples. A square is drawn in a light shade when the
pair of samples is similar, and in a dark shade when the pair of samples
is highly dissimilar. The plot is symmetric about the main diagonal. The
samples are listed as they are ordered horizontally in Fig. 6.4.

stimulation templates. The height of an internal node in a template-tree is measured

by the dissimilarity between the pair of samples (templates) denoted by the left and

right children of the internal node. The height of the root in Fig. 6.4 is more than

twice of the height of any other node. Hence the algorithm successfully identiﬁes two

templates with small within-template deviation while maintaining a clear separation

between them.

When inserting a new sample S, the template-tree is dynamically updated to

reﬂect the information gained from the new sample. After insertion, the position

of S in the tree determines its predicted class. S is classiﬁed as a pre-stimulation

sample when it is placed in the left (blue) subtree and otherwise, classiﬁed as a post-

stimulation sample. Similar to the classiﬁcation with static templates, we observe in

Fig. 6.4 that all samples except 9-, 10- and 11-, are correctly classiﬁed.

Samples before stimulation                Samples after stimulationSamples after stimulation                Samples before stimulation11−18+12+16+11+20+17+13+9+27+22+29+28+26+24+23+25+21+15+19+10+14+6+5+8+7+4+3+2+1+10−9−18−6−8−7−5−3−2−4−23−22−19−29−28−26−21−27−25−24−15−20−14−13−17−16−12−1−1−12−16−17−13−14−20−15−24−25−27−21−26−28−29−19−22−23−4−2−3−5−7−8−6−18−9−10−1+2+3+4+7+8+5+6+14+10+19+15+21+25+23+24+26+28+29+22+27+9+13+17+20+11+16+12+18+11−0102030405060112

Figure 6.6. Levels of SLP-76 expression in each pair of samples (joined by
a line) from the TCP dataset. For most samples, SLP-76 levels increase
after the anti-CD3 stimulation. However, the three samples {9, 10, 11}
have high levels of SLP-76 protein in their pre-stimulation states, and do
not show the usual increase after stimulation.

Outlying samples: Now I discuss the three outlying pre-stimulation samples, 9-

, 10- and 11-, which are consistently classiﬁed with the post-stimulation samples by

both the static and dynamic classiﬁcation algorithms. Fig. 6.5 shows the dissimilarity

between every pair of samples in the dataset in a heatplot where a square is drawn

in a lighter shade when a pair of samples is similar, and in darker shade when a pair

of samples is highly dissimilar. We observe that most squares in the top-left and

bottom-right quadrants are in light colors indicating similarity among samples within

pre- and post-stimulation classes. However, three pre-stimulation samples, 9-, 10-

and 11-, are more similar to the post-stimulation samples than to the pre-stimulation

samples. This anomaly can be explained by plotting the average expression of SLP-76
protein for each pair of samples in Figure 6.6. The three outlying samples {9, 10, 11}
have much higher levels of SLP-76 than the remaining samples in their pre-stimulation

states. On stimulation, two of these samples have decreased levels of SLP-76, while

one shows an increase. Consequently these samples are classiﬁed with the post-

stimulations samples by the templates-based classiﬁcation algorithms presented here.

0.10.20.30.40.50.6BeforeStimulationAfterStimulationStimulationstatusExpressionlevelsof SLP-76 proteinNormalsamplesOutlyingsamples(9,10,11)113

Figure 6.7. The template-tree created from samples in the healthy donor
dataset. The algorithm identiﬁes ﬁve well separated branches denoting
templates for the ﬁve subjects. A subtree consisting of samples from the
same subject is shown in same color.

6.4.2 Classifying immune patterns in healthy individuals

I further validated the template-based classiﬁcation with a healthy donor (HD)

dataset described in Section 1.6.1. The HD dataset represents a “biological simu-

lation” where peripheral blood mononuclear cells (PBMC) were collected from ﬁve

healthy subjects on diﬀerent days, and each sample was divided into ﬁve parts and

analyzed through a ﬂow cytometer at Purdue’s Bindley Biosciences Center. Each of

the 65 samples is preprocessed, variance stabilized, and clustered to identify four cell

populations: (a) helper T cells (CD3+CD4+), (b) cytotoxic T cells (CD3+CD8+), (c)
B cells (CD3−CD19+), and (d) natural killer cells (CD3−CD19−). Detail discussion

about the clustering step can be found in Section 3.5.1.

A template tree is created from the 65 samples in the HD dataset by repeated inser-

tion of samples with the procedure described in Sec. 6.3. Fig. 6.7 shows the complete

template-tree where samples from ﬁve individuals are shown in ﬁve diﬀerent colors.

114

We observe that samples from the ﬁve subjects create ﬁve well-separated branches and

the roots of the ﬁve branches denote subject-speciﬁc templates. Intuitively we expect

samples from each subject to be classiﬁed together. Here, the within-subject varia-

tions of a subject come from day-to-day natural variations and technical variations in

ﬂow cytometry sample preparation and measurement, whereas the between-subject

variations come from the innate biological variability in the healthy subjects. In this

dataset we observe more natural variation than the temporal and technical variations.

The observations from the healthy donor dataset conﬁrm that we can build im-

mune proﬁles for individuals despite within-subject variations from diﬀerent sources.

Additionally, the ﬁve templates from the ﬁve subjects create another level of hierar-

chy and the root of the tree in Fig. 6.7 can be considered as a template for healthy

individuals. This combined template represents a healthy immune proﬁle by preserv-

ing the common features of healthy individuals and by removing between subject

variations. This template can be compared against templates created from diseased

samples in order to diagnose diseases and to perform comparative study of healthy

and diseased immune proﬁles.

6.5 Conclusions

I describe template-based classiﬁcation methods for ﬂow cytometry samples dis-

playing a combination of diﬀerent immunophenotypes. A template built from samples

of a class provides a concise description of the class by emphasizing the key character-

istics while masking statistical noise and low-level details, and thus helps to measure

overall changes in cell populations across diﬀerent conditions. By moving beyond

sample-speciﬁc variations, the templates act as the blueprints for diﬀerent classes,

and can be used to classify future samples to diﬀerent classes in a more relevant pa-

rameter space. It is also more eﬃcient to classify a sample using templates rather

than all of the previously seen samples. I maintain a hierarchy of the samples in a

template-tree such that samples can be analyzed in higher resolution as needed.

115

The major contribution in this chapter is a dynamic algorithm to construct and

update the templates, and build and maintain the template-tree, when the samples

arrive continuously over a period of time. As new samples come in, the templates are

dynamically updated to reﬂect the information gained from them. This is a desirable

property in dynamic situations, as in the course of an epidemic, when new samples

are being collected and analyzed. Another context where the dynamic classiﬁcation

approach is useful is when the samples are collected at a large number of hospitals or

labs; the data at each hospital can be analyzed in situ, and only the summaries need

to be shared among the hospitals to create a global proﬁle of the immune system,

thus avoiding issues with privacy of clinical data.

Dynamic classiﬁcation is a critical step towards characterizing diverse states of

the human immune system from big datasets of samples collected at geograph-

ically distributed laboratories, e.g., the Human Immunology Project Consortium

(www.immuneprofiling.org). This work makes it possible to summarize the data

from each laboratory using templates for each class, and then to merge the templates

and template-trees across various laboratories, as the data is being continuously col-

lected and analyzed.

116

7 CLASSIFICATION OF ACUTE MYELOID LEUKEMIA

7.1 Introduction

Can Acute Myeloid Leukemia (AML) samples be distinguished from healthy ones

using ﬂow cytometry data from blood or bone marrow with a template-based clas-

siﬁcation method? This method builds a template for each class to summarize the

samples belonging to the class, and uses them to classify new samples as described in

Chapter 6. This question is interesting because AML is a heterogeneous disease with

several subtypes and hence it is not clear that a template can succinctly describe all

types of AML. Furthermore, we wish to identify immunophenotypes (cell types in the

bone marrow and blood) that are known to be characteristic of subtypes of AML.

Pathologists use these immunophenotypes to visualize AML and its subtypes, and a

computational procedure that can provide this information would be more helpful in

clinical practice than a classiﬁcation score that indicates if an individual is healthy

or has AML.

In Chapter 6, I described a template-based classiﬁcation framework for analyzing

ﬂow cytometry (FC) data [46]. In this framework, each sample is characterized by

means of the cell populations that it contains. Similar samples belonging to the same

class are described by a template for the class. A template consists of meta-clusters

that characterize the cell populations present in the samples that constitute the class.

I described a hierarchical algorithm in Chapter 5 that organizes the templates into a

template tree. Given a sample to classify, we can compare it with the nodes in the

template tree, and classify it to the template that it is closest to. A combinatorial

measure for the dissimilarity of two samples or two templates, computed by means

of a mixed edge cover in a graph model (described in Chapter 4), is at the heart of

this approach.

117

The algorithmic pipeline for template-based classiﬁcation has been applied to

various problems: to distinguish the phosphorylation state of T cells; to study the

biological, temporal, and technical variability of cell types in the blood of healthy

individuals; to characterize changes in the immune cells of Multiple Sclerosis patients

undergoing drug treatments; and to predict the vaccination status of HIV patients [37,

46]. However, it is not clear if the AML data set can be successfully analyzed with

this scheme, since AML is a heterogeneous disease at the morphologic, cytogenetic

and molecular levels, and a few templates may not describe all of its subtypes.

AML is a disease of myeloid stem cells that diﬀerentiate to form several types

of cells in the blood and marrow.

It is characterized by the profusion of imma-

ture myeloid cells, which are usually prevented from maturing due to the disease.

The myeloid stem cell diﬀerentiates in several steps to form myeloblasts and other

cell types in a hierarchical process. This hierarchical diﬀerentiation process could

be blocked at diﬀerent cell types, leading to the multiple subtypes of AML. Eight

diﬀerent subtypes of AML based on cell lineage are included in the French-American-

British Cooperative Group (FAB) classiﬁcation scheme [165].

(A diﬀerent World

Health Organization (WHO) classiﬁcation scheme has also been published.) Since

the prognosis and treatment varies greatly among the subtypes of AML, accurate

diagnosis is critical.

In this chapter, I extend the template-based classiﬁcation scheme presented in

Chapter 6 by developing a scoring function that accounts for the subtleties of FC data

of AML samples [45]. Only a small number of the myeloid cell populations in AML

samples are speciﬁc to AML, and there are a larger number of cell populations that

these samples share with healthy samples. Furthermore, the scoring function needs

to account for the diversity of the myeloid cell populations in the various subtypes of

AML. This approach has the advantage of identifying immunophenotypes of clinical

interest in AML from the templates. Earlier work on the AML dataset used in

this chapter has classiﬁed AML samples using methods such as nearest neighbor

118

classiﬁcation, logistic regression, matrix relevance learning vector quantization, etc.,

but they have not identiﬁed these immunophenotypes; e.g., [166–168].

Template-based classiﬁcation has the advantage of being more robust than simple

nearest neighbor classiﬁcation since a template summarizes the characteristic prop-

erties of a class while ignoring small sample-to-sample variations. It is also scalable

to large numbers of samples, since it compares a sample to be classiﬁed only against

a small number of templates rather than the much larger number of samples. The

comparisons with the templates can be performed eﬃciently using the structure of

the template tree. It also reduces the data size by clustering the data to identify cell

populations and then working with the statistical distributions characterizing the cell

populations, in contrast to some of the earlier approaches that work with data sets

even larger than the FC data by creating multiple variables from a marker (reciprocal,

powers, products and quotients of subsets of the markers, etc. [167]).

Template-based classiﬁcation has been employed in other areas such as character,

face, and image recognition, but its application to FC is relatively recent. In addition

to our work, templates have been used for detecting the eﬀects of phosphorylation [27],

evaluating the eﬃciency of data transformations [23], and labeling clusters across

samples [39].

7.2 Methods

7.2.1 The AML Dataset

I have used an FC dataset on AML that was included in the DREAM6/FlowCAP2

challenge of 2011 [169]. The dataset consists of FC measurements of peripheral blood

or bone marrow aspirate collected from 43 AML positive patients and 316 healthy

donors over a one year period. Each patient sample was subdivided into eight aliquots

(“tubes”) and analyzed with diﬀerent biomarker combinations, ﬁve markers per tube

(most markers are proteins) as described in Table 7.1. In addition to the markers, the

forward scatter (FS) and side scatter (SS) of each sample was also measured in each

The ﬂuorophore-conjugated antibodies contained in each of the 8 tubes in
which the samples were incubated.

Table 7.1

119

Tubes

FL1

FL2

FL3

FL4

FL5

(FITC)

(PE)

(ECD)

(PC5)

(PC7)

1

2

3

4

5

6

7

8

IgG1

IgG1

CD45

IgG1

IgG1

Kappa

Lambda

CD45

CD19

CD20

CD7

CD15

CD14

CD4

CD13

CD11c

HLA-DR CD117

CD5

NA

CD19

NA

CD45

CD45

CD45

CD45

CD45

NA

CD8

CD2

CD16

CD56

CD64

CD33

CD34

CD38

CD3

NA

CD10

NA

tube. Hence, the dataset contains 359× 8 = 2, 872 samples and each sample is seven-
dimensional (ﬁve markers and the two scatters). Tube 1 is an isotype control used to

detect non-speciﬁc antibody binding and Tube 8 is an unstained control for identifying

background or autoﬂuorescence of the system. Since the data has been compensated

for autoﬂuorescence and spectral overlap by experts, I omit these tubes from the

analysis. The disease status (AML/healthy) of 23 AML patients and 156 healthy

donors are provided as training set, and the challenge is to determine the disease status

of the rest of the samples, 20 AML and 157 healthy, based only on the information in

the training set. The complete dataset is available at http://flowrepository.org/.

The side scatter (SS) and all of the ﬂuorescence channels are transformed loga-

rithmically, but the forward scatter (FS) is linearly transformed to the interval [0,1]

so that all channels have values in the same range. This removes any bias towards

FS channel in the multi-dimensional clustering phase. After preprocessing, an FC
sample is stored as an n × p matrix A, where the element A(i, j) quantiﬁes the jth

120

feature in the ith cell, and p is the number of features measured in each of n cells. In

this dataset, p = 7 for each tube and n varies among the samples.

7.2.2 Identifying cell populations in each sample

I employ a two-stage clustering approach for identifying phenotypically similar

cell populations (homogeneous clusters of cells) in each sample. At ﬁrst, I apply the

k-means clustering algorithm for a wide range of values for k, and select the optimum
number of clusters k∗ by simultaneously optimizing the Calinski-Harabasz and S Dbw

cluster validation methods [34]. Next, the clusters identiﬁed by the k-means algorithm

are modeled with a ﬁnite mixture model of multivariate normal distributions. In the

mixture model, the ith cluster is represented by two distribution parameters µi, the
p-dimensional mean vector, and Σ, the p × p covariance matrix. The distribution
parameters for each cluster are then estimated using the Expectation-Maximization

(EM) algorithm. The statistical parameters of a cluster are used to describe the

corresponding cell population in the rest of the analysis. The population identiﬁcation

process is described in Chapter 3.

7.2.3 Creating templates from a collection of samples

The hierarchical matching-and-merging (HM&M) algorithm described in Chap-

ter 5 is used to create templates representing distinct classes of samples. The HM&M

algorithm arranges a set of similar samples into a binary template tree data struc-

ture [36]. The dissimilarity between a pair of samples is computed by the cost of

optimum mixed edge cover solution discussed in Chapter 4.

7.2.4 Classiﬁcation score of a sample in AML dataset

Consider a sample X consisting of k cell populations S = {c1, c2, ..., ck}, with
the ith cluster ci containing |ci| cells. Let T − and T + be the templates created from

121

AML-negative (healthy) and AML-positive training samples, respectively. I describe

how to compute a score f (X) in order to classify the sample X to either the healthy

class or the AML class.

The intuition behind the score is as follows. An AML sample contains two kinds

of cell populations: (1) AML-speciﬁc myeloblasts and myeloid cells, and (2) AML-

unrelated cell populations, such as lymphocytes. The former cell populations corre-

spond to the immunophenotypes of AML-speciﬁc metaclusters in the AML template,

and hence when we compute a mixed edge cover between the AML template and an

AML sample, these clusters get matched to each other. (Such clusters in the sample

do not match to any metacluster in the healthy template.) Hence a positive score

is assigned to a cluster in sample when it satisﬁes this condition, signifying that it

is indicative of AML. AML-unrelated cell populations in a sample could match to

meta-clusters in the healthy template, and also to AML-unrelated meta-clusters in

the AML template. When either of these conditions is satisﬁed, a cluster gets a neg-

ative score, signifying that it is not indicative of AML. Since AML aﬀects only the

myeloid cell line and its progenitors, it aﬀects only a small number of AML-speciﬁc cell

populations in an AML sample. Furthermore, diﬀerent subtypes of AML aﬀect diﬀer-

ent cell types in the myeloid cell line. Hence, there are many more clusters common

to healthy samples than there are AML-speciﬁc clusters common to AML samples.

(This is illustrated later in Fig. 7.2 (c) and (d).) Thus the range of positive scores

are made relatively higher than the range of negative scores. This scoring system is

designed to reduce the possibility of a false negative (an undetected AML-positive

patient), since this is more serious in the diagnosis of AML. Additional data such

as chromosomal translocations and images of bone marrow from microscopy could

conﬁrm an initial diagnosis of AML from ﬂow cytometry.

In the light of the discussion above, we need to identify AML-speciﬁc metaclusters
initially. Given the templates T + and T −, we create a complete bipartite graph with

the meta-clusters in each template as vertices, and with each edge weighted by the

Mahalanobis distance between its endpoints. A minimum cost mixed edge cover

122

solution in this graph will match meta-clusters common to both templates, and such

meta-clusters represent non-myeloid cell populations that are not AML-speciﬁc. On

the other hand, meta-clusters in the AML template T + that are not matched to a
meta-cluster in the healthy template T − correspond to AML-speciﬁc metaclusters.
Such meta-clusters in the AML template T + are denoted by the set M +.

Now we can proceed to compare a sample against the template for healthy samples

and the template for AML. I compute a minimum cost mixed edge cover between
a sample X and the healthy template T −, and let mec−(ci) denote the set of meta-
clusters in T − mapped to a cluster ci in the sample X. Similarly, compute a minimum
cost mixed edge cover between X and the AML template T +, and let mec+(ci) denote

the set of meta-clusters in T + mapped to a cluster ci. These sets could be empty if ci

is unmatched in the mixed edge cover. I compute the average Mahalanobis distance
between ci and the meta-clusters matched to it in the template T −, and deﬁne this as
the dissimilarity d(ci, mec−(ci)). From the formulation of the mixed edge cover in [37],
we have d(ci, mec−(ci)) ≤ 2λ, where λ is the cost of leaving a cluster unmatched
in the mixed edge cover solution. Hence we can deﬁne the similarity between ci
and mec−(ci) as s(ci, mec−(ci)) = 2λ − d(ci, mec−(ci)). By analogous reasoning, the
similarity between ci and mec+(ci) is deﬁned as s(ci, mec+(ci)) = 2λ − d(ci, mec+(ci)).
The score of a sample is the sum of the scores of its clusters. I deﬁne the score
of a cluster ci, f (ci), as the sum of two functions f +(ci) and f−(ci) multiplied with
suitable weights. A positive score indicates that the sample belongs to AML, and a

negative score indicates that it is healthy.

The function f +(ci) contributes a positive score to the sum if ci is matched to an

AML-speciﬁc meta-cluster in the mixed edge cover between the sample X and the

AML template T +, and a non-positive score otherwise. For the latter case, there are

two subcases: If ci is unmatched in the mixed edge cover, it corresponds to none of

the meta-clusters in the template T +, and gets a zero score. If ci is matched only to

non-AML speciﬁc meta-clusters in the AML template T +, then it is assigned a small

123



negative score to indicate that it likely belongs to the healthy class (recall that k is

the number of clusters in sample X). Hence

f +(ci) =

s (ci, mec+(ci)) ,
− 1

k [s(ci, mec+(ci))] ,

0,

if mec+(ci) ∩ M + (cid:54)= ∅,
if mec+(ci) ∩ M + = ∅, and mec+(ci) (cid:54)= ∅,
if mec+(ci) = ∅.

The function f−(ci) contributes a negative score to a cluster ci in the sample X
if it is matched with some meta-cluster in the healthy template T −, indicating that
it likely belongs to the healthy class. If it is not matched to any meta-cluster in T −,

then it is assigned a positive score λ. This latter subcase accounts for AML-speciﬁc

clusters in the sample, or a cluster that is in neither template. In this last case, we

acknowledge the diversity of cell populations in AML samples. Hence we have

− 1

λ,

f−(ci) =

k [s(ci, mec−(ci))] ,

if mec−(ci) (cid:54)= ∅,
if mec−(ci) = ∅.

Finally, we deﬁne

(cid:88)

ci∈X

|ci|
|X|

1
2

f (X) =

(f +(ci) + f−(ci)).

(7.1)

Here |X| is the number of cells in the sample X. The score of a cluster ci is weighted
by the fractional abundance of cells in it.

7.3 Results

7.3.1 Cell populations in healthy and AML samples

In each tube, I identify cell populations in the samples using the clustering al-

gorithm described in Section 7.2.2. Each sample contains ﬁve major cell types that

can be seen when cell clusters are projected on the side scatter (SS) and CD45 chan-

nels, as depicted in Fig. 7.1. (Blast cells are immature progenitors of myeloid cells

124

Figure 7.1. Cell types identiﬁed on the side scatter (SS) and CD45 chan-
nels for a healthy and an AML positive sample. Cell populations are dis-
covered in the seven-dimensional samples with the clustering algorithm
and then projected on these channels for visualization. A pair of clusters
denoting the same cell type is marked with the same color. The proportion
of myeloid blast cells (shown in red) increases signiﬁcantly in the AML
sample.

or lymphocytes.) The side scatter measures the granularity of cells, whereas CD45

is variably expressed by diﬀerent white blood cells (leukocytes). AML is initially di-

agnosed by rapid growth of immature myeloid blast cells with medium SS and CD45

expressions [141] marked in red in Fig. 7.1. According to the WHO guidelines, AML

is initially conﬁrmed when the sample contains more than 20% blasts. This is the

case for all, except one of the AML samples in the DREAM6/FlowCAP2 training set,

and the latter will be discussed later.

7.3.2 Healthy and AML templates

From each tube of the AML dataset, using the training samples, we build two

templates: one for healthy samples, and one for AML. As described in Section 7.2.3,

the HM&M algorithm organizes samples of the same class into a binary template

tree whose root represents the class template. The template trees created from the

healthy and AML training samples in Tube 6 are shown in Subﬁgures 7.2(a) and

7.2(b) respectively. The height of an internal node in the template tree measures

0.20.40.60.80.20.40.60.8CD45−ECD(log)SS(log)0.20.40.60.80.20.40.60.8CD45−ECD(log)SS(log)LymphocytesLymphoid blastsMyeloid cellsMyeloid blastsMonocytesNormalAML1.5%28%125

Figure 7.2. The healthy and AML templates created from Tube 6. (a)
The template-tree created from 156 healthy samples in the training set.
(b) The template-tree created from 23 AML samples in the training set.
Samples in the red subtree exhibit the characteristics of Acute Promye-
locytic Leukemia (APL) as shown in Subﬁgure (f). (c) Fraction of 156
healthy samples present in each of the 22 meta-clusters in the healthy
template. Nine meta-clusters, each of them shared by at least 60% of the
healthy samples, form the core of the healthy template. (d) Fraction of
23 AML samples present in each of the 40 meta-clusters in the AML tem-
plate. The AML samples, unlike the healthy ones, are heterogeneously
distributed over the meta-clusters. (e) The expression levels of markers
in the meta-cluster shown with blue bar in Subﬁgure (d). (Each hori-
zontal bar in Subﬁgures (e) and (f) represents the average expression of
a marker and the error bar shows its standard deviation.) This meta-
cluster represents lymphocytes denoted by medium SS and high CD45
expression and therefore does not express the AML-related markers mea-
sured in Tube 6. (f ) Expression of markers in a meta-cluster shown with
red bar in Subﬁgure (d). This meta-cluster denotes myeloblast cells as
deﬁned by the SS and CD45 levels. This meta-cluster expresses HLA-
DR−CD117+CD34−CD38+, a characteristic immunophenotype of APL.
Five AML samples sharing this meta-cluster are similar to each other as
shown in the red subtree in Subﬁgure (b).

020406080100116101717249103885269601053313417416515195117896737580204060801000204060801000.00.20.40.6SSCD45HLA−DRCD117CD34CD380.00.20.40.6SSCD45HLA−DRCD117CD34CD38010203040Dissimilaritybetweensamples(templates)862313714514213182721291011051514654128461169365621401301185839919124155501105713139134156517810089676041437191144714731473014321092711181536175901174126979998244959448312795104512534144761031154204287521357438361121768150577641021211670312322148488421923796942963111791331151201061411386615126152132563385802569311071198812211353136325561088711214940812810435Expression levels of markersMeta-clusters in the AML templateMeta-clusters in the healthy templateFraction of samples present  in a meta-cluster (%)Fraction of samples present  in a meta-cluster (%)Healthy individuals AML positive patients Dissimilarity between samples (templates)Dissimilarity between samples (templates)(a)(b)(c)(d)(e)(f)APL 126

the dissimilarity between its left and right children, whereas the horizontal placement

of a sample is arbitrary. In these trees, we observe twice as much heterogeneity in

the AML samples than among the healthy samples (in the dissimilarity measure),

despite the number of healthy samples being ﬁve times as numerous as the AML

samples. The larger heterogeneity among AML samples is observed in other tubes as

well. The template-tree for AML partitions these samples into diﬀerent subtrees that

possibly denote diﬀerent subtypes of AML. For example, the subtree in Fig. 7.2(b)

that is colored red includes samples (with subject ids 37, 58, 67, 89, and 117) with

immunophenotypes of Acute Promyelocytic Leukemia (APL) (discussed later in this

section).

Together, the meta-clusters in a healthy template represent a healthy immune

proﬁle in the feature space of a tube from which the template is created. 22 meta-

clusters are obtained in the healthy template created from Tube 6. The percentage

of samples from the training set participating in each of these meta-clusters is shown

in Fig. 7.2(c). Observe that 60% or more of the healthy samples participate in the

nine most common meta-clusters (these constitute the core of the healthy template).

The remaining thirteen meta-clusters include populations from a small fraction of

samples. These populations could correspond to biological variability in the healthy

samples,variations in the FC experimental protocols, and possibly also from the split-

ting of populations that could be an artifact of the clustering algorithm.

The AML template created from Tube 6 consists of forty meta-clusters (almost

twice the number in the more numerous healthy samples). Fig. 7.2(d) shows that,

unlike the healthy samples, the AML samples are heterogeneous with respect to the

meta-clusters they participate in: There are 21 meta-clusters that include cell popu-

lations from at least 20% of the AML samples. Some of the meta-clusters common

to a large number of AML samples represent non-AML speciﬁc cell populations. For

example, Fig. 7.2(e) shows the average marker expressions of the meta-cluster shown

in the blue bar in Fig. 7.2(d). This meta-cluster has low to medium side scatter

and high CD45 expression, and therefore represents lymphocytes (Fig. 7.1). Since

127

lymphocytes are not aﬀected by AML, this meta-cluster does not express any AML-
related markers, and hence can be described as HLA-DR−CD117−CD34−CD38−, as

expected. Fig. 7.2(f) shows the expression proﬁle of another meta-cluster shown in

the red bar in Fig. 7.2(d). This meta-cluster consists of ﬁve cell populations from ﬁve

AML samples (with subject ids 37, 58, 67, 89, and 117) and exhibits medium side

scatter and CD45 expression and therefore, represents myeloid blast cells. Further-
more, this meta-cluster is HLA-DR−CD117+CD34−CD38+, and represents a proﬁle

known to be that of Acute Promyelocytic Leukemia (APL) [170]. APL is subtype

M3 in the FAB classiﬁcation of AML [165]) and is characterized by chromosomal

translocation of retinoic acid receptor-alpha (RARα) gene on chromosome 17 with

the promyelocytic leukemia gene (PML) on chromosome 15, a translocation denoted

as t(15;17). In the feature space of Tube 6, these APL samples are similar to each

other while signiﬁcantly diﬀerent from the other AML samples. The template-based

classiﬁcation algorithm groups these samples together in the subtree colored red in

the AML template tree shown in Fig. 7.2(b).

7.3.3 Identifying meta-clusters symptomatic of AML

In each tube, meta-clusters are registered across the AML and healthy templates
√

using the mixed edge cover (MEC) algorithm. The unmatch-penalty λ is set to

7

so that a pair of meta-clusters get matched only if the average squared deviation

across all dimensions is less than one. Meta-clusters in the AML template that are

not matched to any meta-clusters in the healthy template represent the abnormal,

AML-speciﬁc immunophenotypes while the matched meta-clusters represent healthy

or non-AML-relevant cell populations. Table 7.2 lists several unmatched meta-clusters

indicative of AML from diﬀerent tubes. As expected, every unmatched meta-cluster

displays medium side scatter and CD45 expression characteristic of myeloid blast cells,

and therefore we can omit FS, SS, and CD45 values in Table 7.2. I brieﬂy discuss

128

Table 7.2

Some of the meta-clusters characteristic of AML for the 23 AML samples
in the training set. In the second column, ‘−’, ‘low’, and ‘+’ denote very
low, low and high, abundance of a marker, respectively, and ± denotes
a marker that is positively expressed by some samples and negatively
expressed by others. The number of samples participating in a meta-
cluster is shown in the third column. The average fraction of cells in a
sample participating in a meta-cluster, and the standard deviation, are
shown in the fourth column.

Tube

Marker expression

#Samples Fraction of cells

2

3

4

4

5

5

5

6

6

6

7

7

7

KappalowLambdalowCD19+CD20−

CD7+CD4−CD8−CD2−

CD15−CD13+CD16−CD56−
CD15−CD13+CD16−CD56+
CD14−CD11c−CD64−CD33+
CD14−CD11c+CD64−CD33+
CD14lowCD11c+CD64lowCD33+

HLA-DR+CD117+CD34+CD38+
HLA-DR+CD117±CD34+CD38+
HLA-DR−CD117±CD34−CD38+

CD5−CD19+CD3−CD10−
CD5+CD19−CD3−CD10−
CD5−CD19−CD3−CD10+

5

4

17

8

10

18

6

11

13

5

3

3

1

6.3%(±6.8)
18.0%(±4.8)
16.6%(±6.9)
11.1%(±5.7)
13.5%(±5.2)
10.8%(±3.8)
13.8%(±4.3)
13.3%(±2.6)
17.3%(±6.6)
12.9%(±4.7)
12.3%(±2.4)
10.0%(±8.5)

9.9%

the immunophenotypes represented by each AML-speciﬁc meta-cluster in each tube,

omitting the isotype control Tube 1 and unstained Tube 8.

Tube 6 is the most important panel for diagnosing AML since it includes several

markers expressed by AML blasts. HLA-DR is an MHC class II cell surface receptor

complex that is expressed on antigen-presenting cells, e.g., B cells, dendritic cells,

macrophages, and activated T cells. It is expressed by myeloblasts in most subtypes

of AML except M3 and M7 [171]. CD117 is a tyrosine kinase receptor (c-KIT)

129

expressed in blasts of some cases (30 − 100%) of AML [171]. CD34 is a cell adhesion
molecule expressed on diﬀerent stem cells and on the blast cells of many cases of

AML (40%) [172]. CD38 is a glycoprotein found on the surface of blasts of several

subtypes of AML but usually not expressed in the M3 subtypes of AML [173]. In Tube

6, the matching algorithm has identiﬁed two AML-speciﬁc meta-clusters with high

expressions of HLA-DR and CD34. One of them also expresses CD117 and CD34,

and Fig. 7.3(c) shows the bivariate contour plots of the cell populations contained

in this meta-cluster. The second meta-cluster expresses positive but low levels of

CD117 and CD34. These two HLA-DR+CD34+ meta-clusters together are present

in 18 out of the 23 training AML samples. The remaining ﬁve samples (subject id:
5, 7, 103, 165, 174) express HLA-DR−CD117±CD34−CD38+ myeloblasts, which is

an immunophenotype of APL [170] as was discussed earlier. Fig. 7.3(d) shows the

bivariate contour plots of this APL-speciﬁc meta-cluster.

Tube 5 contains several antigens typically expressed by AML blasts, of which

CD33 is the most important. CD33 is a transmembrane receptor protein usually

expressed on immature myeloid cells of the majority of cases of AML (91% reported

in [174]). The AML speciﬁc meta-clusters identiﬁed from markers in Tube 5 (see

Table 7.2) include CD33+ myeloblasts from every sample in the training set. Several

of the CD33+ populations also express CD11c, a type I transmembrane protein found

on monocytes, macrophages and neutrophils. CD11c is usually expressed by blast

cells in acute myelomonocytic leukemia (M4 subclass of AML), and acute monocytic
leukemia (M5 subclass of AML) [171]. Therefore CD14−CD11c+CD64−CD33+ meta-

cluster could represent patients with M4 and M5 subclasses of AML. I show the

bivariate contour plots of this meta-cluster in Fig. 7.3(b) .

Tube 4 includes several markers usually expressed by AML blasts, of which CD13

is the most important. CD13 is a zinc-metalloproteinase enzyme that binds to the cell

membrane and degrades regulatory peptides [172]. CD13 is expressed on the blast

cells of the majority of cases of AML (95% as reported in [174]). Table 7.2 shows

two AML-speciﬁc meta-clusters detected from the blast cells in Tube 4. Both of the

130

meta-clusters are CD13+ and they include populations from every AML sample in

the training set. In addition to CD13, eight AML samples express CD56 glycoprotein

that is naturally expressed on NK cells, a subset of CD4+ T cells and a subset of

CD8+ T cells. Raspadori et al. [175] reported that CD56 was more often expressed

by myeloblasts in FAB subclasses M2 and M5, which covers about 42% of AML cases

in a study by Legrand et al. [174]. In this dataset, we observe more AML samples ex-
pressing CD13+CD56− blasts than expressing CD13+CD56+ blasts, which conforms

to the ﬁndings of Raspadori et al. [175]. Fig. 7.3(a) shows the bivariate contour plots
of the CD13+CD56− meta-cluster. CD15 is a carbohydrate adhesion molecule (not a

protein) expressed on mature glycoproteins and CD16 is an Fc (Fragment, crystalliz-

able) receptor protein expressed on mature NK cells, macrophages, and neutrophils.

They are not usually expressed by myeloblasts and were absent in the AML-related

meta-clusters.

Tube 2 is a B cell panel measuring B cell markers CD19 and CD20, and Kappa

(κ) and Lambda (λ), immunoglobulin light chains present on the surface of antibodies

produced by B lymphocytes. This panel is used in diagnosing diseases such as B-cell

lymphomas and acute lymphoblastic leukemia (ALL) [171]. B-cell speciﬁc markers

are occasionally co-expressed with myeloid antigens especially in FAB M2 subtype of

AML (with chromosomal translocation t(8;21)) [171, 176]. In Tube 2, the matching

algorithm has identiﬁed a meta-cluster in the myeloblasts that expresses high levels

of CD19 and low levels of Kappa and Lambda. The ﬁve samples with subject ids 5,

7, 103, 165, and 174 participating in this meta-cluster possibly belong to the FAB-M2

subtype of AML.

Tube 3 is a T cell panel measuring T cell speciﬁc markers CD4, CD8, CD2, and

CD7. This panel is frequently used in diagnosing T-lineage ALL [171,172]. In signiﬁ-

cant minority of cases of AML (e.g., 37% of cases reported in [174]), CD7 is aberrantly

expressed by myeloblasts [171]. The matching algorithm identiﬁes a meta-cluster in
the blast region, which includes four populations expressing CD7+CD4−CD8−CD2−.

131

individual marker)
Figure 7.3. Bivariate contour plots (side scatter vs.
for two meta-clusters (one in each row) indicative of AML. The ellipses
in a subplot denote the 95th quantile contour lines of cell populations in-
cluded in the corresponding meta-cluster. Myeloblast cells have medium
side scatter (SS) and CD45 expressions. The red lines indicate approxi-
mate myeloblast boundaries (located on the left-most subﬁgures in each
row and extended horizontally to the subﬁgures on the right) and conﬁrm
that these meta-clusters represent immunophenotypes of myeloblast cells.
Blue vertical lines denote the +/- boundaries of a marker. Gray subplots
show contour plots of dominant markers deﬁning the meta-cluster in the
same row. (a) HLA-DR+CD117+CD34+CD38+ meta-cluster shared by
11 AML samples in Tube 6. (b) HLA-DR−CD117±CD34−CD38+ meta-
cluster shared by 5 AML samples in Tube 6. This meta-cluster is in-
dicative of acute promyelocytic leukemia (APL). These bivariate plots are
shown for illustration only, since the populations of speciﬁc cell types are
identiﬁed from seven-dimensional data.

This ﬁnding conﬁrms that T cell antigens are infrequently expressed by AML blasts,

and therefore, they are less useful in AML diagnosis and classiﬁcation.

Tube 7 is a lymphocyte panel with several markers expressed on T and B lym-

phocytes and is less important in detecting AML since they are infrequently expressed

by AML blasts. In Tube 7, we obtain three samples with CD19+, three samples with

CD5+ and a sample with CD10+ myeloblast cells. The meta-clusters in rows 11-13

in Table 7.2 conﬁrm that lymphocyte antigens are infrequently expressed by AML

blasts and are less useful in AML diagnosis and classiﬁcation [171, 176].

0.00.20.40.60.81.00.00.20.40.60.8CD45−ECDSSSSCD45−ECD0.00.20.40.60.8HLA−DR−FITC0HLA−DR−FITC0.00.20.40.60.8CD117−PE0CD117−PE0.00.20.40.60.8CD34−PC50CD34−PC50.00.20.40.60.8CD38−PC70CD38−PC70.00.20.40.60.81.00.00.20.40.60.8CD45−ECDSSSSCD45−ECD0.00.20.40.60.81.0HLA−DR−FITC0HLA−DR−FITC0.00.20.40.60.8CD117−PE0CD117−PE0.00.20.40.60.8CD34−PC50CD34−PC50.00.20.40.60.8CD38−PC70CD38−PC7(b) Tube 6HLA-DR-CD117±CD34-CD38+blasts(a) Tube 6HLA-DR+CD117+CD34+CD38+blastsTable 7.3

Precision (P), Recall (R), Sensitivity (S) and F-measure (F) of the
template-based classiﬁcation in the training set and test set of the AML
data. The statistical measures are computed for each tube separately and
two combinations of tubes.

132

Tubes

Training set

Test set

P

R

S

F

P

R

S

F

1.00

0.26

1.00

0.41

1.00

0.15

1.00

0.26

0.86

0.26

0.99

0.40

0.83

0.25

0.99

0.38

1.00

0.52

1.00

0.69

1.00

0.35

1.00

0.52

0.94

0.74

0.99

0.83

1.00

0.75

1.00

0.86

0.75

0.91

0.96

0.82

0.65

0.85

0.94

0.74

1.00

0.70

1.00

0.82

1.00

0.80

1.00

0.89

0.52

0.48

0.94

0.50

0.48

0.60

0.92

0.53

1

2

3

4

5

6

7

All (2-7)

1.00

0.74

1.00

0.85

1.00

0.85

1.00

0.92

4,5,6

1.00

0.96

1.00

0.98

1.00

1.00

1.00

1.00

7.3.4 Impact of each tube in the classiﬁcation

As discussed in the methods section, I build six independent classiﬁers based

on the healthy and AML templates created from Tubes 2-7 of the AML dataset.

Tubes 1 and 8 are omitted since the former is an isotope control and the latter

is unstained, and therefore, they are uninformative for classiﬁcation. A sample is

classiﬁed as an AML sample if the classiﬁcation score is positive, and as a healthy

sample otherwise. Let true positives (TP) be the number of AML samples correctly

classiﬁed, true negatives (TN) be the number of healthy samples correctly classiﬁed,

false positives (FP) be the number of healthy samples incorrectly classiﬁed as AML,

and false negatives (FN) be the number of AML samples incorrectly classiﬁed as

healthy. Then, I evaluate the performance of each template-based classiﬁer with the

133

Figure 7.4. Average classiﬁcation score from Tubes 4,5,6 for each sample
in the (a) training set and (b) test set. Samples with scores above the
horizontal line are classiﬁed as AML, and as healthy otherwise. The actual
class of each sample is also shown. An AML sample (subject id 116) is
always misclassiﬁed in the training set, and this is discussed in the text.

well-known four statistical measures: Precision, Recall(Sensitivity), Speciﬁcity, and

TN

TP+FP, Recall(Sensitivity) = TP

TP+FN, Speciﬁcity =
. These four measures take values in the interval

F-value, deﬁned as Precision = TP
FP+TN, and F-value = 2(Precision×Recall)
[0,1], and the higher the values the better the classiﬁer.

Precision+Recall

First, I evaluate the impact of each tube in the classiﬁcation of the training sam-

ples. For a training sample X, the classiﬁcation score is computed by comparing it

with the healthy and AML templates created from the training set after removing

X. The predicted status of X is then compared against true status to evaluate the

classiﬁcation accuracy. Table 7.3 (left panel) shows various statistical measures for

the classiﬁers deﬁned in Tubes 2-7 of the training set. The classiﬁers based on Tubes

4, 5, and 6 have the highest sensitivity because these tubes include several markers

relevant to AML diagnosis [170,171]. The number of true negatives TN is high in ev-

ery tube since the identiﬁcation of healthy samples does not depend on the detection

of AML-speciﬁc markers. Hence speciﬁcity is close to one for all tubes. Analogously,

FP is low for most tubes, and we observe high precision for most tubes. The F-value

is a harmonic mean of precision and recall, and denotes the superior classiﬁcation

ability of markers in Tubes 4-6. Averaging scores from all tubes does not improve

the sensitivity and F-value dramatically. However, combining Tubes 4-6 gives almost

0501001500.00.51.0Training samples, orderedClassificationscoreActual class HealthyAML0501001500.00.51.0Test samples, orderedClassificationscoreActual class HealthyAMLSam(a) Training set(b) Test setclassification boundaryclassification boundary134

perfect classiﬁcation with one misclassiﬁcation for the training set. I plot the average

classiﬁcation scores from Tubes 4-6 for the training samples in Fig. 7.4(a). On the x-

axis, the healthy samples are placed ﬁrst followed by the AML samples, and samples

in each group are placed in the ascending order of the average classiﬁcation score.

The class labels of samples are also shown (blue circles for healthy and red triangles

for AML samples).

In Fig. 7.4(a), we observe an AML sample (subject id 116) with score below

the classiﬁcation boundary. Fig. 7.5 shows the cell populations present in subject

116 projected on the SS and CD45 channels.

In this subject, the proportion of

myeloid blasts is 4.4%, which is lower than the minimum 20% AML blasts necessary

to recognize a patient to be AML-positive according to the WHO guidelines [177]

(the FAB threshold is even higher, at 30%). (Recall Fig. 7.1 for a plot of the cell

types in healthy and AML samples.) Hence this is either a rare case of AML, or one

with minimal residual disease after therapy, or perhaps it was incorrectly labeled as

AML in the training set. Since the template-based classiﬁer weighs individual clusters

with their cell proportions, the abnormal myelobasts contribute insigniﬁcantly in the

ﬁnal score computed by Eq. 7.1. As a result, Subject 116 is placed with the healthy

samples in Fig. 7.4. Subject 116 was classiﬁed with the healthy samples by methods

in other published work [166].

7.3.5 Classifying test samples

Now we turn to the test samples. For each tube, I compute the classiﬁcation

score for each sample in the test set using templates created from the training set

and applying Eq. 7.1. Since the average classiﬁcation score from Tubes 4-6 performs

best for the training set, it is used as a classiﬁer for the test set as well. Since

the status of test samples was released after the DREAM6/FlowCAP2 challenge, we

can determine the classiﬁcation accuracy of the test samples. Fig. 7.4(b) shows the

classiﬁcation scores of the test samples, where samples are placed in ascending order

135

Figure 7.5. Cell populations in a sample from subject 116. Even though
this sample is marked as AML by the organizers of DREAM6/FlowCAP2
competition, it contains only 4.4% myeloid blast cells (shown in red).
According to the World Health Organization (WHO) guidelines, AML is
only conﬁrmed when peripheral blood contains at least 20% immature
myeloblasts. Hence, this subject is either a rare AML subtype, or has
been incorrectly labeled.

of classiﬁcation scores.

In Fig. 7.4(b), we observe perfect classiﬁcation in the test

set. Similar to the training set, I tabulate statistical measures for the classiﬁers in

Table 7.3.

When classifying a sample X, we can assume the null hypothesis: X is healthy

(non-leukemic). The sample X receives a positive score if it contains AML-speciﬁc

immunophenotypes, and the higher the score, the stronger the evidence against the

null hypothesis. Since Tube 1 (isotype control) does not include any AML-speciﬁc

markers, it can provide a background distribution for the classiﬁcation scores.

In

Tube 1, 174 out of 179 training samples have negative classiﬁcation scores, but ﬁve

samples have positive scores, with values less than 0.2. In the best classiﬁer designed

from Tubes 4, 5, 6, we observe that two AML-positive samples in the training set

and three AML-positive samples in the test set have scores between 0 and 0.2. The

classiﬁer is relatively less conﬁdent about these samples; nevertheless, the p-values of

these ﬁve samples (computed from the distribution in Tube 1) are still small (< 0.05),

so that they can be classiﬁed as AML-positive. The rest of the AML samples in the

0.20.40.60.80.20.40.60.8CD45−ECD(log)SS(log)myeloidblasts(4.4%)LymphocytesLymphoidblastsMyeloidcellsMyeloidblastsMonocytesSubject 116136

training and test sets have scores greater than 0.2 and the classiﬁer is quite conﬁdent

about their status (p-value zero).

Four AML samples in the test set (ids 239, 262, 285, and 326) were subclassiﬁed

as APL by comparing against distinct template trees for APL and the other AML

samples in the training set (cf. Fig. 7.2 (b)).

Finally, I state the computational times required on an iMac with four 2.7 GHz

cores and 8 GB memory. The code is written in C++ and R. Consider a single tube

with 359 samples in it. The k-means clustering of all samples took one hour, primarily

because we need to run the algorithm multiple times (about ten on the average) to

ﬁnd the optimal value of the number of clusters. Creating the healthy template from

156 samples in the training set required 10 seconds (s) on one core, and the AML

template for 23 AML samples took 0.5s on one core. Cross validation (leave one out)

of the training set took 30 minutes, and computing the classiﬁcation score for the 180

test samples took 15s, both on four cores. I could have reduced the running time by

executing the code in parallel on more cores. In an ongoing project, we have made

the dominant step, the k-means clustering of all the samples with an optimal number

of clusters, faster using a GPU, reducing the total time to a few minutes.

7.4 Conclusions

In this chapter, I have demonstrated that an algorithmic pipeline for template-

based classiﬁcation can successfully identify immunophenotypes of clinical interest in

AML. These could be used to diﬀerentiate the subtypes of AML, which is advanta-

geous since prognosis and treatment depends on the subtype. The templates enable

us to classify AML samples in spite of their heterogeneity. This was accomplished by

creating a scoring function that accounts for the subtleties in cell populations within

AML samples. We are currently applying this approach to a larger AML data set,

and intend to analyze other heterogeneous data sets.

137

8 CONCLUSIONS AND FUTURE WORK

8.1 Conclusions

In my dissertation, I have explored, designed and developed a collection of al-

gorithms for analyzing multi-parametric ﬂow cytometry data. These algorithms

solve sample preprocessing, variance stabilization, clustering, population registra-

tion, meta-clustering, sample classiﬁcation, and other related problems arising in FC

data analysis. I have assembled the algorithms into a data analysis pipeline, ﬂow-

Match [42], that is made available as an open-source R package in Bioconductor

(http://www.bioconductor.org/). The pipeline has been employed to analyze sev-

eral practical datasets and the results are published in peer-reviewed journals and

conferences [36, 37, 46].

Flow cytometry (FC) is a widely used platform for measuring phenotypes of

individual cells from millions of cells in biological samples. Modern FC technol-

ogy gives rise to high-dimensional and high-content data that challenges the ability

to manually investigate the data and interpret the results. To address the limita-

tions of manual analysis, researchers have developed a new branch of research called

the “computational cytometry”. Along with a number of contemporary software

tools [14, 23, 24, 26, 27, 31, 32, 39, 56, 59], ﬂowMatch automates diﬀerent analysis steps

of FC data with an aim to prevent the data analysis from being the bottleneck in

scientiﬁc discovery based on cytometry.

The ﬂowMatch pipeline consists of six well deﬁned algorithmic modules for (1)

unmixing of spectra (compensation) to remove the eﬀect of overlapping ﬂuorescence

channels, (2) transforming data in order to stabilize variance and normalize data,

(3) identifying cell population by automated gating or clustering algorithm in the

high-dimensional marker space, (4) registering cell populations (cluster labeling or

138

matching) across samples, (5) representing a class of samples with high-level tem-

plates, and (6) classifying samples based on the phenotypic pattern of the cell clus-

ters. Each module of ﬂowMatch is designed to perform a speciﬁc task independent

of other modules of the pipeline. However, they can also be employed sequentially in

the order described in Fig. 1.6 to perform the complete data analysis.

I have developed a variance stabilization (VS) method called ﬂowVS for removing

the mean-variance correlation arisen in ﬂuorescence based ﬂow cytometry. ﬂowVS

stabilizes variance by transforming FC samples with the inverse hyperbolic sine func-

tion whose parameters are estimated by minimizing Bartlett’s likelihood-ratio statis-

tics. For population identiﬁcation, I demonstrate that several simple, oﬀ-the-shelf

clustering algorithms provide more accurate and robust partition of an FC sample. I

describe several cluster validation methods that can be used to select the optimum

parameters for a clustering algorithm (e.g., the optimum number of clusters), as well

as choosing the best algorithm for a dataset. Furthermore, I describe an algorithm

for computing the consensus of multiple clustering solutions, which performs better

than any individual algorithm.

For population registration [27,36], I developed a robust mixed edge cover (MEC)

algorithm that matches cell populations across a pair of FC samples. The MEC al-

gorithm uses a robust graph-theoretic framework to match a cluster from a sample

to zero or more clusters in another sample and thus solves the problem of missing or

splitting populations. Next, I describe a hierarchical algorithm for encapsulating a

collection of sample belonging to the same class with a template. A template is a col-

lection of relatively homogeneous meta-clusters commonly shared across samples of a

given class, thus describing the key immunophenotypes of an overall class of samples.

Finally, I demonstrate that the use of templates leads to eﬃcient classiﬁcation algo-

rithms. By comparing a sample with class templates, the sample is predicted to come

from a class whose template it is most similar to. The template-base classiﬁcation is

robust and eﬃcient because it compares samples to cleaner and fewer class templates

rather than the large number of noisy samples themselves.

139

I have employed diﬀerent components of ﬂowMatch for classifying leukemia sam-

ples, evaluating the phosphorylation eﬀects on T cells, classifying healthy immune

proﬁles, comparing the impact of two treatments against Multiple Sclerosis, and clas-

sifying the HIV vaccination status.

In these analyses, ﬂowMatch is able to reach

biologically meaningful conclusions with the automated algorithms. The algorithms

included in ﬂowMatch can also be applied to problems outside of ﬂow cytometry such

as from microarray data analysis and image recognitions.

8.2 Future work

Application to larger and higher-dimensional datasets: Thus far, I have em-

ployed ﬂowMatch to ﬁve FC datasets, the largest of which is an AML dataset

with nearly 3000 seven-dimensional samples. More rigorous testing with other

datasets will certainly increase the conﬁdence about the correctness and eﬃciency

of the pipeline. I am in the process of getting access to large cytomics data from

Immune Tolerance Network (http://www.immunetolerance.org/), FlowRepository

(http://flowrepository.org/), Cytobank (http://www.cytobank.org), and from

other public repositories. I have tested the ﬂowMatch pipeline with up to eight di-

mensional samples. However, the newly developed mass cytometry technology [7] can

investigate more than 40 parameters of a single cell. ﬂowMatch needs to be tested

and enhanced (if needed) for this high dimensional data.

Enhancing the modules of the ﬂowMatch pipeline: The ﬂowMatch pipeline is still

under development. I plan to enhance diﬀerent components of the pipeline with ad-

ditional functionalities from which the users can choose depending on the objective

of the data analysis. For variance stabilization, in addition to the inverse hyperbolic

sine (asinh) function, several other transformations can be tested. It also remains a

future work to design and implement a multi-dimensional variance stabilization algo-

rithm. In current work, I am incorporating the proportion of cells into the population

registration algorithm, which will lead to a between-sample distance metric similar

140

in spirit of the earth mover’s distance [133, 139]. For the meta-clustering algorithm, I

investigate the use of networks instead of trees to organize the templates, similar in

spirit to the use of networks rather than trees in phylogenetics [160]. Finally, I am

considering other classiﬁcation algorithms, such as the logistic regression [178], for

complementing the template-based classiﬁcation methods.

Parallelizing algorithms for faster processing: At present, the modules of ﬂow-

Match are implemented as serial algorithms. However, given the ever increasing

volume of data and the availability of high-performance computers, the algorithms

of the pipeline can be parallelized to analyze a dataset faster without incurring any

additional cost. I consider parallelizing ﬂowMatch at diﬀerent levels. The variance

stabilization algorithm is embarrassingly parallel where density peaks on diﬀerent

channels can be identiﬁed and their likelihood-ratio test can be evaluated on diﬀerent

processing units. A number of parallel clustering algorithms have been discussed in

the literature [179–181] and they can be integrated into the ﬂowMatch pipeline. The

quality of partitions can be evaluated in parallel for diﬀerent choices of clustering

parameters. The population registration problem can be solved faster by paralleliz-

ing the mixed edge cover algorithm. I have already developed algorithms for parallel

cardinality matching on bipartite graphs [47–49]. Developing parallel algorithms for

weighted matching problem remains a future work. However, the number of pop-

ulations is generally small (tens to hundreds) in typical FC samples, and therefore

parallel population registration might not decrease the processing time signiﬁcantly.

The samples are processed in a sequential order by the meta-clustering algorithm,

which is diﬃcult to parallelize. However, we can relax the strict order of sample

processing, and then parallelize the hierarchical algorithm. In the dynamic classiﬁca-

tion algorithm, we can insert multiple samples into the template tree simultaneously

whenever the inserted samples update diﬀerent parts of the template-tree.

Applying the pipeline to problem outside of the ﬂow cytometry: Stabilizing vari-

ance, clustering, matching, creating templates are general concepts with applications

to diﬀerent areas. Therefore, the algorithms developed in this dissertation can be

141

applied – possibly with simple modiﬁcations– to problems outside of ﬂow cytometry.

I have already applied the variance stabilization framework to microarray data and

compared the results with a state-of-the-art software developed for microarrays in

Chapter 2. Likewise, other algorithms have applications to problems from microar-

rays, ChIp-Seq, etc.

FC data projected on a lower dimension has considerable similarities with im-

ages from tradition photography and from bio-imaging technologies such as imaging

cytometry, MRI, etc. Therefore, the algorithms in ﬂowMatch have direct applica-

tion in analyzing images from these technologies. For example, consider an image

recognition application where the clustering algorithm segments images into diﬀerent

features (eyes, nose, etc.), the matching algorithm registers diﬀerent features across

images, and the classiﬁcation algorithm recognizes the images with templates created

from existing image library. This image recognition problem can be solved by the

clustering, matching and classiﬁcation algorithms from the ﬂowMatch pipeline.

I expect this dissertation to be a strong algorithmic contribution with application

to ﬂow cytometry, as well as to domains outside of ﬂow cytometry.

LIST OF REFERENCES

142

LIST OF REFERENCES

[1] R. Coico and G. Sunshine, Immunology: A Short Course. Wiley-Blackwell,

2009.

[2] J. W. Mellors, A. Munoz, J. V. Giorgi, J. B. Margolick, C. J. Tassoni, P. Gupta,
L. A. Kingsley, J. A. Todd, A. J. Saah, R. Detels, et al., “Plasma viral load
and CD4+ lymphocytes as prognostic markers of HIV-1 infection,” Annals of
Internal Medicine, vol. 126, no. 12, pp. 946–954, 1997.

[3] H. T. Maecker, J. P. McCoy, and R. Nussenblatt, “Standardizing immunophe-
notyping for the human immunology project,” Nature Reviews Immunology,
vol. 12, no. 3, pp. 191–200, 2012.

[4] J. Van Dongen, L. Lhermitte, S. B¨ottcher, J. Almeida, V. Van der Velden,
J. Flores-Montero, A. Rawstron, V. Asnaﬁ, Q. L´ecrevisse, P. Lucio, et al.,
“Euroﬂow antibody panels for standardized n-dimensional ﬂow cytometric im-
munophenotyping of normal, reactive and malignant leukocytes,” Leukemia,
vol. 26, no. 9, pp. 1908–1975, 2012.

[5] H. M. Shapiro, Practical Flow Cytometry. Wiley-Liss, 2005.

[6] E. Lugli, M. Roederer, and A. Cossarizza, “Data analysis in ﬂow cytometry:

The future just started,” Cytometry Part A, vol. 77, pp. 705–713, 2010.

[7] S. C. Bendall, E. F. Simonds, P. Qiu, D. A. El-ad, P. O. Krutzik, R. Finck, R. V.
Bruggner, R. Melamed, A. Trejo, O. I. Ornatsky, et al., “Single-cell mass cytom-
etry of diﬀerential immune and drug responses across a human hematopoietic
continuum,” Science, vol. 332, no. 6030, pp. 687–696, 2011.

[8] S. P. Perfetto, P. K. Chattopadhyay, and M. Roederer, “Seventeen-colour ﬂow
cytometry: Unravelling the immune system,” Nature Reviews Immunology,
vol. 4, no. 8, pp. 648–655, 2004.

[9] J. M. Peters and M. Q. Ansari, “Multiparameter ﬂow cytometry in the diag-
nosis and management of acute leukemia,” Archives of Pathology & Laboratory
Medicine, vol. 135, no. 1, pp. 44–54, 2011.

[10] R. A. Seder, P. A. Darrah, and M. Roederer, “T-cell quality in memory and pro-
tection: Implications for vaccine design,” Nature Reviews Immunology, vol. 8,
no. 4, pp. 247–258, 2008.

[11] S. P. Perfetto, P. K. Chattopadhyay, L. Lamoreaux, R. Nguyen, D. Ambrozak,
R. A. Koup, and M. Roederer, “Amine reactive dyes: An eﬀective tool to
discriminate live and dead cells in polychromatic ﬂow cytometry,” Journal of
Immunological Methods, vol. 313, no. 1, pp. 199–208, 2006.

143

[12] N. Le Meur, A. Rossini, M. Gasparetto, C. Smith, R. R. Brinkman, and
R. Gentleman, “Data quality assessment of ungated ﬂow cytometry data in
high throughput experiments,” Cytometry Part A, vol. 71, no. 6, pp. 393–403,
2007.

[13] M. Roederer, “Spectral compensation for ﬂow cytometry: Visualization arti-

facts, limitations, and caveats,” Cytometry, vol. 45, no. 3, pp. 194–205, 2001.

[14] C. B. Bagwell and E. G. Adams, “Fluorescence spectral overlap compensa-
tion for any number of ﬂow cytometry parameters,” Annals of the New York
Academy of Sciences, vol. 677, no. 1, pp. 167–184, 1993.

[15] D. Novo, G. Gr´egori, and B. Rajwa, “Generalized unmixing model for multi-
spectral ﬂow cytometry utilizing nonsquare compensation matrices,” Cytometry
Part A, vol. 83, pp. 508–520, May 2013.

[16] C. Snow, “Flow cytometer electronics,” Cytometry Part A, vol. 57, no. 2, pp. 63–

69, 2004.

[17] C. Bagwell, “Hyperlog – A ﬂexible log-like transform for negative, zero, and

positive valued data,” Cytometry Part A, vol. 64, no. 1, pp. 34–42, 2005.

[18] D. Parks, M. Roederer, and W. Moore, “A new logicle display method avoids
deceptive eﬀects of logarithmic scaling for low signals and compensated data,”
Cytometry Part A, vol. 69, no. 6, pp. 541–551, 2006.

[19] J. Dvorak and S. Banks, “Modiﬁed Box-Cox transform for modulating the dy-
namic range of ﬂow cytometry data,” Cytometry, vol. 10, no. 6, pp. 811–813,
2005.

[20] D. Novo and J. Wood, “Flow cytometry histograms: Transformations, resolu-

tion, and display,” Cytometry Part A, vol. 73, no. 8, pp. 685–692, 2008.

[21] B. Efron, “Transformation theory: How normal is a family of distributions?,”

The Annals of Statistics, vol. 10, no. 2, pp. 323–339, 1982.

[22] W. Huber, A. Von Heydebreck, H. S¨ultmann, A. Poustka, and M. Vingron,
“Variance stabilization applied to microarray data calibration and to the
quantiﬁcation of diﬀerential expression,” Bioinformatics, vol. 18, no. suppl 1,
pp. S96–S104, 2002.

[23] G. Finak, J. Perez, A. Weng, and R. Gottardo, “Optimizing transformations
for automated, high throughput analysis of ﬂow cytometry data,” BMC Bioin-
formatics, vol. 11, no. 1, p. 546, 2010.

[24] S. Ray and S. Pyne, “A computational framework to emulate the human per-
spective in ﬂow cytometric data analysis,” PLoS One, vol. 7, no. 5, p. e35693,
2012.

[25] C. Chan, F. Feng, J. Ottinger, D. Foster, M. West, and T. B. Kepler, “Statistical
mixture modeling for cell subtype identiﬁcation in ﬂow cytometry,” Cytometry
Part A, vol. 73, no. 8, pp. 693–701, 2008.

[26] K. Lo, R. Brinkman, and R. Gottardo, “Automated gating of ﬂow cytometry
data via robust model-based clustering,” Cytometry Part A, vol. 73, no. 4,
pp. 321–332, 2008.

144

[27] S. Pyne, X. Hu, K. Wang, E. Rossin, T. Lin, L. Maier, C. Baecher-Allan,
G. McLachlan, P. Tamayo, D. Haﬂer, et al., “Automated high-dimensional ﬂow
cytometric data analysis,” Proceedings of the National Academy of Sciences,
vol. 106, no. 21, pp. 8519–8524, 2009.

[28] Y. Qian, C. Wei, F. Eun-Hyung Lee, J. Campbell, J. Halliley, J. A. Lee, J. Cai,
Y. M. Kong, E. Sadat, E. Thomson, et al., “Elucidation of seventeen human
peripheral blood B-cell subsets and quantiﬁcation of the tetanus response using
a density-based method for the automated identiﬁcation of cell populations in
multidimensional ﬂow cytometry data,” Cytometry Part B: Clinical Cytometry,
vol. 78, no. S1, pp. S69–S82, 2010.

[29] G. Walther, N. Zimmerman, W. Moore, D. Parks, S. Meehan, I. Belitskaya,
J. Pan, and L. Herzenberg, “Automatic clustering of ﬂow cytometry data with
density-based merging,” Advances in Bioinformatics, vol. 2009, 2009.

[30] H. Zare, P. Shooshtari, A. Gupta, and R. Brinkman, “Data reduction for spec-
tral clustering to analyze high throughput ﬂow cytometry data,” BMC Bioin-
formatics, vol. 11, no. 1, p. 403, 2010.

[31] N. Aghaeepour, R. Nikolic, H. H. Hoos, and R. R. Brinkman, “Rapid cell
population identiﬁcation in ﬂow cytometry data,” Cytometry Part A, vol. 79,
no. 1, pp. 6–13, 2011.

[32] N. Aghaeepour, G. Finak, H. Hoos, T. R. Mosmann, R. Brinkman, R. Gottardo,
R. H. Scheuermann, et al., “Critical assessment of automated ﬂow cytometry
data analysis techniques,” Nature Methods, vol. 10, no. 3, pp. 228–238, 2013.

[33] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering: A review,” ACM

Computing Surveys (CSUR), vol. 31, no. 3, pp. 264–323, 1999.

[34] M. Halkidi, Y. Batistakis, and M. Vazirgiannis, “On clustering validation tech-
niques,” Journal of Intelligent Information Systems, vol. 17, no. 2-3, pp. 107–
145, 2001.

[35] K. Hornik and W. B¨ohm, “Hard and soft euclidean consensus partitions,”
in Data Analysis, Machine Learning and Applications, pp. 147–154, Springer,
2008.

[36] A. Azad, S. Pyne, and A. Pothen, “Matching phosphorylation response patterns
of antigen-receptor-stimulated T cells via ﬂow cytometry,” BMC Bioinformat-
ics, vol. 13, no. Suppl 2, p. S10, 2012.

[37] A. Azad, J. Langguth, Y. Fang, A. Qi, and A. Pothen, “Identifying rare cell
populations in comparative ﬂow cytometry,” Lecture Notes in Computer Sci-
ence, vol. 6293, pp. 162–175, 2010.

[38] D. B. Allison, X. Cui, G. P. Page, and M. Sabripour, “Microarray data analysis:
From disarray to consolidation and consensus,” Nature Reviews Genetics, vol. 7,
no. 1, pp. 55–65, 2006.

[39] J. Spidlen, A. Barsky, K. Breuer, P. Carr, M.-D. Nazaire, B. A. Hill, Y. Qian,
T. Liefeld, M. Reich, J. P. Mesirov, P. Wilkinson, R. H. Scheuermann, R.-P.
Sekaly, and R. R. Brinkman, “Genepattern ﬂow cytometry suite,” Source Code
for Biology and Medicine, vol. 8, no. 1, p. 14, 2013.

145

[40] N. Kotecha, P. O. Krutzik, and J. M. Irish, “Web-based analysis and publication
of ﬂow cytometry experiments,” Current Protocols in Cytometry, vol. 10, 2010.

[41] A. Azad, B. Rajwa, and A. Pothen, “ﬂowMatch: An algorithmic pipeline for

ﬂow cytometry data analysis,” Submitted, 2014.

[42] A. Azad, ﬂowMatch: Matching and meta-clustering in ﬂow cytometry, 2013. R

package version 0.99.2.

[43] R. C. Gentleman, V. J. Carey, D. M. Bates, B. Bolstad, M. Dettling, S. Dudoit,
B. Ellis, L. Gautier, Y. Ge, J. Gentry, et al., “Bioconductor: Open software
development for computational biology and bioinformatics,” Genome Biology,
vol. 5, no. 10, p. R80, 2004.

[44] L. Maier, D. Anderson, P. De Jager, L. Wicker, and D. Haﬂer, “Allelic variant
in CTLA4 alters T cell phosphorylation patterns,” Proceedings of the National
Academy of Sciences, vol. 104, no. 47, p. 18607, 2007.

[45] A. Azad, B. Rajwa, and A. Pothen, “Immunophenotypes of acute myeloid

leukemia from ﬂow cytometry data using templates,” ArXiv, 2014.

[46] A. Azad, A. Khan, B. Rajwa, S. Pyne, and A. Pothen, “Classifying immunophe-
notypes with templates from ﬂow cytometry,” in Proceedings of the Interna-
tional Conference on Bioinformatics, Computational Biology and Biomedical
Informatics (ACM BCB), p. 256, ACM, 2013.

[47] A. Azad, M. Halappanavar, S. Rajamanickam, E. G. Boman, A. Khan, and
A. Pothen, “Multithreaded algorithms for maximum matching in bipartite
graphs,” in IEEE Parallel & Distributed Processing Symposium (IPDPS),
pp. 860–872, IEEE, 2012.

[48] A. Azad, M. Halappanavar, F. Dobrian, and A. Pothen, “Computing maximum
matching in parallel on bipartite graphs: Worth the eﬀort?,” in Proceedings of
the First Workshop on Irregular Applications: Architectures and Algorithm,
pp. 11–14, ACM, 2011.

[49] A. Azad and A. Pothen, “Multithreaded algorithms for matching in graphs with
application to data analysis in ﬂow cytometry,” in IEEE Parallel and Distributed
Processing Symposium Workshops & PhD Forum (IPDPSW), pp. 2494–2497,
IEEE, 2012.

[50] P. J. Waddell and A. Azad, “Resampling residuals: Robust estimators
of error and ﬁt for evolutionary trees and phylogenomics,” arXiv preprint
arXiv:0912.5288, 2009.

[51] P. J. Waddell, A. Azad, and I. Khan, “Resampling residuals on phylogenetic

trees: Extended results,” arXiv preprint arXiv:1101.0020, 2010.

[52] F. Hahne, A. Khodabakhshi, A. Bashashati, C. Wong, R. Gascoyne, A. Weng,
V. Seyfert-Margolis, K. Bourcier, A. Asare, T. Lumley, et al., “Per-channel basis
normalization methods for ﬂow cytometry data,” Cytometry Part A, vol. 77,
no. 2, pp. 121–131, 2010.

146

[53] C. Brockmeyer, W. Paster, D. Pepper, et al., “T Cell Receptor (TCR)-induced
tyrosine phosphorylation dynamics identiﬁes THEMIS as a new TCR signalo-
some component,” Journal of Biological Chemistry, vol. 286, no. 9, pp. 7535–
7547, 2011.

[54] N. Aghaeepour, P. K. Chattopadhyay, A. Ganesan, K. O’Neill, H. Zare,
A. Jalali, H. H. Hoos, M. Roederer, and R. R. Brinkman, “Early immuno-
logic correlates of HIV protection can be identiﬁed from computational analysis
of complex multivariate T-cell ﬂow cytometry assays,” Bioinformatics, vol. 28,
no. 7, pp. 1009–1016, 2012.

[55] P. Qiu, E. F. Simonds, S. C. Bendall, K. D. Gibbs Jr, R. V. Bruggner, M. D.
Linderman, K. Sachs, G. P. Nolan, and S. K. Plevritis, “Extracting a cellular
hierarchy from high-dimensional cytometry data with SPADE,” Nature Biotech-
nology, vol. 29, no. 10, pp. 886–891, 2011.

[56] J. P. Robinson, B. Rajwa, V. Patsekin, and V. J. Davisson, “Computational
analysis of high-throughput ﬂow cytometry data,” Expert Opinion on Drug
Discovery, vol. 7, no. 8, pp. 679–693, 2012.

[57] H. T. Maecker, T. M. Lindstrom, W. H. Robinson, P. J. Utz, M. Hale, S. D.
Boyd, S. S. Shen-Orr, and C. G. Fathman, “New tools for classiﬁcation and mon-
itoring of autoimmune diseases,” Nature Reviews Rheumatology, vol. 8, no. 6,
pp. 317–328, 2012.

[58] A. Bashashati and R. R. Brinkman, “A survey of ﬂow cytometry data analysis

methods,” Advances in Bioinformatics, vol. 2009, 2009.

[59] F. Hahne, N. LeMeur, R. Brinkman, B. Ellis, P. Haaland, D. Sarkar, J. Spi-
dlen, E. Strain, and R. Gentleman, “ﬂowcore: A bioconductor package for high
throughput ﬂow cytometry,” BMC Bioinformatics, vol. 10, no. 1, p. 106, 2009.

[60] D. Sarkar, N. Le Meur, and R. Gentleman, “Using ﬂowviz to visualize ﬂow

cytometry data,” Bioinformatics, vol. 24, no. 6, pp. 878–879, 2008.

[61] K. Lo, F. Hahne, R. Brinkman, and R. Gottardo, “ﬂowclust: A bioconductor
package for automated gating of ﬂow cytometry data,” BMC Bioinformatics,
vol. 10, no. 1, p. 145, 2009.

[62] F. Hahne, N. Gopalakrishnan, A. Khodabakhshi, and C. Wong, ﬂowStats: Sta-
tistical methods for the analysis of ﬂow cytometry data. R package version 3.20,
available at http://www.bioconductor.org.

[63] R. Scheuermann, Y. Qian, C. Wei, and I. Sanz, “ImmPortFLOCK: Automated
cell population identiﬁcation in high dimensional ﬂow cytometry data,” The
Journal of Immunology, vol. 182, no. Meeting Abstracts 1, pp. 42–17, 2009.

[64] M. Schena, D. Shalon, R. W. Davis, and P. O. Brown, “Quantitative monitoring
of gene expression patterns with a complementary DNA microarray,” Science,
vol. 270, no. 5235, pp. 467–470, 1995.

[65] Y. Chen, E. R. Dougherty, and M. L. Bittner, “Ratio-based decisions and the
quantitative analysis of cDNA microarray images,” Journal of Biomedical op-
tics, vol. 2, no. 4, pp. 364–374, 1997.

147

[66] B. P. Durbin, J. S. Hardin, D. M. Hawkins, and D. M. Rocke, “A variance-
stabilizing transformation for gene-expression microarray data,” Bioinformat-
ics, vol. 18, no. suppl 1, pp. S105–S110, 2002.

[67] M. Bartlett, “Properties of suﬃciency and statistical tests,” Proceedings of
the Royal Society of London. Series A: Mathematical and Physical Sciences,
vol. 160, no. 901, pp. 268–282, 1937.

[68] F. J. Anscombe, “The transformation of poisson, binomial and negative-

binomial data,” Biometrika, vol. 35, no. 3/4, pp. 246–254, 1948.

[69] S. K. Bar-Lev and P. Enis, “On the classical choice of variance stabilizing trans-
formations and an application for a poisson variate,” Biometrika, vol. 75, no. 4,
pp. 803–804, 1988.

[70] M. Bartlett, “The square root transformation in analysis of variance,” Supple-
ment to the Journal of the Royal Statistical Society, vol. 3, no. 1, pp. 68–78,
1936.

[71] R. Tibshirani, “Estimating transformations for regression via additivity and
variance stabilization,” Journal of the American Statistical Association, vol. 83,
no. 402, pp. 394–405, 1988.

[72] B. Zhang, J. M. Fadili, and J.-L. Starck, “Wavelets, ridgelets, and curvelets for
poisson noise removal,” IEEE Transactions on Image Processing, vol. 17, no. 7,
pp. 1093–1108, 2008.

[73] Y. Qian, Y. Liu, J. Campbell, E. Thomson, Y. M. Kong, and R. H. Scheuer-
mann, “FCSTrans: An open source software system for fcs ﬁle conversion and
data transformation,” Cytometry Part A, vol. 81, no. 5, pp. 353–356, 2012.

[74] M. B. Wilk and R. Gnanadesikan, “Probability plotting methods for the analysis

for the analysis of data,” Biometrika, vol. 55, no. 1, pp. 1–17, 1968.

[75] E. Motakis, G. P. Nason, P. Fryzlewicz, and G. Rutter, “Variance stabilization
and normalization for one-color microarray data using a data-driven multiscale
approach,” Bioinformatics, vol. 22, no. 20, pp. 2547–2553, 2006.

[76] P. Fryzlewicz and V. Delouille, “A data-driven haar-ﬁsz transform for multi-
scale variance stabilization,” in IEEE/SP 13th Workshop on Statistical Signal
Processing, pp. 539–544, IEEE, 2005.

[77] H. Levene, “Robust tests for equality of variances1,” Contributions to Probabil-

ity and Statistics: Essays in Honor of Harold Hotelling, vol. 2, p. 278, 1960.

[78] M. B. Brown and A. B. Forsythe, “Robust tests for the equality of variances,”
Journal of the American Statistical Association, vol. 69, no. 346, pp. 364–367,
1974.

[79] G. Finak, A. Bashashati, R. Brinkman, and R. Gottardo, “Merging mixture
components for cell population identiﬁcation in ﬂow cytometry,” Advances in
Bioinformatics, vol. 2009, 2009.

[80] I. P. Sug´ar and S. C. Sealfon, “Misty mountain clustering: Application to
fast unsupervised ﬂow cytometry gating,” BMC Bioinformatics, vol. 11, no. 1,
p. 502, 2010.

148

[81] U. Naumann, G. Luta, and M. Wand, “The curvHDR method for gating ﬂow

cytometry samples,” BMC Bioinformatics, vol. 11, no. 1, p. 44, 2010.

[82] I. Naim, S. Datta, G. Sharma, J. S. Cavenaugh, and T. R. Mosmann, “SWIFT:
Scalable weighted iterative sampling for ﬂow cytometry clustering,” in IEEE
International Conference on Acoustics Speech and Signal Processing (ICASSP),
pp. 509–512, IEEE, 2010.

[83] J. Quinn, P. W. Fisher, R. J. Capocasale, R. Achuthanandam, M. Kam, P. J.
Bugelski, and L. Hrebien, “A statistical pattern recognition approach for de-
termining cellular viability and lineage phenotype in cultured cells and murine
bone marrow,” Cytometry Part A, vol. 71, no. 8, pp. 612–624, 2007.

[84] K. Hornik, “A CLUE for CLUster Ensembles,” Journal of Statistical Software,

vol. 14, September 2005.

[85] H. Zare, P. Shooshtari, A. Gupta, and R. Brinkman, “Data reduction for spec-
tral clustering to analyze high throughput ﬂow cytometry data,” BMC Bioin-
formatics, vol. 11, no. 1, p. 403, 2010.

[86] J. A. Hartigan and M. A. Wong, “Algorithm AS 136: A k-means clustering al-
gorithm,” Journal of the Royal Statistical Society. Series C (Applied Statistics),
vol. 28, no. 1, pp. 100–108, 1979.

[87] S. Lloyd, “Least squares quantization in PCM,” IEEE Transactions on Infor-

mation Theory, vol. 28, no. 2, pp. 129–137, 1982.

[88] L. Kaufman and P. J. Rousseeuw, Finding Groups in Data: An Introduction to

Cluster Analysis, vol. 344. Wiley, 2009.

[89] D. M¨ullner, “fastcluster: Fast hierarchical, agglomerative clustering routines for
R and Python,” Journal of Statistical Software, vol. 53, no. 9, pp. 1–18, 2013.

[90] C. M. Bishop and N. M. Nasrabadi, Pattern Recognition and Machine Learning,

vol. 1. Springer New York, 2006.

[91] R. Lebret, S. Iovleﬀ, and F. Langrognet, Rmixmod: An interface of MIXMOD.

R package version 2.0.1, available at http://cran.r-project.org.

[92] J. Herrero, A. Valencia, and J. Dopazo, “A hierarchical unsupervised growing
neural network for clustering gene expression patterns,” Bioinformatics, vol. 17,
no. 2, pp. 126–136, 2001.

[93] U. Von Luxburg, “A tutorial on spectral clustering,” Statistics and Computing,

vol. 17, no. 4, pp. 395–416, 2007.

[94] D. Yan, L. Huang, and M. Jordan, “Fast approximate spectral clustering,” in
Proceedings of the International Conference on Knowledge Discovery and Data
Mining (ACM SIGKDD), pp. 907–916, ACM, 2009.

[95] G. Gan, C. Ma, and J. Wu, Data Clustering: Theory, Algorithms, and Appli-

cations, vol. 20. SIAM, 2007.

[96] R Development Core Team, R: A language and environment for statistical com-

puting. R Foundation for Statistical Computing, Vienna, Austria, 2012.

149

[97] M. Maechler, P. Rousseeuw, A. Struyf, M. Hubert, and K. Hornik, Cluster:
Cluster analysis basics and extensions. R package version 1.14.4, available at
http://cran.r-project.org.

[98] G. Brock, V. Pihur, S. Datta, and S. Datta, “clValid, an R package for cluster

validation,” Journal of Statistical Software, vol. 25, no. 4, 2008.

[99] A. Zeileis, K. Hornik, A. Smola, and A. Karatzoglou, “Kernlab–an S4 package
for kernel methods in R,” Journal of Statistical Software, vol. 11, no. 9, pp. 1–20,
2004.

[100] M. Ramze Rezaee, B. P. Lelieveldt, and J. H. Reiber, “A new cluster validity
index for the fuzzy c-mean,” Pattern Recognition Letters, vol. 19, no. 3, pp. 237–
246, 1998.

[101] N. R. Pal and J. C. Bezdek, “On cluster validity for the fuzzy c-means model,”

IEEE Transactions on Fuzzy Systems, vol. 3, no. 3, pp. 370–379, 1995.

[102] X. L. Xie and G. Beni, “A validity measure for fuzzy clustering,” IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 13, no. 8, pp. 841–847,
1991.

[103] T. Cali´nski and J. Harabasz, “A dendrite method for cluster analysis,” Com-

munications in Statistics-theory and Methods, vol. 3, no. 1, pp. 1–27, 1974.

[104] J. Dunn, “Well-separated clusters and optimal fuzzy partitions,” Journal of

Cybernetics, vol. 4, no. 1, pp. 95–104, 1974.

[105] P. Rousseeuw, “Silhouettes: A graphical aid to the interpretation and valida-
tion of cluster analysis,” Journal of Computational and Applied Mathematics,
vol. 20, pp. 53–65, 1987.

[106] D. Davies and D. Bouldin, “A cluster separation measure,” IEEE Transactions

on Pattern Analysis and Machine Intelligence, no. 2, pp. 224–227, 1979.

[107] M. Halkidi and M. Vazirgiannis, “Clustering validity assessment: Finding the
optimal partitioning of a data set,” in IEEE International Conference on Data
Mining (ICDM), pp. 187–194, IEEE, 2001.

[108] G. H. Ball and D. J. Hall, “ISODATA, a novel method of data analysis and

pattern classiﬁcation,” Technical Report, DTIC Document, 1965.

[109] L. Hubert and J. Schultz, “Quadratic assignment as a general data analysis
strategy,” British Journal of Mathematical and Statistical Psychology, vol. 29,
no. 2, pp. 190–241, 1976.

[110] S. Ray and R. H. Turi, “Determination of number of clusters in k-means clus-
tering and application in colour image segmentation,” in Proceedings of the
4th International Conference on Advances in Pattern Recognition and Digital
Techniques, pp. 137–143, 1999.

[111] A. Scott and M. J. Symons, “Clustering methods based on likelihood ratio

criteria,” Biometrics, pp. 387–397, 1971.

150

[112] Y. Liu, Z. Li, H. Xiong, X. Gao, and J. Wu, “Understanding of internal clus-
tering validation measures,” in IEEE International Conference on Data Mining
(ICDM), pp. 911–916, IEEE, 2010.

[113] L. Nieweglowski., clv: Cluster validation techniques. R package version 0.3.2,

available at http://cran.r-project.org.

[114] G. Brock, V. Pihur, S. Datta, and S. Datta, clValid: Validation of clustering

results, 2011. R package version 0.6-4.

[115] B. Desgraupes, clusterCrit: Clustering indices. R package version 1.2.3, avail-

able at http://cran.r-project.org.

[116] C. D. Manning, P. Raghavan, and H. Sch¨utze, Introduction to Information

Retrieval, vol. 1. Cambridge University Press Cambridge, 2008.

[117] W. M. Rand, “Objective criteria for the evaluation of clustering methods,”
Journal of the American Statistical Association, vol. 66, no. 336, pp. 846–850,
1971.

[118] P. Jaccard, “Distribution de la ﬂore alpine dans le bassin des drouces et dans
quelques regions voisines,” Bulletin de la Soci´et´e Vaudoise des Sciences Na-
turelles, vol. 37, no. 140, pp. 241–272, 1901.

[119] N. Jardine and R. Sibson, Mathematical Taxonomy. Wiley, New York, 1971.

[120] E. B. Fowlkes and C. L. Mallows, “A method for comparing two hierarchical
clusterings,” Journal of the American Statistical Association, vol. 78, no. 383,
pp. 553–569, 1983.

[121] D. Gusﬁeld, “Partition-distance: A problem and class of perfect graphs arising
in clustering,” Information Processing Letters, vol. 82, no. 3, pp. 159–164, 2002.

[122] D. A. Konovalov, B. Litow, and N. Bajema, “Partition-distance via the assign-

ment problem,” Bioinformatics, vol. 21, no. 10, pp. 2463–2468, 2005.

[123] I. Charon, L. Denoeud, A. Gu´enoche, and O. Hudry, “Maximum transfer dis-
tance between partitions,” Journal of Classiﬁcation, vol. 23, no. 1, pp. 103–121,
2006.

[124] P. Arabie and S. A. Boorman, “Multidimensional scaling of measures of dis-
tance between partitions,” Journal of Mathematical Psychology, vol. 10, no. 2,
pp. 148–203, 1973.

[125] C. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algorithms

and Complexity. Courier Dover Publications, 1998.

[126] A. Gordon and M. Vichi, “Fuzzy partition models for ﬁtting a set of partitions,”

Psychometrika, vol. 66, no. 2, pp. 229–247, 2001.

[127] E. Dimitriadou, A. Weingessel, and K. Hornik, “A combination scheme for
fuzzy clustering,” International Journal of Pattern Recognition and Artiﬁcial
Intelligence, vol. 16, no. 07, pp. 901–912, 2002.

[128] M. R. Gary and D. S. Johnson, Computers and Intractability: A Guide to the

Theory of NP-completeness. WH Freeman and Company, New York, 1979.

151

[129] N. Aghaeepour, ﬂowMeans: Non-parametric ﬂow cytometry data gating. R

package version 1.15, available at http://www.bioconductor.org.

[130] Q. Zeng, M. Wand, A. J. Young, J. Rawn, E. L. Milford, S. J. Mentzer, and
R. A. Greenes, “Matching of ﬂow-cytometry histograms using information the-
ory in feature space,” in Proceedings of the AMIA Symposium, p. 929, American
Medical Informatics Association, 2002.

[131] Q. T. Zeng, J. P. Pratt, J. Pak, D. Ravnic, H. Huss, and S. J. Mentzer, “Feature-
guided clustering of multi-dimensional ﬂow cytometry datasets,” Journal of
Biomedical Informatics, vol. 40, no. 3, pp. 325–331, 2007.

[132] A. Schrijver, Combinatorial Optimization: Polyhedra and Eﬃciency, vol. 24.

Springer, 2003.

[133] N. Zimmerman, “A computational approach to identiﬁcation and comparison

of cell subsets in ﬂow cytometry data,” Doctoral Dissertation, 2011.

[134] H. Jeﬀreys, “An invariant form for the prior probability in estimation prob-
lems,” Proceedings of the Royal Society of London. Series A. Mathematical and
Physical Sciences, vol. 186, no. 1007, pp. 453–461, 1946.

[135] S. Kullback and R. Leibler, “On information and suﬃciency,” The Annals of

Mathematical Statistics, vol. 22, no. 1, pp. 79–86, 1951.

[136] G. McLachlan, “Mahalanobis distance,” Resonance, vol. 4, no. 6, pp. 20–26,

1999.

[137] N. Smirnov, “Table for estimating the goodness of ﬁt of empirical distributions,”

The Annals of Mathematical Statistics, vol. 19, no. 2, pp. 279–281, 1948.

[138] F. J. Massey Jr, “The kolmogorov-smirnov test for goodness of ﬁt,” Journal of

the American Statistical Association, vol. 46, no. 253, pp. 68–78, 1951.

[139] Y. Rubner, C. Tomasi, and L. J. Guibas, “The earth mover’s distance as a
metric for image retrieval,” International Journal of Computer Vision, vol. 40,
no. 2, pp. 99–121, 2000.

[140] J. Berrington, D. Barge, A. Fenton, A. Cant, and G. Spickett, “Lymphocyte
subsets in term and signiﬁcantly preterm UK infants in the ﬁrst year of life ana-
lyzed by single platform ﬂow cytometry,” Clinical & Experimental Immunology,
vol. 140, no. 2, pp. 289–292, 2005.

[141] F. Lacombe, F. Durrieu, A. Briais, P. Dumain, F. Belloc, E. Bascans, J. Reiﬀers,
M. Boisseau, and P. Bernard, “Flow cytometry CD45 gating for immunophe-
notyping of acute myeloid leukemia,” Leukemia, vol. 11, no. 11, pp. 1878–1886,
1997.

[142] W. Kern, U. Bacher, C. Haferlach, S. Schnittger, and T. Haferlach, “The role of
multiparameter ﬂow cytometry for disease monitoring in AML,” Best Practice
& Research Clinical Haematology, vol. 23, no. 3, pp. 379–390, 2010.

[143] R. Sharan and T. Ideker, “Modeling cellular machinery through biological net-

work comparison,” Nature Biotechnology, vol. 24, no. 4, pp. 427–433, 2006.

152

[144] R. Singh, J. Xu, and B. Berger, “Global alignment of multiple protein interac-
tion networks with application to functional orthology detection,” Proceedings
of the National Academy of Sciences, vol. 105, no. 35, pp. 12763–12768, 2008.

[145] C. T. Ekstrøm and H. Sørensen, Introduction to Statistical Data Analysis for

the Life Sciences. CRC Press, 2011.

[146] J. Steiger, “Beyond the f test: Eﬀect size conﬁdence intervals and tests of close
ﬁt in the analysis of variance and contrast analysis.,” Psychological Methods,
vol. 9, no. 2, p. 164, 2004.

[147] J. Cohen, Statistical Power Analysis for the Behavioral Sciences. Lawrence

Erlbaum, 1988.

[148] A. Fleishman, “Conﬁdence intervals for correlation ratios,” Educational and

Psychological Measurement, vol. 40, no. 3, pp. 659–670, 1980.

[149] K. Kelley, “Conﬁdence intervals for standardized eﬀect sizes: Theory, appli-
cation, and implementation,” Journal of Statistical Software, vol. 20, no. 8,
pp. 1–24, 2007.

[150] R. A. Johnson and D. W. Wichern, Applied Multivariate Statistical Analysis,

vol. 5. Prentice hall Upper Saddle River, NJ, 2002.

[151] H. Hotelling, “The generalization of student’s ratio,” The Annals of Mathemat-

ical Statistics, pp. 360–378, 1931.

[152] K. S. Pillai and P. Samson Jr, “On Hotelling’s generalization of T2,” Biometrika,

pp. 160–168, 1959.

[153] K. Ito and W. J. Schull, “On the robustness of the T2

0 test in multivariate anal-
ysis of variance when variance-covariance matrices are not equal,” Biometrika,
vol. 51, no. 1-2, pp. 71–82, 1964.

[154] D. T. Hughes and J. G. Saw, “Approximating the percentage points of
0 statistic,” Biometrika, vol. 59, no. 1, pp. 224–226,

Hotelling’s generalized T2
1972.

[155] H. Steyn Jr and S. Ellis, “Estimating an eﬀect size in one-way multivariate
analysis of variance (MANOVA),” Multivariate Behavioral Research, vol. 44,
no. 1, pp. 106–129, 2009.

[156] K. Kelley, “Methods for the behavioral, educational, and social sciences
(MBESS): An R package,” Behavior Research Methods, vol. 39, no. 4, pp. 979–
984, 2007.

[157] D. Farber, O. Acuto, and K. Bottomly, “Diﬀerential T cell receptor-mediated
signaling in naive and memory CD4 T cells,” European Journal of Immunology,
vol. 27, no. 8, pp. 2094–2101, 1997.

[158] M. Ahmadzadeh, S. Hussain, and D. Farber, “Heterogeneity of the memory
CD4 T cell response: Persisting eﬀectors and resting memory T cells,” The
Journal of Immunology, vol. 166, no. 2, p. 926, 2001.

153

[159] M. Ahmadzadeh, S. Hussain, and D. Farber, “Eﬀector CD4 T cells are biochem-
ically distinct from the memory subset: Evidence for long-term persistence of
eﬀectors in vivo,” The Journal of Immunology, vol. 163, no. 6, p. 3053, 1999.

[160] A. Dress, K. T. Huber, J. Koolen, V. Moulton, and A. Spillner, Basic Phyloge-

netic Combinatorics. Cambridge University Press, 2012.

[161] R. Brunelli and T. Poggio, “Face recognition: Features versus templates,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 15, no. 10,
pp. 1042–1052, 1993.

[162] M. De Wachter, M. Matton, K. Demuynck, P. Wambacq, R. Cools, and
D. Van Compernolle, “Template-based continuous speech recognition,” IEEE
Transactions on Audio, Speech, and Language Processing, vol. 15, no. 4,
pp. 1377–1390, 2007.

[163] L. Deng, H. Strik, et al., “Structure-based and template-based automatic speech
recognition-comparing parametric and nonparametric approaches,” in Proceed-
ings of Interspeech, pp. 898–901, 2007.

[164] S. D. Connell and A. K. Jain, “Template-based online character recognition,”

Pattern Recognition, vol. 34, no. 1, pp. 1–14, 2001.

[165] J. M. Bennett, D. Catovsky, M. T. Daniel, G. Flandrin, D. A. Galton, H. R.
Gralnick, and C. Sultan, “Proposed revised criteria for the classiﬁcation of
acute myeloid leukemia: A report of the French-American-British Cooperative
Group,” Annals of Internal Medicine, vol. 103, no. 4, pp. 620–625, 1985.

[166] M. Biehl, K. Bunte, and P. Schneider, “Analysis of ﬂow cytometry data by ma-
trix relevance learning vector quantization,” PLoS One, vol. 8, no. 3, p. e59401,
2013.

[167] T. Manninen, H. Huttunen, P. Ruusuvuori, and M. Nykter, “Leukemia pre-
diction using sparse logistic regression,” PLoS One, vol. 8, no. 8, p. e72932,
2013.

[168] P. Qiu, “Inferring phenotypic properties from single-cell characteristics,” PLoS

One, vol. 7, no. 5, p. e37038, 2012.

[169] “DREAM6/FlowCAP2 molecular classiﬁcation of acute myeloid leukaemia chal-

lenge.” http://www.the-dream-project.org/. Accessed: 2013-12-25.

[170] E. Paietta, “Expression of cell-surface antigens in acute promyelocytic
leukaemia,” Best Practice & Research Clinical Haematology, vol. 16, no. 3,
pp. 369–385, 2003.

[171] D. Campana and F. G. Behm, “Immunophenotyping of leukemia,” Journal of

Immunological Methods, vol. 243, no. 1, pp. 59–75, 2000.

[172] K. D. Mason, S. K. Juneja, and J. Szer, “The immunophenotype of acute
is there a relationship with prognosis?,” Blood Reviews,

myeloid leukemia:
vol. 20, no. 2, pp. 71–82, 2006.

154

[173] A. Keyhani, Y. O. Huh, D. Jendiroba, L. Pagliaro, J. Cortez, S. Pierce, M. Pearl-
man, E. Estey, H. Kantarjian, and E. J. Freireich, “Increased CD38 expression
is associated with favorable prognosis in adult acute leukemia,” Leukemia Re-
search, vol. 24, no. 2, pp. 153–159, 2000.

[174] O. Legrand, J.-Y. Perrot, M. Baudard, A. Cordier, R. Lautier, G. Simonin,
R. Zittoun, N. Casadevall, and J.-P. Marie, “The immunophenotype of 177
adults with acute myeloid leukemia: proposal of a prognostic score,” Blood,
vol. 96, no. 3, pp. 870–877, 2000.

[175] D. Raspadori, D. Damiani, M. Lenoci, D. Rondelli, N. Testoni, G. Nardi,
C. Sestigiani, C. Mariotti, S. Birtolo, M. Tozzi, et al., “CD56 antigenic expres-
sion in acute myeloid leukemia identiﬁes patients with poor clinical prognosis,”
Leukemia, vol. 15, no. 8, pp. 1161–1164, 2001.

[176] K. Walter, P. Cockerill, R. Barlow, D. Clarke, M. Hoogenkamp, G. Follows,
S. Richards, M. Cullen, C. Bonifer, and H. Tagoh, “Aberrant expression of
CD19 in AML with t (8; 21) involves a poised chromatin structure and pax5,”
Oncogene, vol. 29, no. 20, pp. 2927–2937, 2010.

[177] E. Estey and H. D¨ohner, “Acute myeloid leukaemia,” The Lancet, vol. 368,

no. 9550, pp. 1894–1907, 2006.

[178] D. W. Hosmer Jr, S. Lemeshow, and R. X. Sturdivant, Applied Logistic Regres-

sion. Wiley. com, 2013.

[179] W. Zhao, H. Ma, and Q. He, “Parallel k-means clustering based on MapRe-

duce,” in Cloud Computing, pp. 674–679, Springer, 2009.

[180] D. Foti, D. Lipari, C. Pizzuti, and D. Talia, “Scalable parallel clustering for data
mining on multicomputers,” in Parallel and Distributed Processing, pp. 390–398,
Springer, 2000.

[181] X. Li and Z. Fang, “Parallel clustering algorithms,” Parallel Computing, vol. 11,

no. 3, pp. 275–290, 1989.

VITA

155

VITA

Ariful Azad was born in Ullapara, in the district of Sirajganj, Bangladesh on

September 1, 1982. He is the youngest son of Anwar Hossain and Ayesha Begum. He

ﬁnished high school from Pabna Cadet College in 2000 and completed his Bachelors

in Computer Science and Engineering from Bangladesh University of Engineering and

Technology (BUET) in 2006. Ariful started his Ph.D. in Computer Science at Purdue

University in August 2008 under the supervision of Prof. Alex Pothen. His research

interests include bioinformatics, graph algorithms, and parallel computing. His Ph.D.

research has been published to several peer reviewed journals and conferences.

Ariful is a recipient of an IBM PhD fellowship (2013), outstanding poster award

(Cyto 2013), fellowship incentive grant (2010), Purdue research fellowship (2010) and

several travel awards from NSF, NIH and ISAC. He worked as a summer intern at

Paciﬁc Northwest National Laboratory (PNNL) in summer 2010, 2011. During his

study at Purdue, he served as the president of Bangladesh students organization

(2012-13) and the webmaster of Purdue graduate student government (2009-11).

Ariful is married to Rubaya Pervin who is also a graduate of Bangladesh University

of Engineering and Technology (BUET). His favorite sports are Cricket and Tennis.

He enjoys to travel and watch movies in his leisure time.

